<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[编译链接常识]]></title>
    <url>%2F2017%2F12%2F27%2F%E7%BC%96%E8%AF%91%E9%93%BE%E6%8E%A5%E5%B8%B8%E8%AF%86%2F</url>
    <content type="text"><![CDATA[基本概念 库是一种可执行的二进制代码(但不可以独立执行)，可以被操作系统载入内存执行。 由于 windows 和 linux 的平台不同（主要是编译器、汇编器和连接器 的不同），因此二者库的二进制是不兼容的。本文仅限于介绍 linux 下的库。 库的种类linux 下的库有两种：静态库和共享库（动态库）。 二者的不同点在于代码被载入的时刻不同： 静态库的代码在编译过程中已经被载入可执行程序，因此生成的可执行程序体积较大。静态用.a为后缀， 例如： libhello.a 共享库(动态库)的代码是在可执行程序运行时才载入内存的，在编译过程中仅简单的引用，因此生成的可执行程序代码体积较小。动态通常用.so为后缀， 例如：libhello.so 共享库(动态库)的好处是: 不同的应用程序如果调用相同的库，那么在内存里只需要有一份该共享库的实例。 为了在同一系统中使用不同版本的库，可以在库文件名后加上版本号为后缀,例如： libhello.so.1.0,由于程序连接默认以.so为文件后缀名。所以为了使用这些库，通常使用建立符号连接的方式。 ln -s libhello.so.1.0 libhello.so.1 ln -s libhello.so.1 libhello.so 静态库，动态库文件在linux下是如何生成的以下面的代码为例，生成上面用到的hello库： /* hello.c */ #include &quot;hello.h&quot; void sayhello() { printf(&quot;hello,world &quot;); } 首先用gcc编绎该文件，在编绎时可以使用任何合法的编绎参数，例如-g加入调试代码等：gcc -c hello.c -o hello.o 1、生成静态库 生成静态库使用ar工具，其实ar是archive的意思ar cqs libhello.a hello.o2、生成动态库 用gcc来完成，由于可能存在多个版本，因此通常指定版本号：gcc -shared -o libhello.so.1.0 hello.o 库文件是如何命名的，有没有什么规范在 linux 下，库文件一般放在/usr/lib和/lib下，静态库的名字一般为libxxxx.a，其中 xxxx 是该lib的名称；动态库的名字一般为libxxxx.so.major.minor，xxxx 是该lib的名称，major是主版本号，minor是副版本号 可执行程序在执行的时候如何定位共享库(动态库)文件当系统加载可执行代码(即库文件)的时候，能够知道其所依赖的库的名字，但是还需要知道绝对路径，此时就需要系统动态载入器 (dynamic linker/loader) 对于 elf 格式的可执行程序，是由 ld-linux.so* 来完成的，它先后搜索 elf 文件的 DT_RPATH 段 –&gt; 环境变量LD_LIBRARY_PATH —-&gt; /etc/ld.so.cache 文件列表–&gt; /lib/,/usr/lib 目录找到库文件后将其载入内存 如： export LD_LIBRARY_PATH=’pwd’ 将当前文件目录添加为共享目录。 使用ldd工具，查看可执行程序依赖那些动态库或着动态库依赖于那些动态库ldd 命令可以查看一个可执行程序依赖的共享库，例如 # ldd /bin/lnlibc.so.6 =&gt; /lib/libc.so.6 (0×40021000)/lib/ld-linux.so.2 =&gt; /lib/ld- linux.so.2 (0×40000000)可以看到 ln 命令依赖于 libc 库和 ld-linux 库 使用nm工具，查看静态库和动态库中有那些函数名（T类表示函数是当前库中定义的，U类表示函数是被调用的，在其它库中定义的，W类是当前库中定义，被其它库中的函数覆盖）。：有时候可能需要查看一个库中到底有哪些函数，nm工具可以打印出库中的涉及到的所有符号，这里的库既可以是静态的也可以是动态的。nm列出的符号有很多， 常见的有三种:: T类：是在库中定义的函数，用T表示，这是最常见的； U类：是在库中被调用，但并没有在库中定义(表明需要其他库支持)，用U表示； W类：是所谓的“弱态”符号，它们虽然在库中被定义，但是可能被其他库中的同名符号覆盖，用W表示。 例如，假设开发者希望知道上文提到的hello库中是否引用了 printf(): nm libhello.so | grep printf发现printf是U类符号，说明printf被引用，但是并没有在库中定义。 由此可以推断，要正常使用hello库，必须有其它库支持，使用ldd工具查看hello依赖于哪些库： ldd libhello.so libc.so.6=&gt;/lib/libc.so.6(0x400la000) /lib/ld-linux.so.2=&gt;/lib/ld-linux.so.2 (0x40000000) 从上面的结果可以继续查看printf最终在哪里被定义，有兴趣可以go on 使用ar工具，可以生成静态库，同时可以查看静态库中包含那些.o文件，即有那些源文件构成可以使用 ar -t libname.a 来查看一个静态库由那些.o文件构成。 可以使用 ar q libname.a xxx1.o xxx2.o xxx3.o ... xxxn.o 生成静态库 如何查看动态库和静态库是32位，还是64位下的库如果是动态库，可以使用file *.so；如果是静态库，可以使用objdump -x *.a Linux下进行程序设计时，关于库的使用gcc/g++命令中关于库的参数-shared： 该选项指定生成动态连接库； -fPIC：表示编译为位置独立(地址无关)的代码，不用此选项的话，编译后的代码是位置相关的，所以动态载入时，是通过代码拷贝的方式来满足不同进程的需要，而不能达到真正代码段共享的目的。 -L：指定链接库的路径，-L. 表示要连接的库在当前目录中 -ltest：指定链接库的名称为test，编译器查找动态连接库时有隐含的命名规则，即在给出的名字前面加上lib，后面加上.so来确定库的名称 -Wl,-rpath: 记录以来so文件的路径信息。 LD_LIBRARY_PATH：这个环境变量指示动态连接器可以装载动态库的路径。 当然如果有root权限的话，可以修改/etc/ld.so.conf文件，然后调用 /sbin/ldconfig来达到同样的目的， 不过如果没有root权限，那么只能采用修改LD_LIBRARY_PATH环境变量的方法了。 调用动态库的时候，有几个问题会经常碰到有时，明明已经将库的头文件所在目录 通过 “-I” include进来了，库所在文件通过 “-L”参数引导，并指定了“-l”的库名，但通过ldd命令察看时，就是死活找不到你指定链接的so文件，这时你要作的就是通过修改 LD_LIBRARY_PATH或者/etc/ld.so.conf文件来指定动态库的目录。通常这样做就可以解决库无法链接的问题了。 静态库链接时搜索路径的顺序1. ld会去找gcc/g++命令中的参数-L； 2. 再找gcc的环境变量LIBRARY_PATH,它指定程序静态链接库文件搜索路径； 1. `export LIBRARY_PATH=$LIBRARY_PATH:data/home/billchen/lib ` 3. 再找默认库目录 /lib /usr/lib /usr/local/lib，这是当初compile gcc时写在程序内的。 动态链接时、执行时搜索路径顺序1. 编译目标代码时指定的动态库搜索路径； 2. 环境变量LD_LIBRARY_PATH指定动态库搜索路径，它指定程序动态链接库文件搜索路径； export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:data/home/billchen/lib 3. 配置文件/etc/ld.so.conf中指定的动态库搜索路径； 4. 默认的动态库搜索路径/lib； 5. 默认的动态库搜索路径/usr/lib。 静态库和动态链接库同时存在时，gcc/g++默认链接的是动态库 当一个库同时存在静态库和动态库时，比如libmysqlclient.a和libmysqlclient.so同时存在时：在Linux下，动态库和静态库同事存在时，gcc/g++的链接程序，默认链接的动态库。 可以使用下面的方法，给连接器ld传递参数，看是否链接动态库还是静态库。 -Wl,-Bstatic -llibname //指定让gcc/g++链接静态库 使用: gcc/g++ test.c -o test -Wl,-Bstatic -llibname -Wl,-Bdynamic -lm -lc -Wl,-Bdynamic -llibname //指定让gcc/g++链接动态库 使用: gcc/g++ test.c -o test -Wl,-Bdynamic -llibname 如果要完全静态加载，使用-static参数，即将所有的库以静态的方式链入可执行程序，这样生成的可执行程序，不再依赖任何库，同事出现的问题是，这样编译出来的程序非常大，占用空间。如果不适用-Wl,-Bdynamic -lm -c会有如下错误： [chenbaihu@build17 lib]$ ls libtest.a libtest.so t t.cc test.cc test.h test.o [chenbaihu@build17 lib]$ g++ -Wall -g t.cc -o t -L./ -Wl,-Bstatic -ltest -Wl,-Bdynamic -lm -lc [chenbaihu@build17 lib]$ g++ -Wall -g t.cc -o t -L./ -Wl,-Bstatic -ltest /usr/bin/ld: cannot find -lm collect2: ld 返回 1 参考： http://lists.gnu.org/archive/html/help-gnu-utils/2004-03/msg00009.html 有关环境变量LIBRARY_PATH环境变量：指定程序静态链接库文件搜索路径LD_LIBRARY_PATH环境变量：指定程序动态链接库文件搜索路径 库的依赖问题比如我们有一个基础库libbase.a,还有一个依赖libbase.a编译的库，叫做libchild.a；在我们编译程序时，一定要先-lchild再-lbase。 如果使用 -lbase -lchild，在编译时将出现一些函数undefined，而这些函数实际上已经在base中已经定义； 为什么会有库的依赖问题？ 一、静态库解析符号引用： 链接器ld是如何使用静态库来解析引用的。在符号解析阶段，链接器从左至右，依次扫描可重定位目标文件（*.o）和静态库（*.a）。 在这个过程中，链接器将维持三个集合： 集合E：可重定位目标文件(*.o文件)的集合。 集合U：未解析(未定义)的符号集，即符号表中UNDEF的符号。 集合D： 已定义的符号集。 初始情况下，E、U、D均为空。 1、对于每个输入文件f，如果是目标文件(.o)，则将f加入E，并用f中的符号表修改U、D(在文件f中定义实现的符号是D，在f中引用的符号是U)，然后继续下个文件。 2、如果f是一个静态库(.a)，那么链接器将尝试匹配U中未解析符号与静态库成员(静态库的成员就是.o文件)定义的符号。如果静态库中某个成员m(某个.o文件)定义了一个符号来解析U中引用，那么将m加入E中， 同时使用m的符号表，来更新U、D。对静态库中所有成员目标文件反复进行该过程，直至U和D不再发生变化。此时，静态库f中任何不包含在E中的成员目标文件都将丢弃，链接器将继续下一个文件。 3、当所有输入文件完成后，如果U非空，链接器则会报错，否则合并和重定位E中目标文件，构建出可执行文件。 到这里，为什么会有库的依赖问题已经得到解答： 因为libchild.a依赖于libbase.a，但是libbase.a在libchild.a的左边，导致libbase.a中的目标文件(*.o)根本就没有被加载到E中，所以解决方法就是交换两者的顺序。当然也可以使用-lbase -lchild -lbase的方法。 参考文章：http://pananq.com/index.php/page/3/ 动态库升级问题在动态链接库升级时， 不能使用cp newlib.so oldlib.so，这样有可能会使程序core掉； 而应该使用: rm oldlib.so 然后 cp newlib.so oldlib.so 或者 mv oldlib.so oldlib.so_bak 然后 cp newlib.so oldlib.so 为什么不能用cp newlib.so oldlib.so ? 在替换so文件时，如果在不停程序的情况下，直接用 cp new.so old.so 的方式替换程序使用的动态库文件会导致正在运行中的程序崩溃。 解决方法: 解决的办法是采用“rm＋cp” 或“mv＋cp” 来替代直接“cp” 的操作方法。 linux系统的动态库有两种使用方法：运行时动态链接库，动态加载库并在程序控制之下使用。 1、为什么在不停程序的情况下，直接用 cp 命令替换程序使用的 so 文件，会使程序崩溃？很多同学在工作中遇到过这样一个问题，在替换 so 文件时，如果在不停程序的情况下，直接用cp new.so old.so的方式替换程序使用的动态库文件会导致正在运行中的程序崩溃，退出。 这与 cp 命令的实现有关，cp 并不改变目标文件的 inode，cp 的目标文件会继承被覆盖文件的属性而非源文件。实际上它是这样实现的： strace cp libnew.so libold.so 2&gt;&amp;1 |grep open.*lib.*.so open(&quot;libnew.so&quot;, O_RDONLY|O_LARGEFILE) = 3 open(&quot;libold.so&quot;, O_WRONLY|O_TRUNC|O_LARGEFILE) = 4 在 cp 使用“O_WRONLY|O_TRUNC” 打开目标文件时，原 so 文件的镜像被意外的破坏了。这样动态链接器 ld.so 不能访问到 so 文件中的函数入口。从而导致 Segmentation fault，程序崩溃。ld.so 加载 so 文件及“再定位”的机制比较复杂。 2、怎样在不停止程序的情况下替换so文件，并且保证程序不会崩溃？ 答案是采用“rm＋cp” 或“mv＋cp” 来替代直接“cp” 的操作方法。 在用新的so文件 libnew.so 替换旧的so文件 libold.so 时，如果采用如下方法： rm libold.so //如果内核正在使用libold.so，那么inode节点不会立刻别删除掉。 cp libnew.so libold.so 采用这种方法，目标文件 libold.so 的 inode 其实已经改变了，原来的 libold.so 文件虽然不能用&quot;ls&quot;查看到，但其inode并没有被真正删除，直到内核释放对它的引用。 （即: rm libold.so，此时，如果ld.so正在加在libold.so，内核就在引用libold.so的inode节点，rm libold.so的inode并没有被真正删除，当ld.so对libold.so的引用结束，inode才会真正删除。这样程序就不会崩溃，因为它还在使用旧的libold.so，当下次再使用libold.so时，已经被替换，就会使用新的libold.so） 同理，mv只是改变了文件名，其 inode 不变，新文件使用了新的 inode。这样动态链接器 ld.so 仍然使用原来文件的 inode 访问旧的 so 文件。因而程序依然能正常运行。 (即: mv libold.so *后，如果程序使用动态库，还是使用旧的inode节点，当下次再使用libold.so时，就会使用新的libold.so) 到这里，为什么直接使用“cp new_exec_file old_exec_file”这样的命令时，系统会禁止这样的操作，并且给出这样的提示“cp: cannot create regular file `old&#39;: Text file busy”。 这时，我们采用的办法仍然是用“rm+cp”或者“mv+cp”来替代直接“cp”，这跟以上提到的so文件的替换有同样的道理。 但是，为什么系统会阻止cp覆盖可执行程序，而不阻止覆盖so文件呢？ 这是因为 Linux 有个 Demand Paging 机制，所谓“Demand Paging”，简单的说，就是系统为了节约物理内存开销，并不会程序运行时就将所有页（page）都加载到内存中，而只有在系统有访问需求时才将其加载。“Demand Paging”要求正在运行中的程序镜像（注意，并非文件本身）不被意外修改，因此内核在启动程序后会锁定这个程序镜像的 inode。 对于 so 文件，它是靠 ld.so 加载的，而ld.so毕竟也是用户态程序，没有权利去锁定inode，也不应与内核的文件系统底层实现耦合。 来源转载自：http://blog.163.com/xychenbaihu@yeah/blog/static/13222965520101023104745738/]]></content>
      <categories>
        <category>C语言</category>
      </categories>
      <tags>
        <tag>C语言,编译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[各大公司git地址]]></title>
    <url>%2F2017%2F12%2F13%2F%E5%90%84%E5%A4%A7%E5%85%AC%E5%8F%B8git%E5%9C%B0%E5%9D%80%2F</url>
    <content type="text"><![CDATA[github,一个神奇的网址gitbook，另一个神奇的网址，.com,.net,.cn都可以逛一下 百度https://github.com/baiduhttps://github.com/baidufehttps://github.com/ecomfe 阿里https://github.com/alibaba 腾讯https://github.com/tencenthttps://github.com/AlloyTeamhttps://github.com/TencentOpen 360https://github.com/Qihoo360 网易https://github.com/netease 京东https://github.com/jcloudpub 华为https://github.com/huawei-openlabhttps://github.com/Huawei-Hadoop 唯品会https://github.com/vipshop 豆瓣https://github.com/douban 小米https://github.com/xiaomi 美团，大众点评https://github.com/meituanhttps://github.com/meituan-dianpinghttps://github.com/dianping 58同城https://github.com/58code 当当https://github.com/dangdangdotcom 深度https://github.com/linuxdeepin 新浪https://github.com/fastoshttps://github.com/CNSREhttps://github.com/weibocom 搜狐https://github.com/SOHUDBA 豌豆荚https://github.com/CodisLabs 谷歌https://github.com/google 微软https://github.com/Microsoft 苹果https://github.com/apple 亚马逊https://github.com/aws facebookhttps://github.com/facebook 雅虎https://github.com/yahoo]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pthread常用接口]]></title>
    <url>%2F2017%2F12%2F08%2Fpthread%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[pthread_equal函数判断两个线程ID是否相等int pthread_equal(pthread_t tid1,pthread tid2); 参数： tid1：第一个线程ID tid2：第二个线程ID 返回值： -相等：返回非0数值 不等：返回 0 pthread_self(void)函数返回本线程自身的线程IDpthread_t pthread_self(void); 返回值：调用线程的线程ID pthread_create函数创建新线程int pthread_create(pthread_t *restrict tidp,const pthread_attr_t *restrict attr,void *(*start_rtn)(void*),void *restrict arg); 参数： tidp：成功创建时，新线程的线程ID存放在tidp指向的内存单元 attr：用于定制不同的线程属性。如果为NULL，则是默认属性 start_rtn：线程例程地址。新创建的线程从start_rtn函数的地址处开始运行，该函数的参数为void ，返回值为void arg：作为start_rtn函数的参数 返回值： 成功：返回 0 失败：返回错误编号 pthread_exit函数线程主动退出void pthread_exit(void *rval_ptr); 参数： rval_ptr：一个无类型指针，用于给pthread_join函数传递参数（即线程间消息传递） pthread_join函数等待指定的线程结束（类似于waitpid）int pthread_join(pthread_t tid,void **rval_pptr); 参数： tid：要等待的线程的线程ID rval_pptr：一个指针，指向无类型指针（该无类型指针用于线程返回值） 返回值： 成功：返回 0 失败：返回错误编号 当调用线程调用pthread_join之后，调用线程将会一直阻塞，直到: 指定的线程tid调用pthread_exit。此时rval_pptr指向的内存区就包含pthread_exit的rval_ptr的值 指定的线程tid从启动例程返回。此时rval_pptr指向的内存区就包含返回码 指定的线程tid被取消。此时rval_pptr指向的内存单元就设置为PTHREAD_CANCELED 如果不关注线程的返回值，则可以将rval_pptr设置为NULL。此时pthread_join函数可以等待指定的线程终止，但是并不获取线程的终止状态。 可以通过调用pthread_join自动把线程置于分离状态，此时资源可以恢复。如果线程已经处理分离状态，pthread_join调用就会失败，返回EINVAL pthread_cancel函数请求取消同一个进程中的其他某个线程int pthread_cancel(pthread_t tid); 参数： tid：期望取消的线程的ID 返回值： 成功：返回 0 失败：返回错误码 默认情况下，pthread_cancel函数会使得由tid标识的线程的行为表现得如同调用了pthread_exit(PTHREAD_CANCELD)函数。但是，tid标识的线程可以选择忽略取消或者控制如何被取消。 pthread_cancel并不等待线程tid终止，也不保证线程tid终止，它仅仅提出了请求 pthread_clearnup_push/pthread_cleanup_pop函数注册与注销清理处理程序一个线程可以建立多个清理处理程序处理程序记录在栈中。即它们的执行顺序与它们注册时相反 void pthread_cleanup_push(void (*rtn)(void*),void *arg);void pthread_cleanup_pop(int execute); 对于 pthread_cleanup_push函数： rtn：清理处理程序的指针。rtn函数的参数是void *，返回void arg：作为清理处理程序rtn的参数 对于pthread_cleanup_pop函数： execute：如果为0，则线程退出时，清理函数不被调用（哪个清理函数？见后面说明） execute：如果非零，则线程退出时，对应的清理函数被调用 pthread_detach函数将指定线程设置为分离状态int pthread_detach(pthread_t tid); 参数： tid：被分离的线程的ID 返回值： 成功：返回 0 失败：返回错误码 pthread_mutex_t/pthread_mutex_init/pthread_mutex_destroy互斥量用pthread_mutex_t数据类型表示 使用互斥量之前必须初始化。 如果是动态分配的互斥量（如通过malloc函数），则必须调用pthread_mutex_init函数进行初始化 如果是静态分配的互斥量，那么除了调用pthread_mutex_init函数来初始化，也可以将它设置为常量PTHREAD_MUTEX_INITALIZER来初始化 如果是动态分配的互斥量，那么在free释放内存之前必须调用pthread_mutex_destroy函数来销毁互斥量。该函数会释放在动态初始化互斥量时动态分配的资源#include&lt;pthread.h&gt; int pthread_mutex_init(pthread_mutex_t *restrict mutex, const pthread_mutexattr_t *restrict attr); int pthread_mutex_destroy(pthread_mutex_t *mutex); 参数： mutex：待初始化/释放的互斥量的地址 attr：互斥量的属性。如果为NULL，那么互斥量设置为默认属性 返回值： 成功：返回0 失败： 返回错误编号 pthread_mutex_lock/pthread_mutex_trylock/pthread_mutex_unlock函数对互斥量加锁/解锁操作 #include&lt;pthread.h&gt; int pthread_mutex_lock(pthread_mutex_t *mutex); int pthread_mutex_trylock(pthread_mutex_t *mutex); int pthread_mutex_unlock(pthread_mutex_t *mutex); 参数： mutex：待加锁/解锁的互斥量的地址 返回值： 成功：返回0 失败： 返回错误编号 用法： pthread_mutex_lock用于对互斥量进行加锁。如果互斥量已经上锁，则调用线程将阻塞直到互斥量解锁 pthread_mutex_unlock用于对互斥量进行解锁 pthread_mutex_trylock也用于对互斥量进行加锁 如果它被调用时，互斥量处于未锁定状态，那么函数将锁住互斥量并返回0 如果它被调用时，互斥量处于锁定状态，则函数调用失败，立即返回EBUSY而不是阻塞 pthread_mutex_timedlock函数对互斥量加锁或等待指定时间 #include&lt;pthread.h&gt; #include&lt;time.h&gt; int pthread_mutex_timedlock(pthread_mutex_t *restrict mutex, const struct timespec *restrict tsptr); 参数： mutex：待加锁的互斥量的地址 tsptr(超时时间)：指向一个timespec的指针，该timepsec指定了一个绝对时间（并不是相对时间，比如10秒） 返回值： 成功：返回0 失败： 返回错误编号 pthread_mutex_timedlock被调用时： 如果互斥量处于未锁定状态，那么函数将锁住互斥量并返回0 如果互斥量处于锁定状态，那么函数将阻塞到tsptr指定的时刻。在到达超时时刻时，pthread_mutex_timedlock不再试图对互斥量进行加锁，而是返回错误码ETIMEOUT 可以使用clock_gettime函数获取timespec结构表示的当前时间。但是目前并不是所有平台都支持这个函数。因此也可以用gettimeofday函数获取timeval结构表示的当前时间，然后将这个时间转换为timespec结构。 pthread_rwlock_t、pthread_rwlock_init、pthread_rwlock_destroy 当读写锁是写锁定状态时，在该锁被解锁之前，所有试图对这个锁加锁（无论是加读锁还是价写锁）的线程都会被阻塞 当读写锁是读锁定状态时，所有试图对它加读锁的线程都可以获得访问权，但是所有试图对它加写锁的线程都会被阻塞 使用读写锁之前必须初始化。 如果是动态分配的读写锁（如通过malloc函数），则必须调用pthread_rwlock_init函数进行初始化 如果是静态分配的读写锁，那么除了调用pthread_rwlock_init函数来初始化，也可以将它设置为常量PTHREAD_RWLOCK_INITALIZER来初始化 如果是动态分配的读写锁，那么在free释放内存之前必须调用pthread_rwlock_destroy函数来销毁读写锁。该函数会释放在动态初始化读写锁时动态分配的资源#include&lt;pthread.h&gt; int pthread_rwlock_init(pthread_rwlock_t *restrict rwlock, const pthread_rwlockattr_t *restrict attr); int pthread_rwlock_destroy(pthread_rwlock_t *rwlock); 参数： rwlock：待初始化/销毁的读写锁的地址 attr：读写锁的属性。如果为NULL，那么读写锁设置为默认属性 返回值： 成功：返回0 失败： 返回错误编号 pthread_rwlock_rdlock/pthread_rwlock_wrlock/pthread_rwlock_unlock函数对读写锁加锁/解锁操作 #include&lt;pthread.h&gt; int pthread_rwlock_rdlock(pthread_rwlock_t *rwlock); int pthread_rwlock_wrlock(pthread_rwlock_t *rwlock); int pthread_rwlock_unlock(pthread_rwlock_t *rwlock); 参数： rwlock：待加锁/解锁的读写锁的地址 返回值： 成功：返回0 失败： 返回错误编号 用法： pthread_rwlock_rdlock用于对读写锁加读锁。如果读写锁当前是未加锁的，或者是读锁定的，则加锁成功；如果读写锁当前是写锁定的，则阻塞线程。 pthread_rwlock_wrlock用于对读写锁加写锁。如果读写锁当前是未加锁的，则加锁成功；如果读写锁当前是读锁定或者写锁定的，则阻塞线程。 pthread_rwlock_unlock用于对读写锁进行解锁，无论读写锁当前状态是处于读锁定还是写锁定。 注意：有的实现对读写锁同时加读锁的数量有限制。并不是无限制的加读锁。 pthread_rwlock_tryrdlock/pthread_rwlock_trywrlock函数对读写锁加锁的条件版本 #include&lt;pthread.h&gt; int pthread_rwlock_tryrdlock(pthread_rwlock_t *rwlock); int pthread_rwlock_trywrlock(pthread_rwlock_t *rwlock); 参数： rwlock：待加锁的读写锁的地址 返回值： 成功：返回0 失败： 返回错误编号 当可以加锁时，这两个函数返回0。否则它们返回错误EBUSY而不是阻塞线程。 pthread_rwlock_timedrdlock/pthread_rwlock_timedwrlock函数对读写锁加锁的超时版本 #include&lt;pthread.h&gt; #include&lt;time.h&gt; int pthread_rwlock_timedrdlock(pthread_rwlock_t *rwlock, const struct timespect*restrict tsptr); int pthread_rwlock_timedwrlock(pthread_rwlock_t *rwlock, const struct timespect*restrict tsptr); 参数： rwlock：待加锁的读写锁的地址 tsptr：指向一个timespec的指针，该timepsec指定了一个绝对时间（并不是相对时间，比如10秒） 返回值： 成功：返回0 失败： 返回错误编号这两个函数被调用时： 如果允许加锁，那么函数将对读写锁加锁并返回0 如果不允许加锁，那么函数将阻塞到tsptr指定的时刻。在到达超时时刻时，pthread_mutex_timedlock不再试图对读写锁进行加锁，而是返回错误码ETIMEOUT 可以使用clock_gettime函数获取timespec结构表示的当前时间。但是目前并不是所有平台都支持这个函数。因此也可以用gettimeofday函数获取timeval结构表示的当前时间，然后将这个时间转换为timespec结构。]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>pthread,多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文件和目录]]></title>
    <url>%2F2017%2F12%2F04%2F%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[一、 stat 结构和权限相关 四个stat函数：返回文件或者目录的信息结构： #include&lt;sys/stat.h&gt; int stat(const char * restrict pathname, struct stat*restrict buf); int fstat(int fd, struct stat* buf); int lstat(const char* restrict pathname,struct stat *restrict buf); int fstatat(int fd,const char*restrict pathname,struct stat*restrict buf,int flag); 参数： pathname：文件或者目录的名字 buf：存放信息结构的缓冲区 fd：打开的文件描述符 对于fstat，该文件就是待查看信息的文件 对于fstatat，该文件是并不是待查看信息的文件。待查看信息的文件时已该fd对于的目录相对路径定位的 flag：控制着fstatat函数是否跟随一个符号链接。 对于fstatat函数： 待查看的文件名是由fd和pathname共同决定的。 如果pathname是个绝对路径，则忽略fd参数 如果pathname是个相对路径路径，且 fd=AT_FDCWD，则在当前工作目录的路径下查找pathname 如果pathname是个相对路径路径，且 fd!=AT_FDCWD，则在fd对应的打开目录下查找pathname flag：控制着fstatat函数是否跟随一个符号链接。当!AT_SYMLINK_FOLLOW标志被设置时，查看的是pathname（如果它是个符号链接）本身的信息；否则默认查看的是pathname（如果它是个符号链接）链接引用的文件的信息。 返回值： 成功：返回 0 失败： 返回 -1 注意： lstat类似于stat，但是当pathname是个符号链接时，lstat查看的是该符号链接的有关信息；而stat是查看该符号链接引用的文件的信息。 在 ubuntu 16.04上，虽然有 AT_SYMLINK_NOFOLLOW这个常量，但是不支持。必须用 !AT_SYMLINK_FOLLOW。其常量定义为： AT_SYMLINK_FOLLOW： 1024 (有效） !AT_SYMLINK_FOLLOW： 0(有效） AT_SYMLINK_NOFOLLOW： 256(无效） AT_SYMLINK_FOLLOW： -1025(无效） stat数据结构：其定义可能与具体操作系统相关，但是基本形式为： struct stat{ mode_t st_mode; //文件权限和类型信息 ino_t st_ino; //i-node 号 dev_t st_dev; // 设备号 dev_t st_rdev; // 特殊文件的设备号 nlink_t st_nlink; // 硬链接数量 uid_t st_uid; // owner 的用户ID gid_t st_gid; // owner 的组ID off_t st_size; //对普通文件，它是文件字节大小 struct timespec st_atime; // 上次访问时间 struct timespec st_mtile; // 上次修改时间 struct timespec st_ctime; // 上次文件状态改变的时间 blksize_t st_blksize; // 最佳的 I/O block 大小 blkcnt_t st_blocks; //分配的磁盘块数量 } 其中timespec结构与具体操作系统相关，但是至少包括下面两个字段： struct timespec{ time_t tv_sec; // 秒 long tv_nsec; //纳秒 } UNIX 文件类型： 普通文件：最常见的文件类型，这种文件包含了某种形式的数据。至于这种数据是二进制还是文本，对内核无区别。普通文件的内容解释由具体的应用程序进行。 目录文件：这种文件包含了其他文件的名字，以及指向这些文件有关信息的指针。 只有内核可以直接写目录文件（通常用户写目录文件都要通过内核） 对某个目录文件具有读权限的任何一个进程都可以读取该目录的内容 块特殊文件：这种类型的文件提供对设备（如磁盘）带缓冲的访问。每次访问以固定长度为单位进行。 字符特殊文件：这种类型的文件提供对设备不带缓冲的访问，每次访问长度可变。 系统的所有设备，要么是字符特殊文件，要么是块特殊文件 FIFO：这种类型的文件用于进程间通信，有时也称为命名管道 套接字：这种类型的文件用于进程间的网络通信（也可用于单机上进程的非网络通信） 符号链接：这种类型的文件指向另一个文件 文件类型信息存放在stat.st_mode成员中，可以用下列的宏测试文件类型： S_ISREG()：测试是否普通文件 S_ISDIR()：测试是否目录文件 S_ISCHR()：测试是否字符特殊文件 S_ISBLK()：测试是否块特殊文件 S_ISFIFO()：测试是否FIFO S_ISLNK()：测试是否符号链接文件 S_ISSOCK()：测试是否套接字 另外 POSIX.1 允许将进程间通信对象说明为文件。但是下面的宏测试的不是stat.st_mode，而是stat*（stat指针）： S_TYPEISMQ()：测试是否消息队列 S_TYPEISSEM()：测试是否信号量 S_TYPEISSHM()：测试是否共享存储对象 与一个进程有关的ID有很多: 实际用户 ID 和实际组 ID： 标志我们究竟是谁。当我们登录进操作系统时，这两个值就确定了！ 有效用户 ID、有效组ID、附属组 ID： 用于文件访问权限检查。 保存的设置用户ID、保存的设置组ID：由 exec函数保存 每个文件都有一个所有者和组所有者，分别有 stat.st_uid和stat.st_gid指定。当一个文件时可执行文件时，如果执行这个文件，那么进程的有效用户ID就是实际用户ID，有效组ID就是实际组ID，除了下面的情况： 当在stat.st_mode中设置了一个特殊标志：设置用户ID位时，则将进程的有效用户ID设置为文件所有者的用户ID 当在stat.st_mode中设置了一个特殊标志：设置组ID位时，则将进程的有效组ID设置为文件所有者的组ID 任何进程都是由可执行文件被执行而得到。因此位于磁盘上的可执行文件的所属的用户ID和组ID会影响到进程的用户ID和组ID 如果某个可执行文件所有者是root，且该文件的设置用户ID位已经被设置，那么无论谁执行这个可执行文件时，该可执行文件产生的进程就具有超级用户权限。 设置用户ID位、设置组ID位 都包含在stat.st_mode中，可以通过下列两个宏测试： S_ISUID()：测试是否设置了设置用户ID位 S_ISGID()：测试是否设置了设置组ID位 文件访问权限：所有文件类型（包括目录，字符特别文件等）都有访问权限。每个文件都有9个访问权限位： S_IRUSR：用户读 S_IWUSR：用户写 S_IXUSR：用户执行 S_IRGRP：组读 S_IWGRP：组写 S_IXGRP：组执行 S_IROTH：其他读 S_IWOTH：其他写 S_IXOTH：其他执行 访问权限规则： 当用名字pathname打开任何一个类型的文件时，对pathname中包含的每一个目录，包括pathname可能隐含的当前工作目录都应该具有执行权限 因此目录的执行权限位也称之为搜索位 对一个文件的读权限决定了我们能否打开现有文件进行读操作 对一个文件的写权限决定了我们能否打开现有文件进行写操作 如果你在open函数中对一个文件指定了O_TRUNC标志，则必须对该文件具有写权限 为了在一个目录中常见一个新文件，必须对该目录具有写权限和执行权限 为了删除一个现有文件，必须对包含该文件的目录具有写权限和执行权限。对该文件本身没有权限的限制 如果用7个exec函数中的任何一个执行某个文件，则必须对该文件具有执行权限，且该文件必须是个普通文件 进程每次打开、创建、删除一个文件时，内核就进行文件访问权限测试。这种测试如下： 若进程的有效用户ID是0（超级用户），则对该文件的任何访问行为都批准 若进程的有效用户ID等于文件的所有者ID（也就是进程拥有此文件）： 如果该文件的用户读权限开放，则内核允许进程读该文件 如果该文件的用户写权限开放，则内核允许进程写该文件 如果该文件的用户执行权限开放，则内核允许进程执行该文件 若进程的有效组ID或者进程的附属组ID之一等于文件的组ID： 如果该文件的组读权限开放，则内核允许进程读该文件 如果该文件的组写权限开放，则内核允许进程写该文件 如果该文件的用户执行权限开放，则内核允许进程执行该文件 否则： 如果该文件的其他读权限开放，则内核允许进程读该文件 如果该文件的其他写权限开放，则内核允许进程写该文件 如果该文件的其他户执行权限开放，则内核允许进程执行该文件 只要有一个权限通过，则不再进行测试。若所有权限都不通过，则不允许访问。 对一个目录的读权限和可执行权限是不同的： 目录读权限：允许读目录，从而获得在该目录中所有文件名的列表 目录可执行权限：允许搜索该目录，从而寻找一个特定的文件名 当一个进程通过open或者creat创建一个新文件时： 新文件的用户ID被设置为进程的有效用户ID 新文件的组ID可以有两个值之一： 进程的有效组ID 文件所在目录的组ID 具体选择哪个，由具体操作系统决定 stat和lstat示例：在main函数中调用test_stat_lstat函数： void test_stat_lstat() { M_TRACE(&quot;--------- Begin test_stat_lstat() ---------\n&quot;); Stat stat_buf; My_stat(&quot;/home/huaxz1986/APUE/main.c&quot;,&amp;stat_buf); // regular file My_stat(&quot;/home/huaxz1986/APUE/&quot;,&amp;stat_buf); // dir file My_stat(&quot;/dev/loop0&quot;,&amp;stat_buf); // block file My_stat(&quot;/dev/mem&quot;,&amp;stat_buf); // char file My_lstat(&quot;/dev/cdrom&quot;,&amp;stat_buf); // link file My_stat(&quot;/run/systemd/initctl/fifo&quot;,&amp;stat_buf); // fifo file int fd=My_open_with_mode(&quot;test_stat&quot;,O_WRONLY|O_CREAT,S_IRUSR); // create a new file close(fd); My_stat(&quot;test_stat&quot;,&amp;stat_buf); // regular file M_TRACE(&quot;--------- End test_stat_lstat() ---------\n\n&quot;); } ![stat](../imgs/file_dir/stat.JPG) 二、访问测试和文件模式创建屏蔽字 当用open()函数打开一个文件时，内核根据进程的有效用户ID和有效组ID为依据来执行访问权限测试。但是如果你想测试进程的实际用户ID和实际组ID是否能够通过权限测试时，可以用下列两个函数： #include&lt;unistd.h&gt; int access(const char *pathname,int mode); int faccess(int fd,const char*pathname,int mode,int flag); 参数： pathname：文件路径名 mode：指定要测试的模式。 如果要测试文件是否已存在，则mode设为F_OK 如果要测试进程的实际用户ID和实际组ID的权限，则可以为下列常量的按位或 R_OK：测试读权限 W_OK：测试写权限 X_OK：测试执行权限 对于 faccess函数： fd：一个打开目录文件的描述符，或者AT_FDCWD pathname： 如果为绝对路径，则忽略fd参数 如果为相对路径，则相对路径的目录由fd指定。 若fd=AT_FDCWD，则表示相对于当前工作目录 否则相对于fd对于的打开的目录 flag：如果是AT_EACCESS，则访问检查使用进程的有效用户ID和有效组ID，而不是实际用户ID和实际组ID 返回值： 成功：返回0 出错： 返回 -1 文件模式创建屏蔽字：当进程创建一个新的目录或者文件时，会使用文件模式创建屏蔽字。在文件模式创建屏蔽字中为1的位，在文件mode中的相应位一定被关闭。设置进程的文件模式创建屏蔽字的函数为： #include&lt;sys/stat.h&gt; mode_t umask(mode_t cmask); 参数： cmask：要设置的新的文件模式创建屏蔽字 返回值： 成功：旧的文件模式创建屏蔽字 函数未指定失败时返回何值 如果你在通过creat或者open函数指定了mode，那么该mode必须通过文件模式创建屏蔽字的屏蔽之后才是最终新创建的文件的权限模式。umask指定了哪个，哪个权限就被屏蔽了！ shell 有一个umask命令。我们可以通过该命令来设置或者打印当前的文件模式创建屏蔽字 示例：测试 umask和access函数的用法：在main函数中调用test_access_umask 函数： void test_access_umask() { My_access(&quot;/no/exist&quot;,F_OK); // no exist My_access(&quot;/etc/shadow&quot;,W_OK);// can not write My_access(&quot;/home/huaxz1986/APUE&quot;,W_OK); // can write print_new_file_mode(&quot;test_umask1&quot;) ;// old umask //new umask My_umask(S_IRUSR|S_IRGRP|S_IROTH); print_new_file_mode(&quot;test_umask2&quot;) ;// new umask } 可以看到： access函数：对于不存在的文件名访问失败；对没有写权限的名字写访问失败 被创建的文件的访问权限是由文件创建屏蔽字、创建文件时指定的权限二者共同作用的 三、修改文件访问权限和文件所属用户 修改文件的现有的访问权限： #include&lt;sys/stat.h&gt; int chmod(const char*pathname,mode_t mode); int fchmod(int fd,mode_t mode); int fchmodat(int fd,const char*pathname,mode_t mode,int flag); 参数： pathname：文件路径名 mode：文件修改后的权限。 对于 fchmod函数： fd：打开的文件描述符 对于 fchmod函数： fd：一个打开目录文件的描述符，或者AT_FDCWD pathname： 如果为绝对路径，则忽略fd参数 如果为相对路径，则相对路径的目录由fd指定。 若fd=AT_FDCWD，则表示相对于当前工作目录 否则相对于fd对于的打开的目录 flag：如果是!AT_SYMLINK_FOLLOW，则fchmodtat并不跟随符号链接 返回值： 成功：返回0 出错： 返回 -1 参数mode可以是下面常量的按位或：（来自头文件&lt;sys/stat.h&gt; S_ISUID：执行时设置用户ID S_ISGID：执行时设置组ID S_ISVTX：粘着位 S_IRWXU：用户读、写和执行 S_IRUSR：用户读 S_IWUSR：用户写 S_IXUSR：用户执行 S_IRWXG：组读、写和执行 S_IRGRP：用户读 S_IWGRP：用户写 S_IXGRP：用户执行 S_IRWXO：其他读、写和执行 S_IROTH：用户读 S_IWOTH：用户写 S_IXOTH：用户执行 chmod函数更新的只是i节点最近一次被修改的时间。 chmod函数在下列条件下自动清除两个权限位： 如果我们试图设置普通文件的粘着位，而且又没有超级用户权限，则mod中的粘着位被自动关闭。这意味着只有超级用户才能设置普通文件的粘着位 新创建文件的组ID可能不是调用进程所属的组ID，它可能是父目录的组ID 粘着位：如果对一个目录设置了粘着位，则任何对该目录具有写权限的进程都能够在该目录中创建文件。但是：只有满足下列条件之一的用户才能删除或者重命名该目录下的文件： 拥有此文件 拥有此目录 是超级用户 对于未设置粘着位的目录，则只要用户对该目录有写权限，那么就有修改和重命名该目录下其他文件的能力 修改用户的ID和组ID： #include&lt;unistd.h&gt; int chown(const char *pathname,uid_t owner,gid_t group); int fchown(int fd,uid_t owner,gid_t group); int fchownat(int fd,const char *pathname,uid_t owner,gid_t group,int flag); int lchown(const char *pathname,uid_t owner,gid_t group); 参数： pathname：文件路径名 owner：文件修改后的用户ID group：文件修改后的组ID 对于fchown函数： fd：打开的文件描述符，要修改的就是这个文件 对于 fchmod函数： fd：一个打开目录文件的描述符，或者AT_FDCWD pathname： 如果为绝对路径，则忽略fd参数 如果为相对路径，则相对路径的目录由fd指定。 若fd=AT_FDCWD，则表示相对于当前工作目录 否则相对于fd对于的打开的目录 flag：如果是!AT_SYMLINK_FOLLOW，则fchmodtat并不跟随符号链接，修改的是符号链接本身而不是符号链接指向的文件 返回值： 成功： 返回 0 出错： 返回 -1 有两点注意： lchown函数更改的是符号链接本身，而chown遇到符号链接时更改的是符号链接指向的文件 如果这些函数由非超级用户进程调用，则成功返回时，该文件的设置用户ID和设置组ID位都被清除 示例：在 main 函数中调用test_chmod_chown 函数： void test_chmod_chown() { const char *file_name=&quot;test&quot;; Stat buf; My_stat(file_name,&amp;buf); My_chmod(file_name,S_IRWXU); My_chown(file_name,1,1); } ![chmod_chown](../imgs/file_dir/chmod_chown.JPG) 可以看到： - 修改文件所属的用户和组，需要超级用户权限。普通用户无法修改，即使该用户就是该文件的所有者也不行 四、修改文件长度 文件长度：stat.st_size字段存放的是以字节为单位的文件的长度。此字段只对普通文件、目录文件、符号链接才有意义： 对普通文件：其长度就是文件的大小。长度为0表示该文件为空 对目录文件：其长度通常是个整数（如16或者512）的整数倍 对符号链接：其长度是符号链接本身存放的某个文件名的实际字节数（它并不包含字符串的null字节，因为这些字符是存放在文件中，而不是存放在内存中的字符串） 另外stat.st_blksize存放的是对于文件 I/O 较合适的块长度；stat.st_blocks存放的是所分配的块的数量（一个块512字节）。注意： 对于普通文件，可能包含空洞。空洞是由于设置的文件偏移量超过了文件末尾，然后写入了某些数据造成的。对于空洞文件： 空洞文件的存储需要的磁盘块数量可能远小于文件大小。文件大小是文件末尾到文件头的字节数 读取空洞文件的空洞时，对于没有写过的字节位置read返回的是字节0 截断文件：通常可以用带O_TRUNC选项的open()函数来清空一个文件（截断到0）。但是如果希望截断文件使得文件大小为指定字节数，则可以用下列的函数： #include&lt;unistd.h&gt; int truncate(const char*pathname,off_t length); int ftruncate(int fd,off_t length); 参数： pathname：文件路径名 length：文件修改后大小（字节数） fd：打开的文件描述符，要修改的就是这个文件 返回值： 成功： 返回 0 出错： 返回 -1 有两点注意： 若length小于文件的原大小，则修改文件大小之后，文件新的尾端之后的位置不再可以访问 若length大于文件的原大小，则修改文件大小之后，会形成空洞。即从文件原大小新的尾端形成了空洞 示例：在main函数中调用test_truncate_size函数： void test_truncate_size() { M_TRACE(&quot;--------- Begin test_truncate_size() ---------\n&quot;); char buffer[100]; int len; int fd=My_open_with_mode(&quot;test&quot;,O_CREAT|O_TRUNC|O_RDWR,S_IRWXU); My_write(fd,&quot;abcdefg&quot;,8); print_file_size(&quot;test&quot;); // 打印文件大小 //**** 扩张文件 *******// My_truncate(&quot;test&quot;,20); // 扩张文件 My_lseek(fd,0,SEEK_SET); // 读取之前先调整文件读取位置 len=My_read(fd,buffer,20); printf(&quot;Read:&quot;); for (int i=0;i&lt;len;i++) // 打印读取内容 printf(&quot;\t0x%x,&quot;,buffer[i]); printf(&quot;\n&quot;); //**** 截断文件 *******// My_truncate(&quot;test&quot;,5); // 截断文件 My_lseek(fd,0,SEEK_SET); // 读取之前先调整文件读取位置 len=My_read(fd,buffer,5); printf(&quot;Read:&quot;); for (int i=0;i&lt;len;i++) printf(&quot;\t0x%x,&quot;,buffer[i]); printf(&quot;\n&quot;); close(fd); M_TRACE(&quot;--------- End test_truncate_size() ---------\n&quot;); } ![truncate](../imgs/file_dir/truncate.JPG) 可以看到： - 对于文件空洞，它不占用任何磁盘空间；空洞部分读出的内容全为0 - 对于非常小的文件，比如这里的 8 字节文字，磁盘分配了 8个块（4kb）。 五、UNIX文件系统、硬链接、软链接、删除、重命名 UNIX文件系统简介(传统的基于BSD的UNIX文件系统，称作UFS）： 一个磁盘可以划分成一个或者多个分区，每个分区可以包含一个文件系统。每个文件系统包含一些柱面组。每个柱面组包括： 一个 i 节点图：用于指示哪些 i 节点已经被使用，哪些未被使用 一个 块位图：用于指示哪些数据块已经被使用，哪些为被使用 一个 i 节点组。它包含的是许多 i 节点。 一个数据区：存放具体的数据块和目录块 数据区包含两种类型的块： 目录块：它的内容是 &lt;i 节点编号&gt;|&lt;文件名&gt; 这种格式的记录的列表 数据块：它的内容就是具体文件的数据 i 节点是固定长度的记录项，它包含有关文件的大部分信息 每个 i 节点都有一个链接计数，其值是指向 i 节点的目录的项数(这种链接类型称之为硬链接)。只有当该链接计数减少为0时，才可以删除该链接文件（也就是释放该文件占用的数据块）。 在stat结构中，链接计数包含在st_nlink成员中（POSIX常量：LINK_MAX指定了一个文件链接数的最大值） 每个 i 节点包含了文件有关的所有信息：文件类型、文件权限访问位、文件长度和指向文件数据块的指针 stat结构中的大多数信息来自于 i 结点。只有两项重要数据存放在目录项中：文件名、i节点编号 目录项中的 i 节点编号只能指向同一个文件系统中的相应的 i 节点。 因此硬链接不能跨文件系统 当在不更换文件系统的情况下重命名一个文件时，该文件的实际内容并未移动。只需要构造一个指向现有 i 节点的新目录项，并删除来的目录项。此时该 i节点的链接计数不会改变 这就是 mv命令的操作方式 与硬链接对应的概念是软链接。软链接也称作符号链接，它是一种特殊的文件。该文件的实际内容（在数据块中）包含了该符号链接所指向的文件的名字。同时该文件的 i 节点指示了该文件类型是 S_IFLNK，于是系统知道了这个文件是个符号链接。 硬链接直接指向文件的i节点 软链接是对一个文件的间接指针 引入符号链接的原因是为了避开硬链接的一些限制： 硬链接通常要求链接和文件位于同一个文件系统中 只有超级用户才能创建指向目录的硬链接（在底层文件系统支持的情况下） 对于符号链接以及它指向何种类型的文件并没有什么限制。任何用户都可以创建指向目录的符号链接。但是使用符号链接有可能在文件系统中引入循环 对于处理文件和目录的函数，如果传递的是一个符号链接的文件名，则应该注意：函数是否跟随符号链接，即函数是处理符号链接指向的文件，还是处理符号链接本身。 跟随符号链接（即处理符号链接指向的文件）的函数有：access、chdir、chmod、chown、creat、exec、link、open、opendir、pathconf、stat、truncate 不跟随符号链接（即处理符号链接文件本身）的函数有：lchown、lstat、readlink、remove、rename、unlink 一个例外的情况：如果用O_CREAT和O_EXCL选项调用open，此时若参数是个符号链接的文件名，则open出错返回（并不考虑符号链接指向的文件是否存在），同时将errno设为EEXIST 任何一个目录 dirxxx 的硬链接至少为2： 该目录的内容中有一条名为的.记录，该记录的 &lt;i节点编号&gt; 指向dirxxx目录的节点 该目录的父目录的内容中有一条记录，记录的名字dirxxx，记录的 &lt;i节点编号&gt; 指向dirxxx目录的节点 若该目录有子目录。dirxxx 的任何子目录的内容有一条名为..的记录，该记录的 &lt;i节点编号&gt; 指向dirxxx目录的节点 因此父目录中的每个子目录都使得父目录的链接计数加 1 link/linkat函数：创建一个指向现有文件的硬链接 #include&lt;unistd.h&gt; int link(const char *existingpath,const char *newpath); int linkat(int efd,const char*existingpath,int nfd,const char *newpath,int flag); 参数： existingpath：现有的文件的文件名（新创建的硬链接指向它） newpath：新创建的目录项 如果newpath已存在，则返回出错 只创建newpath中的最后一个分量，路径中的其他部分应当已经存在。 假设 newpath为：/home/aaa/b/c.txt，则要求 /home/aaa/b已经存在，只创建c.txt 对于linkat函数： 现有的文件名是通过efd和existingpath指定。 若existingpath是绝对路径，则忽略efd 若 existingpath是相对路径，则： 若 efd=AT_FDCWD，则existingpath是相对于当前工作目录来计算 若 efd是一个打开的目录文件的文件描述符，则existingpath是相对于efd对应的目录文件 新建的文件名是通过nfd和newpath指定。 若newpath是绝对路径，则忽略nfd 若 newpath是相对路径，则： 若 nfd=AT_FDCWD，则newpath是相对于当前工作目录来计算 若 nfd是一个打开的目录文件的文件描述符，则newpath是相对于nfd对应的目录文件 flag：当现有文件是符号链接时的行为： flag=AT_SYMLINK_FOLLOW：创建符号链接指向的文件的硬链接（跟随行为） flag=!AT_SYMLINK_FOLLOW:创建符号链接本身的硬链接（默认行为） 返回值： 成功： 返回 0 失败： 返回 -1 这两个函数创建新目录项并对链接计数加1。创建新目录项和增加链接计数是一个原子操作。 另外，大多数操作系统中，只有超级用户才能创建指向一个目录的硬链接，因为这样做很有可能在文件系统中形成循环。 unlink函数：删除一个现有的目录项 #include&lt;unistd.h&gt; int unlink(const char*pathname); int unlinkat(int fd,const char*pathname,int flag); 参数： pathname：现有的、待删除的目录项的完整路径名。 对于unlinkat函数： 现有的文件名是通过fd和pathname指定。 若pathname是绝对路径，则忽略fd 若 pathname是相对路径，则： 若 fd=AT_FDCWD，则pathname是相对于当前工作目录来计算 若 fd是一个打开的目录文件的文件描述符，则pathname是相对于fd对应的目录文件 flag： flag=AT_REMOVEDIR：可以类似于rmdir一样的删除目录 flag=!AT_REMOVEDIR:与unlink执行同样的操作 返回值： 成功： 返回 0 失败： 返回 -1 为了解除对文件的链接，必须对包含该目录项的目录具有写和执行权限。如果还对该目录设置了粘着位，则对该目录必须具有写权限以及下列三个条件之一： 拥有该文件 拥有该目录 具有超级用户权限 这两个函数删除目录项并对链接计数减1。创建新目录和增加链接计数是一个原子操作。 如果该文件的硬链接数不为0， 则还可以通过其他链接访问该文件的内容 如果该文件的硬链接数为0，而没有进程打开该文件，则该文件的内容才有被删除 如果该文件的硬链接数为0，但是有进程打开了该文件，则该文件的内容不能被删除。当进程关闭文件时，内核会检查打开该文件的进程个数；当这个数量为0，内核再去检查其链接计数。如果链接计数也是0，则就删除该文件的内容。 这个特性常用于创建临时文件，先open,create一个文件，然后立即调用unlink。这样即使程序崩溃，它所创建的临时文件也不会遗留下来 如果删除目录项出错，则不对该文件做任何更改 如果pathname是个符号链接，则unlink删除该符号链接，而不会删除由该符号链接所引用的文件。 如果仅仅给出符号链接的文件名，没有一个函数可以删除由该符号链接所引用的文件 如果文件系统支持，超级用户可以调用unlink，其参数pathname指定一个目录 通常推荐用rmdir函数，其语义更加清晰 link/unlink实例：在main函数中调用test_link_unlink函数 void test_link_unlink() { M_TRACE(&quot;--------- Begin test_link_unlink() ---------\n&quot;); assert(prepare_file(&quot;test&quot;,NULL,0,S_IRWXU)==0); un_prepare_file(&quot;test1&quot;); print_file_link_num(&quot;test&quot;); My_link(&quot;test&quot;,&quot;test1&quot;); My_unlink(&quot;test1&quot;); print_file_link_num(&quot;test&quot;); My_unlink(&quot;test1&quot;); My_unlink(&quot;test&quot;); print_file_link_num(&quot;test&quot;); un_prepare_file(&quot;test&quot;); un_prepare_file(&quot;test1&quot;); M_TRACE(&quot;--------- End test_link_unlink() ---------\n\n&quot;); } 可以看到： test和new_test这两个文件共享一个 i 结点。因此该节点的 硬链接数为2 一旦删除 new_test，则对new_test执行 fstatat失败（因为已经被unlink）。同时test的硬链接数为1 一旦test也被删除，则 i节点被释放。执行unlink失败。 remove函数：解除对一个目录或者文件的链接。 #include&lt;stdio.h&gt; int remove(const char *pathname); 参数 pathname：文件名或者目录名 返回值： 成功：返回0 失败：返回 -1 对于文件，remove功能与unlink相同；对于目录，remove功能与rmdir相同 rename/renameat函数：重命名文件或目录 #inluce&lt;stdio.h&gt; int rename(const char*oldname,const char *newname); int renameat(int oldfd,const char*oldname,int newfd,const char* newname); 参数： oldname：现有的文件名或者目录名 newname：重命名的名字 如果oldname是个文件名，则为该文件或者符号链接重命名。 此时若newname已存在：若newname是个目录则报错；若newname不是个目录：则先将newname目录项删除，然后将oldname重命名为newname 此时若newname不存在：则直接将oldname重命名为newname 如果oldname是个目录名，则为该目录重命名。 此时若newname已存在：若newname是个目录且该目录是个空目录，则先将它删除，然后oldname重命名为newname；若newname是个目录且该目录不是个空目录，则报错；若newname不是个目录，则报错 此时若newname不存在：则直接将oldname重命名为newname oldname 不能是 newname 的前缀。因为重命名时，需要删除oldname 如果oldname或者newname引用的是符号链接，则处理的是符号链接本身，而不是它引用的文件 不能对.和..重命名。即.和..不能出现在oldname和newname的最后部分 若newname和oldname引用同一个文件，则函数不作任何更改而成功返回 对于renameat函数： 现有的文件名或目录名是通过oldfd和oldname指定。 若oldname是绝对路径，则忽略oldfd 若 oldname是相对路径，则： 若 oldfd=AT_FDCWD，则oldname是相对于当前工作目录来计算 若 oldfd是一个打开的目录文件的文件描述符，则oldname是相对于oldfd对应的目录文件 重命名的文件名或目录名是通过newfd和newname指定。 若newname是绝对路径，则忽略newfd 若 newname是相对路径，则： 若 newfd=AT_FDCWD，则newname是相对于当前工作目录来计算 若 newfd是一个打开的目录文件的文件描述符，则newname是相对于newfd对应的目录文件 flag：当现有文件是符号链接时的行为： flag=AT_SYMLINK_FOLLOW：创建符号链接指向的文件的硬链接（跟随行为） flag=!AT_SYMLINK_FOLLOW:创建符号链接本身的硬链接（默认行为） 返回值： 成功： 返回 0 失败： 返回 -1 对于包含oldname以及newname的目录，调用进程必须具有写和执行的权限，因为将同时更改这两个目录。 symlink/symlinkat函数：创建一个符号链接 #include&lt;unistd.h&gt; int symlink(const char*actualpath,const char *sympath); int symlinkat(const char*actualpath,int fd,const char*sympath); 参数： actualpath：符号链接要指向的文件或者目录（可能尚不存在） sympath：符号链接的名字 二者不要求位于同一个文件系统中 对于`symlinkat`函数： - 符号链接的名字是通过`fd`和`sympath`指定。 - 若`sympath`是绝对路径，则忽略`fd` - 若 `sympath`是相对路径，则： - 若 `fd=AT_FDCWD`，则`sympath`是相对于当前工作目录来计算 - 若 `fd`是一个打开的目录文件的文件描述符，则`sympath`是相对于`fd`对应的目录文件 - 返回值： - 成功： 返回 0 - 失败： 返回 -1 readlink/readlinkat函数：打开符号链接本身 open函数是跟随链接的，即打开符号链接指向的文件 #include&lt;unistd.h&gt; ssize_t readlink(const char *restrict pathname,char *restrict buf,size_t bufsize); ssize_t readlinkat(int fd, const char* restrict pathname,char *restrict buf, size_t bufsize); 参数： pathname：符号链接的名字 buf：存放符号链接内容的缓冲区 bufsize：期望读入缓冲区的字节数 对于readlinkat函数： 符号链接的名字是通过fd和pathname指定。 若pathname是绝对路径，则忽略fd 若 pathname是相对路径，则： 若 fd=AT_FDCWD，则pathname是相对于当前工作目录来计算 若 fd是一个打开的目录文件的文件描述符，则pathname是相对于fd对应的目录文件 返回值： 成功： 返回实际上读取的字节数 失败： 返回 -1 readlink和readlinkat函数组合了open、read、close函数的所有操作。 注意：读入buf中的符号链接的内容，并不是以null字节终止。 以null字节终止的是内存中的字符串这种数据结构。而符号链接文件的内容是简单的字符序列，并不是字符串。 符号链接示例：在main函数中调用test_symlink_readlink函数： ```void test_symlink_readlink(){M_TRACE(“——— Begin test_symlink_readlink() ———\n”);assert(prepare_file(“test”,”abcdefg0123456”,14,S_IRWXU)==0); // 准备 test 文件print_file_type(“test”); // 查看 test 文件类型 My_symlink(“test”,”test_symlink”); // 创建软连接 test_symlink 到 testprint_file_type(“test_symlink”); // 查看 test_symlink 文件类型print_link_file(“test_symlink”); // 由于open 是链接跟随，所以这里打印 test 的内容 char buffer[128];My_readlink(“test_symlink”,buffer,128); un_prepare_file(“test”); // 删除 test 文件un_prepare_file(“test_symlink”); // 删除 test_symlink 文件M_TRACE(“——— End test_symlink_readlink() ———\n\n”);} ``` ![symlink](../imgs/file_dir/symlink.JPG) 可以看到： - 符号链接文件的内容就是它链接到的那个文件的绝对路径名，其中路径名字符序列不包含 `null`字节 - 在 `ubuntu 16.04`中，经多次测试，符号链接文件和普通文件的 `st_mode`完全相同。 - `open`一个链接文件，然后`read`时发现读文件出错，原因是文件描述符有误（实际上打开文件时返回的文件描述符没问题） 六、修改文件的时间 文件的时间：在stat结构中存放着文件的三个时间： st_atim：文件数据的最后访问时间 st_mtim：文件数据的最后修改时间 st_ctim： i 节点状态的最后更改时间 关于这三个时间： 有很多操作，比如修改文件权限，修改文件的所有者等操作，他们只修改 i 节点状态（只影响st_ctim），但是并不修改文件数据，也并不访问文件数据 系统并不维护对 i 节点的最后访问时间。因此对于 access函数和 stat函数，他们并不修改这三个时间中的任何一个 创建一个文件不仅影响了文件本身的这三个时间，也会影响该文件目录的这三个时间 futimens/utimensat/utimes函数：修改文件的访问和修改时间 #include&lt;sys/stat.h&gt; int futimens(int fd,const struct timespec times[2]); int utimensat(int fd,const char*path,const struct timespec times[2],int flag); #include&lt;sys/time.h&gt; int utimes(const char*pathname,const struct timeval times[2]); 参数： 对于 futimens和 utimensat函数： times：指向待修改文件的指定的文件数据访问和文件数据修改时间的指针。 对于C语言，参数中的数组自动转换为指向数组的指针 这两个时间是日历时间，是自 1970:01:01–00:00:00 以来经历的秒数。不足秒的部分用纳秒表示 数组的第一个元素指定 st_atim；数组的第二个元素指定 st_ctim times可以按照下列四种方式之一指定： times为空指针： 则将文件的数据访问时间和文件数据修改时间设置为当前时间 此时要求进程的有效用户ID等于该文件所有者的ID；或者进程对该文件有写权限；或者进程是个超级用户进程 times参数是指向timespec数组的指针： 若数组的任何一个元素的tv_nsec字段为 UTIME_NOW，则相应的时间戳就设置为当前时间，忽略相应的tv_sec字段 此时要求进程的有效用户ID等于该文件所有者的ID；或者进程对该文件有写权限；或者进程是个超级用户进程 若数组的任何一个元素的tv_nsec字段为 UTIME_OMIT，则相应的时间戳保持不变，忽略相应的tv_sec字段 若两个时间戳都忽略，则不需要任何权限限制 若数组的任何一个元素的tv_nsec字段为不是上面的两种之一，则相应的时间戳就设置为相应的tv_sec和tv_nsec字段 此时要求进程的有效用户ID等于该文件所有者的ID；或者进程是个超级用户进程（对文件只有写权限是不够的） 对于 utimes函数： pathname：文件的路径名 times：指向timeval数组的指针。 timeval结构用秒和微秒表示。 struct timeval{ time_t tv_sec;//秒 long tv_usec; //微秒 }; 对于 futimens函数： fd：待修改文件的打开的文件描述符 对于 utimensat函数： 待打开文件的名字是通过fd和path指定。 若path是绝对路径，则忽略fd 若 path是相对路径，则： 若 fd=AT_FDCWD，则path是相对于当前工作目录来计算 若 fd是一个打开的目录文件的文件描述符，则path是相对于fd对应的目录文件 flag：若待修改的文件是符号链接 如果为!AT_SYMLINK_FOLLOW，则符号链接本身的时间就会被修改 默认情况下，修改的是符号链接指向的文件的时间（跟随行为） 返回值： 成功： 返回 0 失败： 返回 -1 我们不能对st_ctim（i节点最后被修改时间）指定一个值。这个时间是被自动更新的。 示例：在 main函数中调用test_utimes函数： void test_utimes() { M_TRACE(&quot;--------- Begin test_utimes() ---------\n&quot;); assert(prepare_file(&quot;test&quot;,NULL,0,S_IRWXU)==0); // 准备 test 文件 print_file_time(&quot;test&quot;); sleep(2); My_access(&quot;test&quot;,F_OK); // 访问文件，但不修改文件 print_file_time(&quot;test&quot;); sleep(2); My_chmod(&quot;test&quot;,S_IRUSR|S_IWUSR);// 修改文件状态 print_file_time(&quot;test&quot;); struct timeval times[2]; times[0].tv_usec=10; times[1].tv_sec=10; times[1].tv_usec=10; My_utimes(&quot;test&quot;,times); un_prepare_file(&quot;test&quot;); // 删除 test 文件 M_TRACE(&quot;--------- End test_utimes() ---------\n\n&quot;); } ![utimes](../imgs/file_dir/utimes.JPG) 可以看到： - `st_ctim`是由系统自动维护的，程序员无法手动指定 七、目录操作 mkdir/mkdirat函数创建一个空目录： #include&lt;sys/stat.h&gt; int mkdir(const char*pathname,mode_t mode); int mkdirat(int fd,const char *pathname,mode_t mode); 参数： pathname:被创建目录的名字 mode:被创建目录的权限 对于 mkdirat，被创建目录的名字是由fd和pathname共同决定的。 若pathname是绝对路径，则忽略fd 若 pathname是相对路径，则： 若 fd=AT_FDCWD，则pathname是相对于当前工作目录来计算 若 fd是一个打开的目录文件的文件描述符，则pathname是相对于fd对应的目录文件 返回值： 成功： 返回0 失败： 返回 -1 注意： 他们创建的目录是空目录。 对于目录，通常至少要设置一个执行权限位，以允许访问该目录中的文件名 rmdir函数：删除一个空目录 #include&lt;unistd.h&gt; int rmdir(const char *pathname); 参数： pathname：待删除的空目录的名字 返回值： 成功： 返回0 失败： 返回 -1 如果调用此函数使得目录的链接计数为0时： 如果此时没有其他进程打开该目录，则释放由此目录占用的空间。 如果此时有一个或者多个进程打开此目录，则在此函数返回时删除最后一个链接以及 .和..项，直到最后一个打开该目录的进程关闭该目录时此目录才真正被释放。 此时，在此目录中不能再创建新文件。 读、写目录：对于某个目录具有访问权限的任何用户都可以读该目录。但是为了防止文件系统产生混乱，只有内核才能写目录。 一个目录的写权限和执行权限位决定了在该目录中能否创建新文件以及删除文件，它们并不能写目录本身 #include&lt;dirent.h&gt; DIR *opendir(const char *pathname); DIR *fdopendir(int fd); struct dirent *readdir(DIR *dp); void rewinddir(DIR *dp); int closedir(DIR *dp); long telldir(DIR *dp); void seekdir(DIR *dp,long loc); 各个函数： opendir：打开目录。 参数：pathname：目录的名字 返回值：成功返回目录指针；失败返回 NULL fdopendir：打开目录。 参数：fd：目录文件的文件描述符 返回值：成功返回目录指针；失败返回 NULL readdir：读取目录 参数： dp：目录指针 返回值： 成功则返回目录项的指针；失败返回 NULL rewinddir:将目录的文件偏移量清零（这样下次读取就是从头开始） 参数：dp：目录指针 closedir：关闭目录。 参数：dp：目录指针 返回值：成功返回 0 ；失败返回 -1 telldir：返回目录的文件偏移量 参数：dp：目录指针 返回值：成功返回目录的文件偏移量 ；失败返回 -1 seekdir：设置目录的当前位置 参数：dp：目录指针；loc：要设定的文件偏移量 对于 DIR结构，它是一个内部结构。起作用类似于 FILE结构。对于dirent结构，它是定义在&lt;dirent.h&gt;头文件中。其与具体操作系统相关。但是它至少定义了两个成员： struct dirent{ ino_t d_ino; // i 节点编号 char d_name[];// 以 null 结尾的文件名字符串 } d_name项的大小并没有指定，但必须保证它能包含至少 NAME_MAX个字节（不包含终止null字节） 目录中各目录项的顺序与操作系统有关。它们通常不按照字母顺序排列 当前工作目录：每个进程都有一个当前工作目录。此目录是搜索所有相对路径名的起点。 当前工作目录是本进程的一个属性 与当前工作目录相关的有三个函数： #include&lt;unistd.h&gt; int chdir(const char *pathname); int fchdir(int fd); char *getcwd(char *buf,size_t size); 各个函数： chdir：更改当前工作目录。 参数：pathname：将该目录作为当前工作目录 返回值：成功返回 0 ；失败返回 -1 fchdir：更改当前工作目录。 参数：fd：将该 fd 文件描述符对应的目录作为当前工作目录 返回值：成功返回 0 ；失败返回 -1 getcwd：返回当前工作目录的名字 参数： buf：缓冲区地址；size：缓冲区长度。这两个参数决定了当前工作目录名字字符串存放的位置。 缓冲区必须足够长以容纳绝对路径名加上一个终止null字节。否则返回出错。 返回值： 成功则返回 buf；失败返回 NULL 示例： 在main函数中调用 test_dir_operations 函数： void test_dir_operations() { M_TRACE(&quot;--------- Begin test_dir_operations() ---------\n&quot;); //*** 创建目录 **** My_mkdir(&quot;test&quot;,S_IRWXU); My_mkdir(&quot;test/test1&quot;,S_IRWXU); //*** 创建文件 prepare_file(&quot;test/tfile_1&quot;,NULL,0,S_IRWXU); prepare_file(&quot;test/tfile_2&quot;,NULL,0,S_IRWXU); prepare_file(&quot;test/tfile_3&quot;,NULL,0,S_IRWXU); prepare_file(&quot;test/test1/tfile_11&quot;,NULL,0,S_IRWXU); prepare_file(&quot;test/test1/tfile_22&quot;,NULL,0,S_IRWXU); prepare_file(&quot;test/test1/tfile_33&quot;,NULL,0,S_IRWXU); print_dir(&quot;test&quot;); print_cwd(); My_chdir(&quot;test&quot;); print_cwd(); My_chdir(&quot;../&quot;); // 切换回来，否则后面的删除文件都会失败（因为都是相对路径） print_cwd(); //***** 清理 My_rmdir(&quot;test&quot;); // 目录非空，删除失败！ un_prepare_file(&quot;test/tfile_1&quot;); un_prepare_file(&quot;test/tfile_2&quot;); un_prepare_file(&quot;test/tfile_3&quot;); un_prepare_file(&quot;test/test1/tfile_11&quot;); un_prepare_file(&quot;test/test1/tfile_22&quot;); un_prepare_file(&quot;test/test1/tfile_33&quot;); My_rmdir(&quot;test/test1&quot;); // 必须非空才能删除成功 My_rmdir(&quot;test&quot;); // 必须非空才能删除成功 M_TRACE(&quot;--------- End test_dir_operations() ---------\n\n&quot;); } ![dir_function](../imgs/file_dir/dir_function.JPG) %]]></content>
      <categories>
        <category>apue</category>
      </categories>
      <tags>
        <tag>apue,文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[标准IO库]]></title>
    <url>%2F2017%2F12%2F04%2F%E6%A0%87%E5%87%86IO%E5%BA%93%2F</url>
    <content type="text"><![CDATA[流和 FILE对象 标准IO库与文件IO区别： 标准IO库处理很多细节，如缓冲区分片、以优化的块长度执行IO等。 文件IO函数都是围绕文件描述符进行。首先打开一个文件，返回一个文件描述符；后续的文件IO操作都使用该文件描述符 标准IO库是围绕流进行的。当用标准IO库打开或者创建一个文件时，就有一个内建的流与之相关联 标准IO库的函数很多都是以 f开头，如fopen、fclose 对于ASCII字符集，一个字符用一个字节表示；对于国际字符集，一个字符可以用多个字节表示。 标准IO文件流可用于单字节或者多字节字符集。流的定向决定了所处理的字符是单字节还是多字节的。 当一个流最初被创建时，它并没有定向。 若在未定向的流上使用一个多字节IO函数，则将该流的定向设置为宽定向的（即处理多字节） 若在未定向的流上使用一个单字节IO函数，则将该流的定向设置为字节定向的（即处理单字节） 只有两个函数可以改变流的定向 freopen函数清除一个流的定向 fwide函数设置流的定向 fwide函数：设置流的定向 #include&lt;stdio.h&gt; #include&lt;wchar.h&gt; int fwide(FILE *fp,int mode); 参数： fp：FILE文件对象的指针 mode：流的定向模式。 如果mode是负数，则函数试图使指定的流为字节定向（并不保证修改成功，因为fwide并不改变已定向流的定向） 如果mode是正数，则函数试图使指定的流为宽定向的（并不保证修改成功，因为fwide并不改变已定向流的定向） 如果mode为0，则函数不试图设置流的定向，而直接返回该流定向的值 返回值： 若流是宽定向的，返回正值 若流是字节定向的，返回负值 若流是未定向的，返回0 这里并没有函数失败的情况 注意： fwide并不改变已定向流的定向。 如果fp是无效流，由于fwide从返回值无法得知函数执行成功还是失败。那么我们必须采用这个方法：首先在调用fwide之前清除errno。然后在fwide之后检查errno的值。通过errno来检测fwide执行成功还是失败。 FILE指针：当使用fopen函数打开一个流时，它返回一个执行FILE对象的指针。该对象通常是一个结构，包含了标准IO库为管理该流所需要的所有信息，包括： 用于实际IO的文件描述符 指向用于该流缓冲区的指针 该流缓冲区的长度 当前在缓冲区中的字符数 出错标志 应用程序没必要检验FILE对象，只需要将FILE指针作为参数传递给每个标准IO函数。 操作系统对每个进程与定义了3个流，并且这3个流可以自动地被进程使用，他们都是定义在&lt;stdio.h&gt;中： 标准输入：预定义的文件指针为stdin，它内部的文件描述符就是STDIN_FILENO 标准输出：预定义的文件指针为stdout，它内部的文件描述符就是STDOUT_FILENO 标准错误：预定义的文件指针为stderr，它内部的文件描述符就是STDERR_FILENO 标准IO库提供缓冲的目的是：尽量减少使用read和write调用的次数。标准IO库对每个IO流自动地进行缓冲管理，从而避免了程序员需要手动管理这一点带来的麻烦。 标准IO库提供了三种类型的缓冲： 全缓冲：此时在标准IO缓冲区被填满后，标准IO库才进行实际的IO操作。 行缓冲：此时当输入和输出中遇到换行符时，标准IO库执行实际的IO操作。但是注意： 只要填满了缓冲区，即使还没有写一个换行符，也立即进行IO操作 任何时候只要通过标准IO库，从一个不带缓冲的流或者一个行缓冲的流得到输入数据，则会冲洗所有行缓冲输出流。(即要缓冲输入，先冲洗输出缓冲) 不带缓冲：标准IO库不对字符进行缓冲存储。此时任何IO都立即执行实际的IO操作。 另外： 在一个流上执行第一次IO操作时，相关标准的IO函数通常调用 malloc获取使用的缓冲区 缓冲区可以由标准的IO操作自动地冲洗（如，当填满一个缓冲区时），也可以手动调用fflush函数冲洗一个流。 ISO C 要求下来缓冲特征： 当且仅当标准输入和标准输出并不指向交互式设备时，他们才是全缓冲的 标准错误绝不会是全缓冲的。 很多操作系统默认使用下列类型的缓冲： 标准错误stderr时不带缓冲的 标准输入stdin和输出stdout：若是指向终端设备的流，则是行缓冲的；否则是全缓冲的 setbuf/setvbuf函数：设置流的缓冲类型 #include&lt;stdio.h&gt; void setbuf(FILE *restrict fp,char *restrict buf); int setvbuf(FILE *restrict fp,char* restrict buf,int mode,size_t size); 参数： fp：被打开的文件对象的指针 buf：一个缓冲区的指针。缓冲区长度必须为BUFSIZ常量（该常量定义在&lt;stdio.h&gt;中）。 如果buf为NULL，则是关闭缓冲 如果buf非NULL，则通常设定该流为全缓冲的。但若该流与一个设备终端相关，则设为行缓冲的 对于setvbuf函数： buf：一个缓冲区的指针。缓冲区长度为size。 若buf为NULL，且mode为_IONBF：则该流为不带缓冲的。因为此时忽略buf和size参数 若buf为NULL，且mode不是_IONBF：则标准IO库将自动为该流分片合适长度的缓冲区（即BUFSIZE长度），然后设定该流为指定的mode mode：指定缓冲类型。可以为： _IOFBF：全缓冲。 _IOLBF：行缓冲 _IONBF：不带缓冲。此时忽略buf和size参数 size：缓冲的长度 返回值： 成功： 返回0 失败： 返回非0(并不是-1) 注意： 如果在一个函数内分配一个自动变量类型的标准IO缓冲区，则从该函数返回之前，必须关闭流。因此自动变量是栈上分配，函数返回之后自动变量被销毁 某些操作系统将缓冲区的一部分存放它自己的管理操作信息，因此可以存放在缓冲区中的实际数据字节数将少于size 通常推荐利用操作系统自动选择缓冲区长度并自动分配缓冲区。在这种情况下若关闭此流，则标准IO库会自动释放缓冲区 fflush函数：手动冲洗一个流 #include&lt;stdio.h&gt; int fflush(FILE *fp); 参数： fp：被打开的文件对象的指针 返回值： 成功：返回0 失败：返回EOF (并不是-1) 该函数会使得该流所有未写的数据都被传送至内核。当fp为NULL时，此函数将导致所有输出流被冲洗。 冲洗是双向的：输出流 —&gt; 内核 —&gt; 磁盘或者终端； 输入流—&gt; 用户缓冲区 冲洗并不是立即写到磁盘文件中。冲洗只是负责数据传到内核 打开关闭流 fopen/freopen/fdopen函数：打开标准IO流 #include&lt;stdio.h&gt; FILE *fopen(const char*restrict pathname,const char*restrict type); FILE *freopen(const char*restrict pathname,const char*restrict type,\ FILE *restrict fp); FILE *fdopen(int fd,const char*type); 参数： type：指定对该IO流的读写方式： &quot;r&quot;或者&quot;rb&quot;：为读打开 &quot;w&quot;或者&quot;wb&quot;：写打开。若文件存在则把文件截断为0长；若文件不存在则创建然后写 &quot;a&quot;或者&quot;ab&quot;：追加写打开；若文件存在每次都定位到文件末尾；若文件不存在则创建然后写 &quot;r+&quot;或者&quot;r+b&quot;或者&quot;rb+&quot;：为读和写打开 &quot;w+&quot;或者&quot;w+b&quot;或者&quot;wb+&quot;：若文件存在则文件截断为0然后读写；若文件不存在则创建然后读写 &quot;a+&quot;或者&quot;a+b&quot;或者&quot;ab+&quot;：若文件存在则每次都定位到文件末尾然后读写；若文件不存在则创建然后读写 其中b用于区分二进制文件和文本文件。但是由于UNIX内核并不区分这两种文件，所以在UNIX环境中指定b并没有什么卵用 创建文件时，无法指定文件访问权限位。POSIX默认要求为：S_IRUSR|S_IWUSR|S_IRGRP|S_IWGRP|S_IROTH|S_IWOTH 对于 fopen函数： pathname：待打开文件的路径名对于 freopen函数： pathname：待打开文件的路径名 fp：在指定的流上打开文件。若fp已经打开，则先关闭该流；若fp已经定向，则清除该定向。 对于 fdopen函数： fd：打开文件的文件描述符 对于fopen，type意义稍微有点区别。因为该描述符已经被打开，所以fdopen为写而打开并不截断该文件。另外该文件既然被打开并返回一个文件描述符，则它一定存在。因此标准 IO追加写方式也不能创建文件 返回值： 成功： 返回文件指针 失败： 返回NULL 这几个函数的常见用途： fopen常用于打开一个指定的文件，返回一个文件指针 freopen常用于将一个指定的文件打开为一个预定义的流（标准输入、标准输出或者标准错误） fdopen常用于将文件描述符包装成一个标准IO流。因为某些特殊类型的文件（如管道、socket文件）不能用fopen打开，必须先获取文件描述符，然后对文件描述符调用fdopen。 注意：当以读和写类型打开一个文件时(type中带+号的类型)，有下列限制： 如果写操作后面没有fflush,fseek,fsetpos,rewind操作之一，则写操作后面不能紧跟读操作 如果读操作后面没有fseek,fsetpos,rewind操作之一，也没有到达文件末尾，则在读操作之后不能紧跟写操作 注意：按照系统默认，流被打开时是全缓冲的。但是如果流引用的是终端设备，则安装系统默认，流被打开时是行缓冲的。 fclose：关闭一个打开的流 #include&lt;stdio.h&gt; int fclose(FILE *fp); 参数： fp：待关闭的文件指针 返回值： 成功： 返回 0 失败： 返回 -1 在该文件被关闭之前： fclose会自动冲洗缓冲中的输出数据 缓冲区中的输入数据被丢弃 若该缓冲区是标准IO库自动分配的，则释放此缓冲区 当一个进程正常终止时（直接调用exit函数，或者从main函数返回）： 所有带未写缓存数据的标准IO流都被冲洗 所有打开的标准IO流都被关闭 示例:在 main函数中调用 test_fopen_fwide_setvbuf函数： void test_fopen_fwide_setvbuf() { M_TRACE(&quot;--------- Begin test_fopen_fwide_setvbuf() ---------\n&quot;); assert(prepare_file(&quot;test&quot;,NULL,0,S_IRWXU)==0); My_fwide(stdin,0); //打印 stdin 的流向 My_fwide(stdout,0); //打印 stdout 的流向 My_fwide(stderr,0); //打印 stderr 的流向 print_FILE(stdin); //打印 stdin 结构 print_FILE(stdout); //打印 stdout 结构 print_FILE(stderr); //打印 stderr 结构 FILE *fp=My_fopen(&quot;test&quot;,&quot;r+&quot;); if(NULL!=fp) { My_fwide(fp,0); //打印 fp 的流向 My_fwide(fp,-1); //设置 fp 为字节流 然后打印 fp 的流向 My_fwide(fp,1); //无法修改已定向的流 print_FILE(fp); //**** 设置不同的缓冲 ****// set_full_buf(fp); print_FILE(fp); set_line_buf(fp); print_FILE(fp); set_no_buf(fp); print_FILE(fp); fclose(fp); //关闭流 } un_prepare_file(&quot;test&quot;); M_TRACE(&quot;--------- End test_fopen_fwide_setvbuf() ---------\n\n&quot;); } 可以看到： 三个标准IO流的文件描述符依次为 0、1、2 未被使用的流不会分配缓冲，因此stdin、stderr的缓冲区地址是 NULL。刚被创建的流的缓冲区地址也是NULL。 未被使用的流是为定向的。因此stdin、stderr是未定向的。刚被创建的流的也是未定向的 对已经定向的流设置流向，并不会改变流的方向。但是也不报告失败。 未分配缓冲区的流，与非缓冲流不是一个概念。非缓冲流是分配了缓冲区的，它的缓冲区长度为1。而未分配缓冲区的流，其缓冲区是无效待分配的。 读写流 一旦打开了流，可以在3中不同类型的非格式化IO中选择，对流进行读、写操作： 每次一个字符的IO。一次读、写一个字符。若流是带缓冲的，则标准IO函数处理所有缓冲 每次一行的IO。一次读、写一行。每一行都以一个换行符终止 二进制IO。每次IO读、写某种数量的对象。 格式化IO由printf族函数完成 getc/fgetc/getchar函数：一次读一个字符： #include&lt;stdio.h&gt; int getc(FILE*fp); int fgetc(FILE*fp); int getchar(void); 参数： fp：打开的文件对象指针 返回值： 成功：则返回下一个字符 到达文件尾端：返回EOF 失败：返回EOF 注意： getchar()等价于getc(stdin)。它从标准输入中读取一个字符 getc和fgetc的区别在于：getc可能通过宏定义来实现，而fgetc不能实现为宏。因此： getc的参数不应该是具有副作用的表达式，因为它可能被计算多次 fgetc可以得到其地址，这就允许将fgetc的地址作为参数传递。而getc不行 调用fgetc所需的时间可能比调用getc长，因为函数调用所需时间通常比调用宏长 这三个函数在返回下一个字符时，将unsigned char类型转换成了int类型。 因为需要通过返回EOF来标记到达末尾或者出错。而EOF通常是常量 -1 。所以需要返回 int ferror/feof函数：查看是读文件出错，还是到达读文件遇到尾端 #include&lt;stdio.h&gt; int ferror(FILE *fp); int feof(FILE *fp); 参数： fp：打开的文件对象指针 返回值： 若条件为真：则返回非 0 若条件为假： 则返回 0 当读流返回EOF时，我们可能不清楚到底是遇到错误，还是读到了文件尾端。此时必须调用ferror或者feof来区别这两种情况。 clearerr函数：清除文件出错标志和文件结束标志 #include&lt;stdio.h&gt; void clearerr(FILE *fp) 参数： fp：打开的文件对象指针 在大多数操作系统中，每个流在FILE对象中维护了两个标志： 出错标志 文件结束标志 调用clearerr函数可以清除这两个标志 ungetc函数：将字符压回流中 #include&lt;stdio.h&gt; int ungetc(int c,FILE *fp); 参数： c：待压入字符转换成的整数值 fp：打开的文件对象指针 返回值： 成功：则返回 c 失败：返回EOF 注意： 若根据某个序列向流中压入一串字符，则再从该流中读取的字符序列是逆序的。即最后压入的字符最先读出 可以执行任意次数的压入单个字符，但是不支持一次压入多个字符 不能压入 EOF。但是当已经读到文件尾端时，支持压入一个字符，此时ungetc会清除该流的文件结束标志 ungetc通常用于这样的情形：正在读取一个输入流，然后需要根据某个字符串（标记字符串）来对输入进行切分。那么我们就需要先看一看下一个字符，来决定如何处理当前字符。此时需要方便的将刚查看的字符回送。 ungetc只是将字符压入流缓冲区中，并没有压入底层的磁盘文件或者操作系统内核中 putc/fputc/putchar函数：一次写一个字符 #include&lt;stdio.h&gt; int putc(int c,FILE*fp); int fputc(int c,FILE*fp); int putchar(int c); 参数： c：待写字符转换成的整数值 fp：打开的文件对象指针 返回值： 成功：则返回 c 失败：返回EOF 注意： putchar(c)等价于putc(c,stdout)。它向标准输出中写一个字符 putc和fputc的区别在于：putc可能通过宏定义来实现，而fputc不能实现为宏 fgets/gets函数：一次读一行字符： #include&lt;stdio.h&gt; char *fgets(char *restrict buf,int n, FILE* restrict fp); char *gets(char *buf); 参数： buf：存放读取到的字符的缓冲区地址 对于 fgets函数： n：缓冲区长度 fp：打开的文件对象指针 返回值： 成功：则返回buf 到达文件尾端：返回NULL 失败：返回NULL 注意： 对于fgets函数，必须指定缓冲区的长度n。该函数一直读到下一个换行符为止，但是不超过n-1个字符。 无论读到多少个字符，缓冲区一定以null字节结尾 若某一行包括换行符超过 n-1个字节，则fgets只返回一个不完整的行；下次调用fgets会继续读该行 对于gets函数，从标准输入总读取字符。由于无法指定缓冲区的长度，因此很可能造成缓冲区溢出漏洞。故该函数不推荐使用 对于发生错误和读到末尾，都是返回NULL fputs/puts函数：一次写一行字符： #include&lt;stdio.h&gt; int fputs(const char* restrict str,FILE*restrict fp); int puts(const char*str); 参数： str：待写的字符串 fp：打开的文件对象指针 返回值： 成功：则返回非负值 失败：返回EOF 注意： fputs和puts都是将一个以null字节终止的字符串写到流中，末尾的null字符不写出！。字符串不要求以换行符结尾！ puts将字符串写到标准输出，末尾的null字符不写出！但是puts随后又将一个换行符写到标准输出中！。而fputs不会自动添加换行符。 虽然puts是安全的，但是我们也是要避免使用它，以免要记住它在最后是否添加了一个换行符。 fread/fwrite函数：执行二进制读写IO #include&lt;stdio.h&gt; size_t fread(void *restrict ptr,size_t size,size_t nobj,FILE *restrict fp); size_t fwrite(const void*restrict ptr,size_t size,size_t nobj,FILE *restrict fp); 参数： ptr:存放二进制数据对象的缓冲区地址 size：单个二进制数据对象的字节数（比如一个struct的大小） nobj：二进制数据对象的数量 fp：打开的文件对象指针 返回值： 成功或失败： 读/写的对象数 对于读：如果出错或者到达文件尾端，则此数字可以少于nobj。此时应调用ferror或者feof来判断究竟是那种情况 对于写：如果返回值少于nobj，则出错 使用二进制IO的基本问题是：它只能用在读取同一个操作系统上已写的数据。如果跨操作系统读写，则很可能工作异常。因为： 同一个struct，可能在不同操作系统或者不同编译系统中，成员的偏移量不同 存储多字节整数和浮点数的二进制格式在不同的操作系统中可能不同 有三种方法定位标准IO流 通过 ftell/fseek函数： #include&lt;stdio.h&gt; long ftell(FILE *fp); 参数：fp：打开的文件对象指针 返回值： 成功：返回当前文件位置指示 失败：返回 -1L 若是二进制文件，则文件指示器是从文件开始位置度量的，并以字节为度量单位。ftell就是返回这种字节位置。 #include&lt;stdio.h&gt; int fseek(FILE *fp,long offset,int whence); 参数： fp：打开的文件对象指针 offset：偏移量。其解释依赖于whence whence：偏移量的解释方式： SEEK_SET常量：表示从文件的起始位置开始 SEEK_CUR常量：表示从文件的当前位置开始 SEEK_END常量：表示从文件的尾端开始 返回值： 成功：返回 0 失败：返回 -1 原书说，对文本文件和二进制文件，fseek定位有某些限制。但是经过在ubuntu 16.04上测试，可以任意定位。并没有要求说不能定位到文件尾端，以及必须用SEEK_SET等诸多限制。 #include&lt;stdio.h&gt; void rewind(FILE *fp); 参数： fp：打开的文件对象指针 rewind函数将一个流设置到文件的起始位置 通过 ftello/fseeko函数：除了偏移量类型为off_t而不是long以外，ftello/fseeko与ftell/fseek相同 #include&lt;stdio.h&gt; off_t ftello(FILE *fp); 参数：fp：打开的文件对象指针 返回值： 成功：返回当前文件位置指示 失败：返回 (off_t)-1 #include&lt;stdio.h&gt; int fseeko(FILE *fp,off_t offset,int whence); 参数： fp：打开的文件对象指针 offset：偏移量。其解释依赖于whence whence：偏移量的解释方式： SEEK_SET常量：表示从文件的起始位置开始 SEEK_CUR常量：表示从文件的当前位置开始 SEEK_END常量：表示从文件的尾端开始 返回值： 成功：返回 0 失败：返回 -1 fgetpos/fsetpos函数：由 ISO C 引入 #include&lt;stdio.h&gt; int fgetpos(FILE *restrict fp,fpos_t *restrict pos); int fsetpos(FILE * fp,const fpos_t * pos); 参数： fp：打开的文件对象指针 pos：存放偏移量的缓冲区 返回值： 成功： 返回 0 失败： 返回非 0 示例:在main函数中调用test_get_put_seek 函数： void test_get_put_seek() { M_TRACE(&quot;--------- Begin test_get_put_seek() ---------\n&quot;); assert(prepare_file(&quot;test_char&quot;,NULL,0,S_IRWXU)==0); assert(prepare_file(&quot;test_line&quot;,NULL,0,S_IRWXU)==0); assert(prepare_file(&quot;test_binary&quot;,NULL,0,S_IRWXU)==0); FILE *file_char=My_fopen(&quot;test_char&quot;,&quot;r+&quot;); FILE *file_line=My_fopen(&quot;test_line&quot;,&quot;r+&quot;); FILE *file_binary=My_fopen(&quot;test_binary&quot;,&quot;rb+&quot;); if((file_char!=NULL) &amp;&amp; (file_line!=NULL) &amp;&amp; (file_binary!=NULL)) { printf(&quot;***** test read write char*****\n&quot;); _test_read_write_char(file_char); printf(&quot;\n\n***** test read write str*****\n&quot;); _test_read_write_line(file_line); printf(&quot;\n\n***** test read write binary*****\n&quot;); _test_read_write_binary(file_binary); } //*** 关闭文件 ***// if(file_char!=NULL) fclose(file_char); if(file_line!=NULL) fclose(file_line); if(file_binary!=NULL) fclose(file_binary); un_prepare_file(&quot;test_char&quot;); un_prepare_file(&quot;test_line&quot;); un_prepare_file(&quot;test_binary&quot;); M_TRACE(&quot;--------- End test_get_put_seek() ---------\n\n&quot;); } 格式化IO 格式化输出函数： #include&lt;stdio.h&gt; int printf(const char *restrict format,...); int fprintf(FILE *restrict fp,const char*restrict format,...); int dprintf(int fd,const char *restrict format,...); int sprintf(char *restrict buf,const char*restrict format,...); int snprintf(char *restrict buf,size_t n,const char *restrict format,...); 参数： format,...：输出的格式化字符串 对于fprintf： fp：打开的文件对象指针。格式化输出到该文件中 对于dprintf： fd：打开文件的文件描述符。格式化输出到该文件中 对于sprintf: buf：一个缓冲区的指针。格式化输出到该缓冲区中 对于snprintf: buf：一个缓冲区的指针。格式化输出到该缓冲区中 n：缓冲区的长度。格式化输出到该缓冲区中 返回值： 成功：返回输出字符数（不包含null字节） 失败：返回负数 printf将格式化输出写到标准输出；fprintf写到指定的流；dprintf写到指定的文件描述符；sprintf写到数组buf中；snprintf也是写到数组buf中，但是在该数组的尾端自动添加一个null字节（该字节不包含在返回值中）。 通常不推荐使用sprintf，因为它可能引起缓冲区溢出流动 如果格式化输出一共 s 个字节，那么snprintf的数组缓冲区至少为s+1个字节，否则发生截断 格式说明：%[flags][fldwidth][precision][lenmodifier]convtype 标志flags有： &#39; : 撇号，将整数按照千位分组字符 - ： 在字段内左对齐输出 +： 总是显示带符号转换的正负号 ：空格。如果第一个字符不是正负号，则在其前面加一个空格 #：指定另一种转换形式（如，对于十六进制格式，加 0x 前缀） 0：添加前导0（而非空格） 进行填充 fldwidth：说明最小字段宽度。转换后参数字符如果小于宽度，则多余字符位置用空格填充。 字段宽度是一个非负十进制数，或者是一个星号 * precision：说明整型转换后最少输出数字位数、浮点数转换后小数点后的最少位数、字符串转换后最大字节数。 精度是一个点.后跟随一个可选的非负十进制数或者一个星号* 宽度和精度可以为*，此时一个整型参数指定宽度或者精度的值。该整型参数正好位于被转换的参数之前 lenmodifier：说明参数长度。可以为： hh：将相应的参数按照signed char或者unsigned char类型输出 h：将相应的参数按照signed short或者unsigned short类型输出 l：将相应的参数按照signed long或者unsigned long或者宽字符类型输出 ll：将相应的参数按照signed longlong或者unsigned longlong类型输出 j：intmax_t或者uintmax_t z：size_t t：ptrdiff_t L：long double convtype：控制如何解释参数 d或者i：有符号十进制 o：无符号八进制 u：无符号十进制 x或者X：无符号十六进制 f或者F：双精度浮点数 e或者E：指数格式双精度浮点数 g或者G：根据转换后的值解释为f、F、e、E a或者A：十六进制指数格式双精度浮点数 c：字符（若带上长度修饰符l,则为宽字符） s：字符串（若带上长度修饰符l,则为宽字符） p：指向void的指针 n：到目前位置，此printf调用输出的字符的数目将被写入到指针所指向的带符号整型中 %：一个%字符 C：宽字符，等效于lc S：宽字符串，等效于ls printf族的变体：将可变参数(...)替换成了va_list arg: #include&lt;stdarg.h&gt; #include&lt;stdio.h&gt; int vprintf(const char *restrict format,va_list arg); int vfprintf(FILE *restrict fp,const char*restrict format,va_list arg); int vdprintf(int fd,const char *restrict format,va_list arg); int vsprintf(char *restrict buf,const char*restrict format,va_list arg); int vsnprintf(char *restrict buf,size_t n,const char *restrict format,va_list arg); 其参数与返回值与前面的printf族完全相同 格式化输入函数： #include&lt;stdio.h&gt; int scanf(const char*restrict format,...); int fscanf(FILE *restrict fp,const char *restrict format,...); int sscanf(const char *restrict buf,const char *restrict format,...); 参数： format,...：格式化字符串 对于fscanf： fp：打开的文件对象指针。从流中读取输入 对于sscanf： buf：一个缓冲区指针。从该缓冲区中读取输入 返回值： 成功：返回赋值的输入项数 提前到达文件尾端：返回EOF 失败：返回EOF scanf族用于分析输入字符串，将字符序列转换成指定类型的变量。在格式之后的各参数中包含了变量的地址，用转换结果对这些变量赋值。 除了转换说明和空白字符以外，格式字符串中的其他字符必须与输入匹配。如有一个字符不匹配，则停止后续处理，不再读输入的其余部分。 转换说明的格式为：%[*][fldwidth][m][lenmodifier]convtype： *：用于抑制转换。按照转换说明的其余部分对输入进行转换，但是转换结果不存放在参数中而是抛弃 fldwidth：说明最大宽度，即最大字符数 lenmodifier：说明要转换结果赋值的参数大小。见前述说明 convtype：类似前述说明。但是稍有区别：输入中的带符号的数值可以赋给无符号类型的变量 m：用于强迫内存分配。当%c,%s时，如果指定了m，则会自动分配内存来容纳转换的字符串。同时该内存的地址会赋给指针类型的变量（即要求对应的参数必须是指针的地址）。同时要求程序员负责释放该缓冲区（通过free函数） scanf族也有一类变体：将可变参数(...)替换成了va_list arg: #include&lt;stdarg.h&gt; #include&lt;stdio.h&gt; int vscanf(const char*restrict format,va_list arg); int vfscanf(FILE *restrict fp,const char *restrict format,va_list arg); int vsscanf(const char *restrict buf,const char *restrict format,va_list arg); 示例： 在 main函数中调用test_printf_scanf函数： ``` void test_printf_scanf(){ M_TRACE(“——— Begin test_printf_scanf() ———\n”); printf(“ test printf *\n”); _test_printf(); printf(“\n\n test snprintf *\n”); _test_snprintf(); printf(“\n\n test scanf *\n”); _test_scanf(); printf(“\n\n test sscanf *\n”); _test_sscanf(); M_TRACE(“——— End test_printf_scanf() ———\n\n”);} ``` ![print_scan](../imgs/std_IO/print_scan.JPG) 其他 fileno函数：获取文件对象的文件描述符 #include&lt;stdio.h&gt; int fileno(FILE *fp); 参数： fp：打开的文件对象的指针 返回值： 返回与该流相关联的文件描述符 tmpnam/tmpfile函数：创建临时文件 #include&lt;stdio.h&gt; char *tmpnam(char *ptr); FILE *tmpfile(void); tmpnam参数： ptr：指向存放临时文件名的缓冲区的指针 若为NULL，则产生的路径名存放在一个静态区中，指向该静态区的指针作为函数值返回 下次再调用tmpnam时，会重写该静态区 如果为非NULL，则认为它指向长度至少为L_tmpnam个字符的数组，产生的路径名存放在该缓冲区中，返回ptr。L_tmpnam常量定义在&lt;stdio.h&gt;头文件中 tmpnam返回值：返回指向唯一路径名的指针 tmpfile返回值： 成功：返回文件指针 失败：返回NULL tmpnam函数产生一个与现有文件名不同的有效路径名字符串。每次调用它时，都产生一个不同路径名。最多调用次数是TMP_MAX次（定义在&lt;stdio.h&gt;中） 它只创建独一无二的文件名，但是并不创建临时文件 tmpfile是创建一个临时二进制文件（类型wb+），在关闭该文件或者程序结束时将自动删除这种文件 UNIX对二进制文件、文本文件并不进行特殊区分 mkdtemp/mkstemp函数：创建临时文件（由SUS 标准给出） #include&lt;stdlib.h&gt; char *mkdtemp(char *template); int mkstemp(char *template); 参数： template：一个字符串。这个字符是最末6个字符设置为XXXXXX的路径名。函数将这些占位符替代成不同的字符来构建一个唯一的路径名。若成功的话，这两个函数将修改template字符串来反映临时文件的名字 因为函数会修改template,因此一定不能用常量字符串来赋值！ mkdtemp返回值： 成功：返回指向目录名的指针 失败：返回NULL mkstemp返回值： 成功： 返回文件描述符 失败： 返回 -1 mkdtemp函数创建了一个目录，该目录有一个唯一的名字；mkstemp函数创建了一个文件，该文件有一个唯一的名字。名字是通过template字符串进程构建的。 mkdtemp函数创建的目录具有权限位集： S_IRUSR|S_IWUSR|S_IXUSR。调用进程的文件模式创建屏蔽字可以进一步限制这些权限 mkstemp函数返回的文件描述符以读写方式打开。它创建的文件用访问权限位：S_IRUSR|S_IWUSR mkstemp创建的临时文件并不会自动删除 示例：在main函数中调用test_tmpnam_mkdtemp函数： void test_tmpnam_mkdtemp() { M_TRACE(&quot;--------- Begin test_printf_scanf() ---------\n&quot;); printf(&quot;******** test tmpnam ********\n&quot;); _test_tmpnam(); printf(&quot;\n\n******** test mkdtemp ********\n&quot;); _test_mkdtemp(); M_TRACE(&quot;--------- End test_printf_scanf() ---------\n\n&quot;); } 内存流：一种标准IO流，虽然它通过 FILE指针来访问，但是并没有底层的文件 。所有的IO都是通过在缓冲区和主存之间来回传送字节来完成。 虽然它看起来像是文件流，但是更适用于字符串操作 创建内存流： #include&lt;stdio.h&gt; FILE *fmemopen(void *restrict buf,size_t size,const char *restrict type); 参数： buf：内存流缓冲区的起始地址 size：内存流缓冲区的大小（字节数） 若buf为NULL时，则函数负责分配size字节的缓冲区，并在流关闭时自动释放分配的缓冲区 type:控制如何使用流（即打开内存流的方式）： r或者rb：读打开 w或者wb：写打开 a或者ab：追加打开；为在第一个null字节处写打开 r+或者r+b或rb+：读写打开 w+或者w+b或wb+：把文件截断为0，然后读写打开 a+或者a+b或ab+：追加；为在第一个null字节处读写打开 返回值： 成功：返回流指针 失败：返回NULL 注意： 无论何时以追a方式打开内存流时，当前文件位置设为缓冲区中第一个null字节处。 若缓冲区中不存在null字节，则当前位置设为缓冲结尾的后一个字节 当内存流不是a方式打开时，当前位置设置为缓冲区的开始位置 如果buf是null，则打开流进行读或者写都没有任何意义。因为此时缓冲区是通过fmemopen分配的，没办法找到缓冲区的地址。 任何时候需要增加流缓冲区中数据流以及调用fclose、fflush、fseek、fseeko、fsetpos时都会在当前位置写入一个null字节 创建内存流的其他两个函数： #include&lt;stdio.h&gt; FILE *open_memstream(char **bufp,size_t *sizep); #include &lt;wchar.h&gt; FILE *open_wmemstream(wchar_t **bufp,size_t *sizep); 参数： bufp：指向缓冲区地址的指针（用于返回缓冲区地址） sizep:指向缓冲区大小的指针（用于返回缓冲区大小） 返回值： 成功：返回流指针 失败：返回 NULL 这两个函数创建的流： 只能写打开 缓冲区由函数自动创建 关闭流后需要程序员释放缓冲区 对流添加字节会增加缓冲区大小 在缓冲区地址和大小使用上要遵守规则： 缓冲区地址和长度只有在调用fclose或者fflush后才有效 这些值只有在下一次写入或者调用fclose之前才有效。因为缓冲区可能增长，也可能需要重新分配 示例：在main函数中调用test_memstream函数： void test_memstream() { M_TRACE(&quot;--------- Begin test_memstream() ---------\n&quot;); char mem_buffer[16]; FILE *fp=My_fmemopen(mem_buffer,16,&quot;r+&quot;); if(NULL!=fp) { char read_write_buffer[8]; My_ftello(fp); // 查看当前位置 //**** 写入 ****// My_fputs(&quot;abcdefg\n&quot;,fp); // 每次7个字符加一个换行符 My_fputs(&quot;0123456789&quot;,fp); // 没有换行符 My_ftello(fp); // 查看当前位置 fflush(fp); print_char_buffer(mem_buffer,16); //**** 读取 ****// My_fseeko(fp,0,SEEK_SET); //重定位到文件头 My_ftello(fp); // 查看当前位置 My_fgets(read_write_buffer,8,fp); // 读取 abcdefg My_fgets(read_write_buffer,8,fp); // 读取 \n My_fgets(read_write_buffer,8,fp);// 读取 0123456，文件指针指向 null 字节 My_fgets(read_write_buffer,8,fp);// 遇到 EOF，即 null 字节 （最后一个字节为 null 字节，因此有效字节只有15个字节） My_ftello(fp); // 查看当前位置，文件指针指向最后一个字节的下一个字节 My_fgets(read_write_buffer,8,fp);// 遇到 EOF，此时读取返回 EOF，并且是 ferror 返回真，且 feof 返回真 printf(&quot;feof=%d,ferror=%d\n&quot;,feof(fp),ferror(fp)); //ferror 返回真，且 feof 返回真 print_char_buffer(mem_buffer,16); // 读取并不会删除 mem_buffer 中的内容 fclose(fp); } M_TRACE(&quot;--------- End test_memstream() ---------\n\n&quot;); } 标准IO库的缺点：效率不高。这与它需要复制的数据量有关。当使用每次一行的函数fgets/fputs时，通常需要复制两次数据： 内核和标准IO缓冲区之间（当调用read/write时） 标准IO缓冲区和用户程序的缓冲区之间%]]></content>
      <categories>
        <category>apue</category>
      </categories>
      <tags>
        <tag>apue,文件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C语言指针&内存分配]]></title>
    <url>%2F2017%2F11%2F27%2FC%E8%AF%AD%E8%A8%80%E6%8C%87%E9%92%88%26%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%2F</url>
    <content type="text"><![CDATA[指针也是一种数据类型。 对数据类型的认识常见非指针类型int型，char型，long型 ...int a=10中心：该内存空间a ：内存空间代号10：内存空间存放的数据&amp;a：a对应的地址编号（该内存空间对应的地址编号）（32位系统编号有32位，64位系统编号有64位） 小插曲，回顾32&amp;64位系统的变量类型的不同之处： 32(byte) 64(byte) long 4 8 int *(指针型变量) 4 8 指针类型char * ,int *,long * ,... int b=10 int *a=&amp;b 中心：该内存空间（这条表达式是重点：int *a=&amp;b）a: 该内存空间的代号&amp;b：该内存空间中存放的数据（是一个地址编号，本例中是存放b的内存空间的地址编号）&amp;a：a对应的地址编号（该内存空间对应的地址编号） 函数类型函数类型比较特殊： int func(){ return 0; } 在内存中函数存放与代码段地址空间（不可修改），所以对函数取地址&amp;func，得到的是代码段，该函数对应的地址。有一个有趣的现象是，gdb调试时，p func,p *func,p &amp;func,得到的全是func函数对应的代码段地址。 (gdb) p func $1 = {int (int)} 0x6b0 &lt;func&gt; (gdb) p *func $2 = {int (int)} 0x6b0 &lt;func&gt; (gdb) p &amp;func $3 = (int (*)(int)) 0x6b0 &lt;func&gt; 也许函数名本本身就是一个特殊的指针变量，指向自己。但是（*func）好像没有意义。如果是自己定义的指针类型，是可以指向对应类型的函数的，这个时候和普通的指针类型是一样的。 9 int func(int a) 10 { 11 int b=10; 12 printf(&quot;a=%d\nb=%d\n&quot;,a,b); 13 return a*b; 14 } 15 int func1(int b){ 16 return 0; 17 } 22 int main() 23 { 24 int a=12; 25 int (*pfunc)(int a)=&amp;func; 26 int b = (*pfunc)(a); 27 pfunc=&amp;func1; (gdb) p pfunc $2 = (int (*)(int)) 0x5555555546e4 &lt;func1&gt; (gdb) p func $3 = {int (int)} 0x5555555546b0 &lt;func&gt; (gdb) p func1 $4 = {int (int)} 0x5555555546e4 &lt;func1&gt; (gdb) p main $5 = {int ()} 0x5555555546f2 &lt;main&gt; (gdb) p &amp;pfunc $6 = (int (**)(int)) 0x7fffffffe168 数组类型 数组在虚拟内存中，是连续存储的。 char *s=&quot;fdl&quot;,这种这是字符串常量定义的一种方式，不能做修改，如同const int a=10，此类常量存在于内存中的数据段。 内存组织形式参考：C程序的内存布局(Memory Layout)]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>C语言,内存分配</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[celery学习笔记]]></title>
    <url>%2F2017%2F11%2F19%2Fcelery%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[简介在程序的运行过程中，我们经常会遇到一些耗时耗资源的操作，为了避免他们阻塞主程序的运行，我们经常会采用多线程或异步任务。比如，在web开发中， 对于新用户的注册，我们通常会给他们发送一封激活邮件，而发送邮件是个IO阻塞式任务，如果直接把它放到应用当中去，就需要等邮件发出去之后才能进行下一步操作，此时用户只能等待再等待，更好的方式是在业务逻辑中触发一个发送邮件的异步任务，而主程序可以继续往下执行。Celery是一个强大的分布式任务队列,他可以让任务执行完全脱离主程序，甚至他可以被分配到其他主机上运行。我们通常使用它来实现异步任务（async task）和定时任务（crontab）。它的架构组图如下： 任务模块Task 包含异步和定时任务。其中，异步任务通常在业务逻辑中被触发然后发往任务队列中，而定时任务由Celery Beat 进程周期性地将任务发往任务队列。 消息中间件Broker Broker，即任务调度队列，接受任务生产者发来的消息（即任务），将任务存入队列。Celery本身不提供队列服务，官方推荐使用RabbitMQ和Redis等。 任务执行单元Worker Worker是执行任务的处理单元，它实时监控消息队列，获取队列中调度的任务，并执行它。 任务结果存储Backend - Backend用于存储任务的执行结果，以供查询。同消息中间件一样，存储也可以使用RabbitMQ，Radis，和MongoDB等。 异步任务使用celery实现异步任务主要包含三个步骤： 创建一个celery实例 启动Celery Worker 应用程序调用异步任务快速入门正确安装celery，redis以及使用redis的celery相关依赖: redis 我用的是容器，直接 docker pull redis docker run -d -p 6379:6379 --name redis redis:latest pip install celery pip install &#39;celery[redis]&#39; 创建Celery实例编写tasks.py # -*- coding: utf-8 -*- import time from celery import Celery broker = &#39;redis://127.0.0.1:6379&#39; backend = &#39;redis://127.0.0.1:6379/0&#39; app = Celery(&#39;my_task&#39;, broker=broker, backend=backend) @app.task def add(x, y): time.sleep(5) # 模拟耗时操作 return x + y 上面代码，做了以下几件事情， 创建了一个Celery实例app，名称为my_task; 指定消息中间件为redis，URL为 redis://127.0.0.1:6379; 指定存储用redis，URL为redis://127.0.0.1:6379/0; 创建了一个celery任务add ，当函数被@app.task装饰后，就成为可被Celery调度的任务。 启动Celery Worker在当前目录，使用如下方式启动Celery Worker $ celery worker -A tasks --loglevel=info 其中： 参数 -A 指定了Celery实例的位置，本例是在 tasks.py 中，Celery会自动在该文件中寻找Celery对象实例，当然我们也可以指定，在本例中使用 -A tasks.app ; 参数 --loglevel 指定了日志的级别，默认为warning，也可以使用 -l info 来表示。 在生产环境中，我们通常会使用Supervisor来控制Celery Worker 进程。启动成功后，控制台会显示如下输出（最后两行输出是我调用了task后的输出，刚开始时没有）： 调用任务 现在我们可以通过delay()和apply_async() 方法来调用任务。 在当前目录打开Python控制台，输入以下代码： (qw_export_post_env) 日 19 11月 - 22:25  ~/code/py/celery  @dl  python Python 2.7.13+ (default, Jul 19 2017, 18:15:03) [GCC 6.4.0 20170704] on linux2 Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information. &gt;&gt;&gt; from tasks import add &gt;&gt;&gt; add.delay(2,1) &lt;AsyncResult: d8be1e96-37bd-4868-9276-7bceafb99ae7&gt; &gt;&gt;&gt; result=add.delay(2,1) &gt;&gt;&gt; result.ready() # 使用 ready() 判断任务是否执行完毕 True &gt;&gt;&gt; result.get() # 使用 get() 获取任务结果 3 &gt;&gt;&gt; result=add.delay(2,1) &gt;&gt;&gt; result.get() 3 &gt;&gt;&gt; result=add.delay(2,1) &gt;&gt;&gt; result.ready() False &gt;&gt;&gt; result.ready() True &gt;&gt;&gt; result.get() 3 在上面，我们从tasks.py 文件中导入了 add 任务对象，然后使用 delay() 方法将任务发送到消息中间件（Broker） ，Celery Worker进程监控到该任务后，就会进行执行。上面图片上最后两行输出，就是执行该任务的日志。这说明该任务已经被调度并执行成功。 上面我们是在 Python的环境中调用的任务。事实上，我们通常在应用程序中调用任务。比如我们将下面的程序保存为client.py: # -*- coding: utf-8 -*- from tasks import add # 异步任务 add.delay(2, 8) print &#39;hello world&#39; 使用配置分离配置文件任务文件，以及应用程序。在上面的例子中，我们直接把 Broker 和 Backend 的配置写在了程序当中，更好的做法是将配置项统一写入到一个配置文件中，通常我们将该文件命名为 celeryconfig.py 。 Celery 的配置比较多，可以在官方文档查询每个配置项的含义。 下面，我们再看一个例子。项目结构如下： celery_demo # 项目根目录 ├── celery_app # 存放 celery 相关文件 │ ├── __init__.py │ ├── celeryconfig.py # 配置文件 │ ├── task1.py # 任务文件 1 │ └── task2.py # 任务文件 2 └── client.py # 应用程序` __init__.py 代码如下： # -*- coding: utf-8 -*- from celery import Celery app = Celery(&#39;demo&#39;) # 创建 Celery 实例 app.config_from_object(&#39;celery_app.celeryconfig&#39;) # 通过 Celery 实例加载配置模块 celeryconfig.py 代码如下： BROKER_URL = &#39;redis://127.0.0.1:6379&#39; # 指定 Broker CELERY_RESULT_BACKEND = &#39;redis://127.0.0.1:6379/0&#39; # 指定 Backend CELERY_TIMEZONE=&#39;Asia/Shanghai&#39; # 指定时区，默认是 UTC # CELERY_TIMEZONE=&#39;UTC&#39; CELERY_IMPORTS = ( # 指定导入的任务模块 &#39;celery_app.task1&#39;, &#39;celery_app.task2&#39; ) task1.py 代码如下： import time from celery_app import app @app.task def add(x, y): time.sleep(2) return x + y task2.py 代码如下： import time from celery_app import app @app.task def multiply(x, y): time.sleep(2) return x * y client.py 代码如下： #!/usr/bin/env python # coding=utf-8 from celery_app import task1 from celery_app import task2 import time result1=task1.add.apply_async(args=[2,8]) result2=task2.multiply.apply_async(args=[3,8]) print &quot;hello&quot; while(not result1.ready() or not result2.ready()): time.sleep(0.5) print result1.ready() print result1.get() print result2.get() 现在，让我们启动 Celery Worker 进程，在项目的根目录下执行下面命令： celery_demo $ celery -A celery_app worker --loglevel=info 接着，运行 $ python client.py ，它会发送两个异步任务到 Broker，在 Worker 的窗口我们可以看到如下输出： [2017-11-19 22:50:39,573: INFO/MainProcess] Received task: celery_app.task1.add[b6e8b247-9f94-4b77-8181-2613247df0f6] [2017-11-19 22:50:39,575: INFO/MainProcess] Received task: celery_app.task2.multiply[c578f21b-d8c6-453f-8d2f-f9d1f16a57fd] [2017-11-19 22:50:41,585: INFO/ForkPoolWorker-1] Task celery_app.task1.add[b6e8b247-9f94-4b77-8181-2613247df0f6] succeeded in 2.010242356s: 10 [2017-11-19 22:50:41,585: INFO/ForkPoolWorker-3] Task celery_app.task2.multiply[c578f21b-d8c6-453f-8d2f-f9d1f16a57fd] succeeded in 2.009279021s: 24 执行输出： @dl  python client.py hello False False False False 10 24 delay 和 apply_async在前面的例子中，我们使用 delay() 或 apply_async() 方法来调用任务。事实上，delay 方法封装了 apply_async，如下： def delay(self, *partial_args, **partial_kwargs): &quot;&quot;&quot;Shortcut to :meth:`apply_async` using star arguments.&quot;&quot;&quot; return self.apply_async(partial_args, partial_kwargs) 也就是说，delay 是使用 apply_async 的快捷方式。apply_async 支持更多的参数，它的一般形式如下： apply_async(args=(), kwargs={}, route_name=None, **options) apply_async 常用的参数如下： countdown：指定多少秒后执行任务task1.apply_async(args=(2, 3), countdown=5) # 5 秒后执行任务 eta (estimated time of arrival)：指定任务被调度的具体时间，参数类型是 datetimefrom datetime import datetime, timedelta # 当前 UTC 时间再加 10 秒后执行任务 task1.multiply.apply_async(args=[3, 7], eta=datetime.utcnow() + timedelta(seconds=10)) expires：任务过期时间，参数类型可以是 int，也可以是 datetimetask1.multiply.apply_async(args=[3, 7], expires=10) # 10 秒后过期 更多的参数列表可以在官方文档中查看。 定时任务Celery 除了可以执行异步任务，也支持执行周期性任务（Periodic Tasks），或者说定时任务。Celery Beat 进程通过读取配置文件的内容，周期性地将定时任务发往任务队列。 让我们看看例子，项目结构如下： celery_demo # 项目根目录 ├── celery_app # 存放 celery 相关文件 ├── __init__.py ├── celeryconfig.py # 配置文件 ├── task1.py # 任务文件 └── task2.py # 任务文件 __init__.py 代码如下： # -*- coding: utf-8 -*- from celery import Celery app = Celery(&#39;demo&#39;) app.config_from_object(&#39;celery_app.celeryconfig&#39;) celeryconfig.py 代码如下： # -*- coding: utf-8 -*- from datetime import timedelta from celery.schedules import crontab # Broker and Backend BROKER_URL = &#39;redis://127.0.0.1:6379&#39; CELERY_RESULT_BACKEND = &#39;redis://127.0.0.1:6379/0&#39; # Timezone CELERY_TIMEZONE=&#39;Asia/Shanghai&#39; # 指定时区，不指定默认为 &#39;UTC&#39; # CELERY_TIMEZONE=&#39;UTC&#39; # import CELERY_IMPORTS = ( &#39;celery_app.task1&#39;, &#39;celery_app.task2&#39; ) # schedules CELERYBEAT_SCHEDULE = { &#39;add-every-30-seconds&#39;: { &#39;task&#39;: &#39;celery_app.task1.add&#39;, &#39;schedule&#39;: timedelta(seconds=30), # 每 30 秒执行一次 &#39;args&#39;: (5, 8) # 任务函数参数 }, &#39;multiply-at-some-time&#39;: { &#39;task&#39;: &#39;celery_app.task2.multiply&#39;, &#39;schedule&#39;: crontab(hour=9, minute=50), # 每天早上 9 点 50 分执行一次 &#39;args&#39;: (3, 7) # 任务函数参数 } } task1.py 代码如下： import time from celery_app import app @app.task def add(x, y): time.sleep(2) return x + y task2.py 代码如下： import time from celery_app import app @app.task def multiply(x, y): time.sleep(2) return x * y 现在，让我们启动 Celery Worker 进程，在项目的根目录下执行下面命令： celery_demo $ celery -A celery_app worker --loglevel=info 接着，启动 Celery Beat 进程，定时将任务发送到 Broker，在项目根目录下执行下面命令： celery_demo $ celery beat -A celery_app celery beat v4.0.1 (latentcall) is starting. __ - ... __ - _ LocalTime -&gt; 2016-12-11 09:48:16 Configuration -&gt; . broker -&gt; redis://127.0.0.1:6379// . loader -&gt; celery.loaders.app.AppLoader . scheduler -&gt; celery.beat.PersistentScheduler . db -&gt; celerybeat-schedule . logfile -&gt; [stderr]@%WARNING . maxinterval -&gt; 5.00 minutes (300s) 之后，在 Worker 窗口我们可以看到，任务 task1 每 30 秒执行一次，而 task2 每天早上 9 点 50 分执行一次。 在上面，我们用两个命令启动了 Worker 进程和 Beat 进程，我们也可以将它们放在一个命令中： $ celery -B -A celery_app worker --loglevel=info Celery 周期性任务也有多个配置项，可参考官方文档。 转载自]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python,web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OJ查重设计]]></title>
    <url>%2F2017%2F11%2F14%2FOJ%E6%9F%A5%E9%87%8D%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[因为OJ有一个查重功能需要完善，所以我今天查阅了百度和google，目前可以用的有standford的moss和Dick grune的sim。 sim 一个实用的代码查重工具 点击上面的sim就可以下载，支持Unix like OS 和windows。支持的语言有： C, C++, Java, Pascal, Modula-2, Lisp, Miranda andnatural language text. Linux安装sim依赖下面几个程序： gcc, flex, cp, ln, echo, rm, and wc 其中flex可能需要单独安装 有个小坑，sim-***.zip文件是直接在项目根目录里面压缩的，所以解压时（unzip）先新建一个文件夹，把zip放进去，在解压。 然后，需要修改Makefile后才能安装。不然Make会出错。 打开Makefile，大概是55-72行，是windows的安装选项，我们实在linux下安装，所以不需要，把这些行删除掉。然后修改44,45,46行，我修改后如下： DIR = /home/dl BINDIR = /usr/bin MAN1DIR = /usr/share/man/man1 Ubuntu的话，直接照抄我的，保存就可以。这个DIR变量不重要，BINDIR表示生成的可执行文件存放的位置，放在/usr/bin下可以直接执行sim的这些命令，因为/usr/bin一般都存在与环境变量下。MANDIR表示man手册的安装位置，ubuntu（debian系）的是这个，其他的不太清楚。然后，就可以执行make的相关命令了，可以先执行make help查看make相关命令。make test生成sim_c , 并执行sim_c的相关案例。没问题的话，就可以执行： make clean make install 执行完成后，sim就安装完毕了。以下命令就安装好了，分别支持对应的语言。 sim_c sim_c++ sim_java sim_lisp sim_m2 sim_mira sim_pasc sim_text sim 使用查看sim.pdf,好吧，看这个如果英语不好的话，很痛苦。我列举以下常用的： -r N：显示重复百分比大于N的比较项。（没有-r参数的话，N默认24） -w N：设置输出显示的行宽（没有-w参数的话，N默认80） -p：输出百分比.（默认是对比每两个文件握一次手，以前面的文件为主，共【（n^2-n）/2】次。 -o file：将输出的内容重定向到file文件 -O：在命令执行的开始显示每个参数代表的含义。（我就是利用这个参数快速学会了sim的使用） -M：在最后显示内存使用情况。 -a:对比所有，目前还不太清楚。（每个文件都与其他的文件握一次手，【n^2-n】次） -e:单独对比每一个。（比较次数同-p，但是比较内容策略，与-a，-p有何不同，还没弄清楚） 后期工作基于sim，利用python，封装一个独立的、方便使用的查重工具。python 取得代码simpython 后台数据库过滤，取得代码，存入文件，文件名为username_time.language,存在一个以该用户名命名的文件夹下。然后执行三种语言的查重。并且输出结果。结果以文本显示。 window安装我没有尝试文档上，说需要MSDOS+MinGW。另外Makefile的编辑，肯定是先删除unix like配置部分，然后修改BINDIR和MAN1DIR。自行发挥，自求多福。 moss还没有看呢，感觉sim就挺好的了。有时间看一下moss。比较一下哪个封装起来更容易。]]></content>
      <categories>
        <category>OJ研发</category>
      </categories>
      <tags>
        <tag>查重,OJ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JS学习笔记2进阶]]></title>
    <url>%2F2017%2F11%2F12%2FJS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02%E8%BF%9B%E9%98%B6%2F</url>
    <content type="text"><![CDATA[JS学习笔记2进阶篇 注意别吧关键字敲错了。。。 基础语法变量命名规则：1.必须以字母、下划线或美元符号开头，后面可以跟字母、下划线、美元符号和数字。如下:正确:mysum，_mychar，$numa12.变量名区分大小写，如:A与a是两个不同变量。3.不允许使用JavaScript关键字和保留字做变量名 运算符优先级同C语言：！ &gt; 算术运算符 &gt; 关系运算符 &gt; &amp;&amp; &gt; || &gt; 赋值运算符优先级参考 数组var myarr=new Array(); var myarr=new Array(3);//数组长度为3 var myarr=new Array(3,4);//数组长度为2，第一个元素为3，第二个元素为4 myarr.length //myarr的长度 myarr.splice(a,b);从myarr[a]开始删除b个元素 字符串类型有split方法，分割字符串。 sort方法， arr.sort(function(a, b){ if(a.length &gt; b.length){ return 1 }else if(a.length &lt; b.length){ return -1 }else{ return 0 } }) //长度短的在前 二维数组定义方式： var myarr=new Array(); //先声明一维 for(var i=0;i&lt;2;i++){ //一维长度为2 myarr[i]=new Array(); //再声明二维 for(var j=0;j&lt;3;j++){ //二维长度为3 myarr[i][j]=i+j; // 赋值，每个数组元素的值为i+j } } 或者： var Myarr = [[0 , 1 , 2 ],[1 , 2 , 3]]//表示的是值 判断if,else: switch： switch(表达式) { case值1: 执行代码块 1 break; case值2: 执行代码块 2 break; ... case值n: 执行代码块 n break; default: 与 case值1 、 case值2...case值n 不同时执行的代码 } 循环for循环： &lt;script type=&quot;text/javascript&quot;&gt; var num=1; for (num=1;num&lt;=6;num++) //初始化值；循环条件；循环后条件值更新 { document.write(&quot;取出第&quot;+num+&quot;个球&lt;br /&gt;&quot;); } &lt;/script&gt; while循环： &lt;script type=&quot;text/javascript&quot;&gt; var num=0; //初始化值 while (num&lt;=6) //条件判断 { document.write(&quot;取出第&quot;+num+&quot;个球&lt;br /&gt;&quot;); num=num+1; //条件值更新 } &lt;/script&gt; 函数事件 JavaScript 创建动态页面。事件是可以被 JavaScript 侦测到的行为。 网页中的每个元素都可以产生某些可以触发 JavaScript 函数或程序的事件。比如说，当用户单击按钮或者提交表单数据时，就发生一个鼠标单击（onclick）事件，需要浏览器做出处理，返回给用户一个结果。 &lt;input name=&quot;点击我&quot; type=&quot;button&quot; value=&quot;点击我&quot; onclick=&quot;openwin()&quot;/&gt; &lt;input name=&quot;确定&quot; type=&quot;button&quot; value=&quot;确定&quot; onmouseover=&quot;message()&quot;/&gt; &lt;form onmouseout=&quot;message()&quot;&gt;&lt;a href=&quot;http://www.imooc.com&quot; &gt;点击我&lt;/a&gt;&lt;/form&gt; onfocus=&quot;message()&quot; onblur事件与onfocus是相对事件，当光标离开当前获得聚焦对象的时候，触发onblur事件，同时执行被调用的程序。 &lt;input name=&quot;username&quot; type=&quot;text&quot; value=&quot;请输入用户名！&quot; onblur=&quot;message()&quot;&gt; &lt;textarea name=&quot;summary&quot; cols=&quot;60&quot; rows=&quot;5&quot; onselect=&quot;message()&quot;&gt;请写入个人简介，不少于200字！&lt;/textarea&gt; &lt;textarea name=&quot;summary&quot; cols=&quot;60&quot; rows=&quot;5&quot; onchange=&quot;message()&quot;&gt;请写入个人简介，不少于200字！&lt;/textarea&gt; &lt;body onload=&quot;message()&quot;&gt;事件会在页面加载完成后，立即发生，同时执行被调用的程序。 注意：1. 加载页面时，触发onload事件，事件写在&lt;body&gt;标签内。 &lt;script type=&quot;text/javascript&quot;&gt; window.onunload = onunload_message; function onunload_message(){ alert(&quot;您确定离开该网页吗？&quot;); } &lt;/script&gt; javascript内置对象Date日期对象String字符串对象Math对象Array数组对象浏览器对象window对象JavaScript计时器History对象Location对象Navigator对象&lt;script type=&quot;text/javascript&quot;&gt; var b=navigator.appName; var b_c=navigator.appCodeName; var b_v=navigator.appVersion; var p=navigator.platform; var ua=navigator.userAgent; document.write(&quot;1:&quot;+b+&quot;&lt;br&gt;&quot;); document.write(&quot;2:&quot;+b_c+&quot;&lt;br&gt;&quot;); document.write(&quot;3:&quot;+b_v+&quot;&lt;br&gt;&quot;); document.write(&quot;4:&quot;+p+&quot;&lt;br&gt;&quot;); document.write(&quot;5:&quot;+ua+&quot;&lt;br&gt;&quot;); &lt;/script&gt; screen对象DOM对象，控制HTML元素]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>js,前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[32位和64位系统区别及int字节数]]></title>
    <url>%2F2017%2F11%2F12%2F32%E4%BD%8D%E5%92%8C64%E4%BD%8D%E7%B3%BB%E7%BB%9F%E5%8C%BA%E5%88%AB%E5%8F%8Aint%E5%AD%97%E8%8A%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[64位系统和32位有什么区别？1、64bit CPU拥有更大的寻址能力，最大支持到16GB内存，而32bit只支持4G内存 2、64位CPU一次可提取64位数据，比32位提高了一倍，理论上性能会提升1倍。但这是建立在64bit操作系统，64bit软件的基础上的。 什么是64位处理器？之所以叫做“64位处理器”，是因为电脑内部都是实行2进制运算，处理器（CPU）一次处理数据的能力也是2的倍数。8位处理器、16位处理器、32位处理器和64位处理器，其计数都是2的倍数。一次处理的数据越大，该电脑处理信息的能力越来越大；因此64位处理在先天就比32位处理器具有快速的能力。那为什么不用更高级的128位处理器呢？因为位数越高，处理器芯片的设计也就越复杂，目前的技术水平暂时无法制造这么复杂的芯片。 64位处理器之失※硬件———缺乏驱动程序，很多现有硬件无法使用 ※软件———操作系统不是问题，但是软件出现不兼容难题 64位处理器之得※硬件———更快的执行速度，更大的内存管理 ※软件———最新的尖端软件首先出现在64位平台 数据类型对应字节数程序运行平台不同的平台上对不同数据类型分配的字节数是不同的。个人对平台的理解是CPU+OS+Compiler，是因为： 1、64位机器也可以装32位系统（x64装XP）； 2、32位机器上可以有16/32位的编译器（XP上有tc是16位的，其他常见的是32位的）； 3、即使是32位的编译器也可以弄出64位的integer来（int64）。 以上这些是基于常见的wintel平台，加上我们可能很少机会接触的其它平台（其它的CPU和OS），所以个人认为所谓平台的概念是三者的组合。 虽然三者的长度可以不一样，但显然相互配合（即长度相等，32位的CPU+32位的OS+32位的Compiler）发挥的能量最大。 理论上来讲 我觉得数据类型的字节数应该是由CPU决定的，但是实际上主要由编译器决定(占多少位由编译器在编译期间说了算)。 常用数据类型对应字节数 可用如sizeof（char),sizeof(char*)等得出 32位编译器： char ：1个字节 char*（即指针变量）: 4个字节（32位的寻址空间是2^32, 即32个bit，也就是4个字节。同理64位编译器） short int : 2个字节 int： 4个字节 unsigned int : 4个字节 float: 4个字节 double: 8个字节 long: 4个字节 long long: 8个字节 unsigned long: 4个字节 64位编译器： char ：1个字节 char*(即指针变量): 8个字节 short int : 2个字节 int： 4个字节 unsigned int : 4个字节 float: 4个字节 double: 8个字节 long: 8个字节 long long: 8个字节 unsigned long: 8个字节]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>C,Cpp,面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JS学习笔记1入门]]></title>
    <url>%2F2017%2F11%2F12%2FJS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[JS学习笔记1入门篇document.write();是追加写，不是覆盖写。html是顺序读取的，所以插入到html中的js也是顺序执行的。JS中区分大小写；引用外部js文件&lt;script src=&quot;script.js&quot;&gt;&lt;/script&gt;定义函数： &lt;script type=&quot;text/javascript&quot;&gt; function funcname(){ alert(&quot;hello world!&quot;); } &lt;/script&gt; //调用 &lt;form&gt; &lt;input type=&quot;butten&quot; value=&quot;按钮&quot; submit=&quot;funcname()&quot; /&gt; &lt;/form&gt; 常用命令： document.write(&quot;向网页中写入内容&quot;); alert(&quot;弹窗&quot;); confirm(&quot;确定与否，确定返回真，取消返回假！&quot;); prompt(str1, str2);//弹窗，显示str1和文本框，文本框中为str2。确定返回文本框中的值，取消返回null。 window.open(&#39;URL&#39;,&#39;窗口名（新建窗口的位置）&#39;,&#39;参数&#39;) URL：可选参数，在窗口中要显示网页的网址或路径。如果省略这个参数，或者它的值是空字符串，那么窗口就不显示任何文档。 窗口名称：可选参数，被打开窗口的名称。 1.该名称由字母、数字和下划线字符组成。 2.&quot;_top&quot;、&quot;_blank&quot;、&quot;_self&quot;具有特殊意义的名称。 _blank：在新窗口显示目标网页 _self：在当前窗口显示目标网页 _top：框架网页中在上部窗口中显示目标网页 3.相同 name 的窗口只能创建一个，要想创建多个窗口则 name 不能相同。 4.name 不能包含有空格。 参数字符串：可选参数，设置窗口参数，各参数用逗号隔开。 window.close();//关闭窗口 object=document.getElementById(&quot;id_num&quot;);//返回html对应DOM对象 Object.innerHTML //用于获取或替换 HTML 元素的内容 Object.style.property=newstyle; 基本属性表（property）: Object.style.display = &quot;value&quot; value取值 var object=document.getElementById(&quot;p1&quot;); object.className = &quot;classname&quot;;//控制类名（className 属性） 实例： &lt;!DOCTYPE HTML&gt; &lt;html&gt; &lt;head&gt; &lt;meta http-equiv=&quot;txttent-Type&quot; txttent=&quot;text/html; charset=utf-8&quot; /&gt; &lt;title&gt;javascript&lt;/title&gt; &lt;style type=&quot;text/css&quot;&gt; body{font-size:12px;} #txt{ height:400px; width:600px; border:#333 solid 1px; padding:5px;} p{ line-height:18px; text-indent:2em;} &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;h2 id=&quot;con&quot;&gt;JavaScript课程&lt;/H2&gt; &lt;div id=&quot;txt&quot;&gt; &lt;h5&gt;JavaScript为网页添加动态效果并实现与用户交互的功能。&lt;/h5&gt; &lt;p&gt;1. JavaScript入门篇，让不懂JS的你，快速了解JS。&lt;/p&gt; &lt;p&gt;2. JavaScript进阶篇，让你掌握JS的基础语法、函数、数组、事件、内置对象、BOM浏览器、DOM操作。&lt;/p&gt; &lt;p&gt;3. 学完以上两门基础课后，在深入学习JavaScript的变量作用域、事件、对象、运动、cookie、正则表达式、ajax等课程。&lt;/p&gt; &lt;/div&gt; &lt;form&gt; &lt;!--当点击相应按钮，执行相应操作，为按钮添加相应事件--&gt; &lt;input type=&quot;button&quot; value=&quot;改变颜色&quot; onclick=&quot;set.changeColor()&quot;&gt; &lt;input type=&quot;button&quot; value=&quot;改变宽高&quot; onclick=&quot;set.changeSize()&quot;&gt; &lt;input type=&quot;button&quot; value=&quot;隐藏内容&quot; onclick=&quot;set.objHide()&quot;&gt; &lt;input type=&quot;button&quot; value=&quot;显示内容&quot; onclick=&quot;set.objShow()&quot;&gt; &lt;input type=&quot;button&quot; value=&quot;取消设置&quot; onclick=&quot;set.offSet()&quot;&gt; &lt;/form&gt; &lt;script type=&quot;text/javascript&quot;&gt; var txt=document.getElementById(&quot;txt&quot;); var set={ changeColor:function(){ txt.style.color=&quot;red&quot;; txt.style.backgroundColor=&quot;#ccc&quot;; }, changeSize:function(){ txt.style.width=&quot;300px&quot;; txt.style.height=&quot;300px&quot;; }, objHide:function(){ txt.style.display=&quot;none&quot;; }, objShow:function(){ txt.style.display=&quot;block&quot;; }, offSet:function(){ var message=confirm(&quot;你确定要重置所有设置么？&quot;); if(message==true){ txt.removeAttribute(&#39;style&#39;); } } } &lt;/script&gt; &lt;/body&gt; &lt;/html&gt;]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>js,前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[毕业设计]]></title>
    <url>%2F2017%2F11%2F03%2F%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[定题 面向容器级别的虚拟化存储研究 案例研究speedy，容器镜像高性能存储解决方案。https://github.com/jcloudpub/speedy田琪：我们通过Docker搭建了我们的弹性计算云平台，服务于公司内外各项业务。在搭建整个平台过程中遇到了很多问题，存储是其中一项待解决的问题。Docker官方提供了Docker Registry服务，但是最终的镜像文件落地存储并没有提供，目前支持的第三方存储服务主要是S3、Swift等。 我们也调研了一些开源分布式存储项目。发现主要存在几个问题：一是架构上倾向于无中心，或者一致性哈希等方式管理存储节点，运维方面我们比较担心可控性问题，另外增减机器都需要涉及文件数据的迁移，不利于线上系统稳定。二是大多开源方案都没有提供高性能的存储引擎，即只提供了数据分布的算法，但数据落地没有提供存储层的优化，这样产生大量文件时就会存在性能问题。三是针对大文件没有特别的优化措施。 认识到这些问题后，我们决定自己研发分布式存储系统，来解决和优化上述的问题。 特点 C语言编写的存储引擎高性能，高效率 高可用，存储实例多副本和无状态前后端代理的镜像服务器 高可控，弱化中心主节点，上传和下载不会通过中心主节点 高可扩展性，动态添加存储实例，前后端无状态镜像服务器 大文件被分成小块，从而可以快速并发的上传和下载这些块 仪表盘存储监控系统 仪表盘丰富的操控工具 支持docker 仓库1.0 API 架构 组成部分docker-registry-speedy-driverimageserver 镜像服务器块服务器主节点块服务器Docker Registry Driver是一个遵照Docker Registry 1.0协议实现的驱动，完成Docker Registry与后端存储系统的对接工作。ChunkServer与ChunkMaster组成了一个通用的对象存储服务，ChunkMaster是中心节点，缓存了所有ChunkServer的信息，ChunkServer本身是最终镜像数据落地的存储节点，多个ChunkServer会构成一个组，拥有唯一的组ID，上传这个组内的所有ChunkServer都成功才算成功，下载可以随机选择其中一个节点下载。ImageServer本身是一个无状态的Proxy服务，它相当于是后面通用对象存储服务的一个接入层，Driver发起的镜像上传/下载操作会直接发给ImageServer, ImageServer里面缓存了ChunkMaster中的存储节点信息，通过这些信息，ImageServer会进行ChunkServer节点的选择操作，找到一组合适的ChunkServer机器完成镜像的上传或下载操作。 元数据服务器他是另外一个分布式的键值存储，尚未开源。你可以利用mysql代替他存储镜像层的元数据信息。 启动顺序1.metaserver2.chunkmaster3.chunkserver4.imageserver5.docker-registry After that you can push and pull docker images. 上传流程：首先我们通过docker push命令发起上传镜像的操作，docker本身会进行多次与后端存储系统的交互，最后一次交互是上传image的layer数据到Docker Registry。 这里我要简单吐个槽，合理的情况是这个结构化数据和非结构化数据分开存储，docker本身用json表示结构化的描述信息，也是上传到后端存储系统的，个人觉得docker的元数据管理方面很混乱。 如果使用默认的本地存储，Docker Registry就直接把数据写到了磁盘上，我们这里通过自己实现的Driver完成与后端对象存储系统的上传工作。 我们的Driver首先会对源源不断上传过来的字节流进行切割，按照配置的固定大小并发上传到ImageServer中，并在上传的http请求中携带了该分片的索引及位置信息。 ImageServer在收到该分片上传请求后，根据自己从ChunkMaster中同步过来的chunk信息来动态选择一组ChunkServer，并将分片上传到该组ChunkServer中的所有实例上，都成功才返回成功。并将分片索引位置信息及上传成功返回的文件ID提交给MetaServer保存. Driver在收到所有分片的上传成功返回后，再返回给前端Docker，整个上传流程结束。 下载流程：首先docker通过docker pull请求下载镜像，同样在真正下载数据开始前，docker同Docker Registry以及后端的存储系统间也会产生多次的数据交互，这里省略，最后一步是下载对应的Image Layer数据。 Docker Registry在收到下载请求后首先通过ImageServer从MetaServer里获取到该文件path对应的分片信息，主要是分片的个数，及每一片的索引，然后将这些分片下载请求并发的发送给ImageServer服务器。 ImageServer收到分片下载请求后，查询MetaServer获得对应的文件ID，该文件ID中包含有ChunkServer的位置信息，随后请求相应ChunkServer下载数据并返回给Driver。 Driver收到分片下载的数据后，会根据分片的位置索引进行排序，按文件分片顺序返回给Docker。 研究内容 metadata组织形式（他是没有开源的）。 另外一个就是driver部分，他目前用的是device-mapper，他也提到overlayfs。 a. 我们可以在dm上面做文章，加上我们的重删。 b. 利用overlayfs，做driver，这个工作量估计有点大。 1、Docker镜像存储技术探秘 我们首先思考一个问题，docker本质上都涉及了哪些方面的技术： Linux内核系统技术，如：Namespace, Cgroup等；存储技术，如：镜像的存储，镜像的CoW所需的文件系统，如：overlayfs, aufs, dm等；网络技术，如：libnetwork，flannel等开源项目主要来解决容器的网络互通及SDN等问题。我们今天的话题主要集中在存储技术方面，也就是和镜像相关，docker依赖的存储技术方面也是分为两个方面： 单机内核层存储技术，也就是overlayfs, aufs等主要用于提供镜像的CoW机制，解决的是一台物理资源跑多个容器，多个容器之间共享同一个rootfs，然后各自修改是通过CoW完成的，这样解决存储空间等问题。这个话题我已经公开分享过很多次，不再多说了。另一层面，当我们使用Docker过程中，可能会使用到很多不同的镜像，这些镜像本身也是需要存储的，我们需要一个靠可用的可扩展的分布式存储系统。我们今天就详细讨论这两个方面的技术选型，Docker镜像驱动的选择。默认支持的驱动主要有这几个： Dockerbtrfsaufsoverlayfsdevice mappervfs个人认为我们的选择主要是在overlayfs与device mapper之间，btrfs因为目前还没有production ready，生产环境用的公司应该很少，aufs因为没有进入主线内核，且代码庞大书写风格又比较混乱，所以也不是很看好，目前只有少数发行版默认支持这个文件系统。 而vfs则是完全没有解决任何问题，比如一台物理机跑100个容器，则相应的rootfs会独立保存100份，这个完全没法接受，所以最终我们很可能是在overlayfs与device mapper之间进行选择。 ovelayfs简介： overlayfs本身是一个叠加文件系统，用于叠合多个文件系统形成一个新的文件系统，使用方式如下： mount -t overlay overlay -olowerdir=/lower, upperdir=/upper, workdir=/work /merged 简单的说overlayfs通过Linux内核VFS层的灵活性能够将对文件A的修改变成对B的修改，利用这种灵活性来完成文件系统叠加的效果。比如指令： /lower：是下层的文件系统，通常是只读的。可以放我们的镜像模板的rootfs 如果我们要对其中某个文件做修改，比如文件A，则overlayfs会将该文件拷贝到/upper目录中修改，也就是实现了文件级别的CoW。/merged ：是最终叠加后形成的文件系统，也就是用户实际使用看到叠加效果后的文件系统。device-mapper简介： device-mapper(后面简称dm)本身是一个位于内核通用块层的一个框架，完成内核IO的一些策略定制等功能，比如可以通过dm完成磁盘的软raid功能，比如facebook前些时间开源的flashcache缓存方案也是基于device-mapper的。 DM是一个框架，提供了通用的一套框架完成IO的重定向及定制等策略，它包含很多具体的策略实现，Docker用到的是其中的thin-provision。thin-provision本质上提供两个功能： 磁盘空间按需分配，这个特点决定了如果Docker使用dm驱动，则对应的盘大小默认10G，实际是不占任何空间的，直到你真正写入数据，才会占用实际的磁盘空间。基于block块粒度的CoW，如上面overlayfs原理类似，我要修改一个文件，thin-provision会将修改的部分对应的磁盘块单独拷贝出来一份修改，这里粒度是要小于overlayfs的。dm与overlayfs之间的选择： 从上面原理上分析不难得出一个结论，dm的CoW的粒度是要比overlayfs的小的，也就是说如果用overlayfs做驱动，存在的问题是如果模板rootfs中有个比较大的文件在大多数容器中都可能会动态修改，则这个文件需要整个copyup到上层文件系统，而用dm则只需要CoW修改的那个块。 从这方面讲dm是占优的，但是dm在使用中存在很多功能限制，因为它本身是一个块设备，所以并不了解上层文件系统的细节，使用中存在种种限制，并且在文件系统缓存这层也没有overlayfs有效。但是overlayfs需要3.18以上kernel才支持。大多数Linux发行版还不支持这么高的内核版本，所以需要单独编译。 综合考虑，个人认为当前用dm是可以接受的选择，未来可能会切换到overlayfs上。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>容器,计划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python time datetime学习]]></title>
    <url>%2F2017%2F10%2F25%2Fpython%20time%20datetime%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python,时间处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据可视化echarts]]></title>
    <url>%2F2017%2F10%2F25%2Fpython%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96bokeh%2F</url>
    <content type="text"><![CDATA[功能 展示数据 就是向人家写好的框架里面填充数据。调参侠！ 常用图形常用API前后端代码模板]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python,数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongodb 学习笔记]]></title>
    <url>%2F2017%2F10%2F23%2Fmongodb%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[mongodb简介 mongodb安装mongodb常用命令显示所有数据库show dbs 显示该数据库下所有集合（表）show collections或者show tables 显示集合中所有数据（查询）# 输出 &gt; db.col.find() { &quot;_id&quot; : ObjectId(&quot;59edaea04995c58db2af8d2d&quot;), &quot;title&quot; : &quot;MongoDB&quot;, &quot;by&quot; : &quot;NB教程&quot; } { &quot;_id&quot; : ObjectId(&quot;59edafca4995c58db2af8d2e&quot;), &quot;title&quot; : &quot;MongoDB&quot;, &quot;description&quot; : &quot;MongoDB 是一个 Nosql 数据库&quot;, &quot;by&quot; : &quot;NB教程&quot;, &quot;url&quot; : &quot;http://www.runoob.com&quot;, &quot;tags&quot; : [ &quot;mongodb&quot;, &quot;database&quot;, &quot;NoSQL&quot; ], &quot;likes&quot; : 100 } # 格式化输出 &gt; db.col.find().pretty() { &quot;_id&quot; : ObjectId(&quot;59edaea04995c58db2af8d2d&quot;), &quot;title&quot; : &quot;MongoDB&quot;, &quot;by&quot; : &quot;NB教程&quot; } { &quot;_id&quot; : ObjectId(&quot;59edafca4995c58db2af8d2e&quot;), &quot;title&quot; : &quot;MongoDB&quot;, &quot;description&quot; : &quot;MongoDB 是一个 Nosql 数据库&quot;, &quot;by&quot; : &quot;NB教程&quot;, &quot;url&quot; : &quot;http://www.runoob.com&quot;, &quot;tags&quot; : [ &quot;mongodb&quot;, &quot;database&quot;, &quot;NoSQL&quot; ], &quot;likes&quot; : 100 } 操作 格式 范例 RDBMS中的类似语句 等于 {&lt;key&gt;:&lt;value&gt;} db.col.find({“by”:”菜鸟教程”}).pretty() where by = ‘菜鸟教程’ 小于 {&lt;key&gt;:{$lt:&lt;value&gt;}} db.col.find({“likes”:{$lt:50}}).pretty() where likes &lt; 50 小于或等于 {&lt;key&gt;:{$lte:&lt;value&gt;}} db.col.find({“likes”:{$lte:50}}).pretty() where likes &lt;= 50 大于 {&lt;key&gt;:{$gt:&lt;value&gt;}} db.col.find({“likes”:{$gt:50}}).pretty() where likes &gt; 50 大于或等于 {&lt;key&gt;:{$gte:&lt;value&gt;}} db.col.find({“likes”:{$gte:50}}).pretty() where likes &gt;= 50 不等于 {&lt;key&gt;:{$ne:&lt;value&gt;}} db.col.find({“likes”:{$ne:50}}).pretty() where likes != 50 AND 和 OR 联合使用以下实例演示了 AND 和 OR 联合使用，类似常规 SQL 语句为： &#39;where likes&gt;50 AND (by = &#39;菜鸟教程&#39; OR title = &#39;MongoDB 教程&#39;)&#39; &gt;db.col.find({&quot;likes&quot;: {$gt:50}, $or: [{&quot;by&quot;: &quot;菜鸟教程&quot;},{&quot;title&quot;: &quot;MongoDB 教程&quot;}]}).pretty() { &quot;_id&quot; : ObjectId(&quot;56063f17ade2f21f36b03133&quot;), &quot;title&quot; : &quot;MongoDB 教程&quot;, &quot;description&quot; : &quot;MongoDB 是一个 Nosql 数据库&quot;, &quot;by&quot; : &quot;菜鸟教程&quot;, &quot;url&quot; : &quot;http://www.runoob.com&quot;, &quot;tags&quot; : [ &quot;mongodb&quot;, &quot;database&quot;, &quot;NoSQL&quot; ], &quot;likes&quot; : 100 } 连接数据库使用用户名和密码连接登陆到指定数据库，格式如下：mongodb://admin:123456@localhost/test 创建数据库use dbname如果数据库存在，则切换到dbname，如果不存在，则创建。刚创建完成后，使用show dbs命令，看不到dbname，必须向dbname中添加数据后才能显示。 删除数据库&gt; show dbs admin 0.000GB fdl 0.000GB local 0.000GB test 0.000GB &gt; use fdl switched to db fdl &gt; db.dropDatabase() 2017-10-23T16:54:13.853+0800 I COMMAND [conn1] dropDatabase fdl starting 2017-10-23T16:54:13.857+0800 I COMMAND [conn1] dropDatabase fdl finished { &quot;dropped&quot; : &quot;fdl&quot;, &quot;ok&quot; : 1 } &gt; show dbs admin 0.000GB local 0.000GB test 0.000GB 向collection添加数据db.collectionname.insert({&quot;name&quot;:&quot;fandeliang&quot;}) # 插入单条数据 &gt; var document = db.collection.insertOne({&quot;a&quot;: 3}) &gt; document { &quot;acknowledged&quot; : true, &quot;insertedId&quot; : ObjectId(&quot;571a218011a82a1d94c02333&quot;) } # 插入多条数据 &gt; var res = db.collection.insertMany([{&quot;b&quot;: 3}, {&#39;c&#39;: 4}]) &gt; res { &quot;acknowledged&quot; : true, &quot;insertedIds&quot; : [ ObjectId(&quot;571a22a911a82a1d94c02337&quot;), ObjectId(&quot;571a22a911a82a1d94c02338&quot;) ] } 更新数据注意加不加$set:的区别。 &gt; use test switched to db test &gt; db.col.insert({ ... title: &#39;MongoDB 教程&#39;, ... description: &#39;MongoDB 是一个 Nosql 数据库&#39;, ... by: &#39;菜鸟教程&#39;, ... url: &#39;http://www.runoob.com&#39;, ... tags: [&#39;mongodb&#39;, &#39;database&#39;, &#39;NoSQL&#39;], ... likes: 100 ... }) WriteResult({ &quot;nInserted&quot; : 1 }) &gt; show tables; col runoob &gt; db.col.find() { &quot;_id&quot; : ObjectId(&quot;59edaea04995c58db2af8d2d&quot;), &quot;title&quot; : &quot;MongoDB 教程&quot;, &quot;description&quot; : &quot;MongoDB 是一个 Nosql 数据库&quot;, &quot;by&quot; : &quot;菜鸟教程&quot;, &quot;url&quot; : &quot;http://www.runoob.com&quot;, &quot;tags&quot; : [ &quot;mongodb&quot;, &quot;database&quot;, &quot;NoSQL&quot; ], &quot;likes&quot; : 100 } &gt; db.col.update({&quot;title&quot;:&quot;MongoDB 教程&quot;},{&quot;title&quot;:&quot;MongoDB&quot;,&quot;by&quot;:&quot;NB教程&quot;}) WriteResult({ &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 }) &gt; db.col.find() { &quot;_id&quot; : ObjectId(&quot;59edaea04995c58db2af8d2d&quot;), &quot;title&quot; : &quot;MongoDB&quot;, &quot;by&quot; : &quot;NB教程&quot; } &gt; db.col.find().pretty() { &quot;_id&quot; : ObjectId(&quot;59edaea04995c58db2af8d2d&quot;), &quot;title&quot; : &quot;MongoDB&quot;, &quot;by&quot; : &quot;NB教程&quot; } &gt; db.col.insert({ ... title: &#39;MongoDB 教程&#39;, ... description: &#39;MongoDB 是一个 Nosql 数据库&#39;, ... by: &#39;菜鸟教程&#39;, ... url: &#39;http://www.runoob.com&#39;, ... tags: [&#39;mongodb&#39;, &#39;database&#39;, &#39;NoSQL&#39;], ... likes: 100 ... }) WriteResult({ &quot;nInserted&quot; : 1 }) &gt; db.col.update({&quot;title&quot;:&quot;MongoDB 教程&quot;},{$set:{&quot;title&quot;:&quot;MongoDB&quot;,&quot;by&quot;:&quot;NB教程&quot;}}) WriteResult({ &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 }) &gt; db.col.find().pretty() { &quot;_id&quot; : ObjectId(&quot;59edaea04995c58db2af8d2d&quot;), &quot;title&quot; : &quot;MongoDB&quot;, &quot;by&quot; : &quot;NB教程&quot; } { &quot;_id&quot; : ObjectId(&quot;59edafca4995c58db2af8d2e&quot;), &quot;title&quot; : &quot;MongoDB&quot;, &quot;description&quot; : &quot;MongoDB 是一个 Nosql 数据库&quot;, &quot;by&quot; : &quot;NB教程&quot;, &quot;url&quot; : &quot;http://www.runoob.com&quot;, &quot;tags&quot; : [ &quot;mongodb&quot;, &quot;database&quot;, &quot;NoSQL&quot; ], &quot;likes&quot; : 100 } 更多实例 只更新第一条记录： db.col.update( { &quot;count&quot; : { $gt : 1 } } , { $set : { &quot;test2&quot; : &quot;OK&quot;} } ); 全部更新： db.col.update( { &quot;count&quot; : { $gt : 3 } } , { $set : { &quot;test2&quot; : &quot;OK&quot;} },false,true ); 只添加第一条： db.col.update( { &quot;count&quot; : { $gt : 4 } } , { $set : { &quot;test5&quot; : &quot;OK&quot;} },true,false ); 全部添加加进去: db.col.update( { &quot;count&quot; : { $gt : 5 } } , { $set : { &quot;test5&quot; : &quot;OK&quot;} },true,true ); 全部更新： db.col.update( { &quot;count&quot; : { $gt : 15 } } , { $inc : { &quot;count&quot; : 1} },false,true ); 只更新第一条记录： db.col.update( { &quot;count&quot; : { $gt : 10 } } , { $inc : { &quot;count&quot; : 1} },false,false ); 删除数据&gt; db.col.find().pretty() { &quot;_id&quot; : ObjectId(&quot;59edaea04995c58db2af8d2d&quot;), &quot;title&quot; : &quot;MongoDB&quot;, &quot;by&quot; : &quot;NB教程&quot; } { &quot;_id&quot; : ObjectId(&quot;59edafca4995c58db2af8d2e&quot;), &quot;title&quot; : &quot;MongoDB&quot;, &quot;description&quot; : &quot;MongoDB 是一个 Nosql 数据库&quot;, &quot;by&quot; : &quot;NB教程&quot;, &quot;url&quot; : &quot;http://www.runoob.com&quot;, &quot;tags&quot; : [ &quot;mongodb&quot;, &quot;database&quot;, &quot;NoSQL&quot; ], &quot;likes&quot; : 100 } &gt; db.col.remove({&#39;title&#39;:&quot;MongoDB&quot;}) WriteResult({ &quot;nRemoved&quot; : 2 }) &gt; db.col.find().pretty() &gt; db.collection.remove( &lt;query&gt;, { justOne: &lt;boolean&gt;, writeConcern: &lt;document&gt; } ) 参数说明： query :（可选）删除的文档的条件。 justOne : （可选）如果设为 true 或 1，则只删除一个文档。 writeConcern :（可选）抛出异常的级别。 如果你想删除所有数据，可以使用以下方式（类似常规 SQL 的 truncate 命令）： &gt;db.col.remove({}) &gt;db.col.find() &gt; $type 操作符 MongoDB 中可以使用的类型如下表所示：类型 数字 备注Double 1String 2Object 3Array 4Binary data 5Undefined 6 已废弃。Object id 7Boolean 8Date 9Null 10Regular Expression 11JavaScript 13Symbol 14JavaScript (with scope) 1532-bit integer 16Timestamp 1764-bit integer 18Min key 255 Query with -1.Max key 127 如果想获取 &quot;col&quot; 集合中 title 为 String 的数据，你可以使用以下命令： db.col.find({&quot;title&quot; : {$type : 2}}) 输出结果为： { &quot;_id&quot; : ObjectId(&quot;56066542ade2f21f36b0313a&quot;), &quot;title&quot; : &quot;PHP 教程&quot;, &quot;description&quot; : &quot;PHP 是一种创建动态交互性站点的强有力的服务器端脚本语言。&quot;, &quot;by&quot; : &quot;菜鸟教程&quot;, &quot;url&quot; : &quot;http://www.runoob.com&quot;, &quot;tags&quot; : [ &quot;php&quot; ], &quot;likes&quot; : 200 } { &quot;_id&quot; : ObjectId(&quot;56066549ade2f21f36b0313b&quot;), &quot;title&quot; : &quot;Java 教程&quot;, &quot;description&quot; : &quot;Java 是由Sun Microsystems公司于1995年5月推出的高级程序设计语言。&quot;, &quot;by&quot; : &quot;菜鸟教程&quot;, &quot;url&quot; : &quot;http://www.runoob.com&quot;, &quot;tags&quot; : [ &quot;java&quot; ], &quot;likes&quot; : 150 } { &quot;_id&quot; : ObjectId(&quot;5606654fade2f21f36b0313c&quot;), &quot;title&quot; : &quot;MongoDB 教程&quot;, &quot;description&quot; : &quot;MongoDB 是一个 Nosql 数据库&quot;, &quot;by&quot; : &quot;菜鸟教程&quot;, &quot;url&quot; : &quot;http://www.runoob.com&quot;, &quot;tags&quot; : [ &quot;mongodb&quot; ], &quot;likes&quot; : 100 } Limit , Skip 和sort()方法 如果你需要在MongoDB中读取指定数量的数据记录，可以使用MongoDB的Limit方法，limit()方法接受一个数字参数，该参数指定从MongoDB中读取的记录条数。我们除了可以使用limit()方法来读取指定数量的数据外，还可以使用skip()方法来跳过指定数量的数据，skip方法同样接受一个数字参数作为跳过的记录条数。在MongoDB中使用使用sort()方法对数据进行排序，sort()方法可以通过参数指定排序的字段，并使用 1 和 -1 来指定排序的方式，其中 1 为升序排列，而-1是用于降序排列。当查询时同时使用sort,skip,limit，无论位置先后，最先执行顺序 sort再skip再limit。 想要读取从 10 条记录后 100 条记录，相当于 sql 中limit (10,100)。 &gt; db.COLLECTION_NAME.find().skip(10).limit(100) 以上实例在集合中跳过前面 10 条返回 100 条数据。 skip 和 limit 结合就能实现分页。 db.col.find({},{&quot;title&quot;:1,_id:0}).limit(2) 补充说明： 第一个 {} 放 where 条件，为空表示返回集合中所有文档。 第二个 {} 指定那些列显示和不显示 （0表示不显示 1表示显示)。 &gt;db.col.find({},{&quot;title&quot;:1,_id:0}).sort({&quot;likes&quot;:-1}) { &quot;title&quot; : &quot;PHP 教程&quot; } { &quot;title&quot; : &quot;Java 教程&quot; } { &quot;title&quot; : &quot;MongoDB 教程&quot; } &gt; ###]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>mongodb,数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux镜像源整理]]></title>
    <url>%2F2017%2F09%2F30%2FLinux%E9%95%9C%E5%83%8F%E6%BA%90%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[各种Linux发行版源配置Linux国内常用源的介绍和使用Linux镜像源 国内列表 Ubuntu源配置 站点版企业站1.搜狐：http://mirrors.sohu.com/2.网易：http://mirrors.163.com/3.阿里云：http://mirrors.aliyun.com/4.腾讯：http://android-mirror.bugly.qq.com:8080/（仅针对APP开发的软件，限流，不推荐） 教育站1.上海交通大学：http://ftp.sjtu.edu.cn/html/resources.xml（部分移动运营商出口状况不佳，无法访问）2.华中科技大学：http://mirror.hust.edu.cn/（当前已用容量估计：4.83T）3.清华大学：http://mirrors.tuna.tsinghua.edu.cn/（当前已用容量估计：9.8T）4.北京理工大学：http://mirror.bit.edu.cn/web/5.兰州大学：http://mirror.lzu.edu.cn/6.中国科技大学：http://mirrors.ustc.edu.cn/（当前已用容量估计：21.32T）7.大连东软信息学院：http://mirrors.neusoft.edu.cn/（当前已用容量估计：2.5T）8.东北大学：http://mirror.neu.edu.cn/9.大连理工大学：http://mirror.dlut.edu.cn/10.哈尔滨工业大学：http://run.hit.edu.cn/html/（部分联通运营商出口状况不佳，无法访问）11.北京交通大学：http://mirror.bjtu.edu.cn/cn/12.天津大学：http://mirror.tju.edu.cn（无法访问，ping超时）13.中国地质大学：http://mirrors.cug.edu.cn/（当前已用容量估计：2.3T）14.浙江大学：http://mirrors.zju.edu.cn/15.厦门大学：http://mirrors.xmu.edu.cn/16.中山大学：http://mirror.sysu.edu.cn/17.重庆大学：http://mirrors.cqu.edu.cn/（当前已用容量估计：3.93T）18.北京化工大学：http://ubuntu.buct.edu.cn/（Android SDK镜像仅供校内使用，当前已用容量估计：1.72T）19.南阳理工学院：http://mirror.nyist.edu.cn/20.中国科学院：http://www.opencas.org/mirrors/21.电子科技大学：http://ubuntu.uestc.edu.cn/（无法访问，ping超时）22.电子科技大学星辰工作室：http://mirrors.stuhome.net/（当前已用容量估计：1.08T）23.西北农林科技大学：http://mirrors.nwsuaf.edu.cn/（只做CentOS镜像，当前已用容量估计：140GB） 其他1.首都在线科技股份有限公司（英文名Capital Online Data Service）：http://mirrors.yun-idc.com/2.中国电信天翼云：http://mirrors.ctyun.cn/3.noc.im：http://mirrors.noc.im/（当前已用容量估计：3.74T）4.常州贝特康姆软件技术有限公司：http://centos.bitcomm.cn/（只做CentOS镜像，当前已用容量估计：140GB）5.公云PubYun（母公司为贝特康姆）：http://mirrors.pubyun.com/6.Linux运维派：http://mirrors.skyshe.cn/（使用阿里云服务器，界面使用浙江大学的模板，首页维护，内容可访问）7.中国互联网络信息中心：http://mirrors.cnnic.cn/（只做Apache镜像，当前已用容量估计：120GB）8.Fayea工作室：http://apache.fayea.com/（只做Apache镜像，当前已用容量估计：120GB） 软件版操作系统类1.Ubuntu阿里云：http://mirrors.aliyun.com/ubuntu-releases/网易：http://mirrors.163.com/ubuntu-releases/搜狐：http://mirrors.sohu.com/ubuntu-releases/（搜狐在12年之后似乎不同步了）首都在线科技股份有限公司：http://mirrors.yun-idc.com/ubuntu-releases/ 2.centos网易：http://mirrors.163.com/centos/搜狐：http://mirrors.sohu.com/centos/阿里云：http://mirrors.aliyun.com/centos/ 服务器类1.tomcat、Apache中国互联网络信息中心：http://mirrors.cnnic.cn/apache/华中科技大学：http://mirrors.hust.edu.cn/apache/北京理工大学：http://mirror.bit.edu.cn/apache/ 2.MySQL北京理工大学：http://mirror.bit.edu.cn/mysql/Downloads/中国电信天翼云：http://mirrors.ctyun.cn/Mysql/ 3.PostgreSQL浙江大学：http://mirrors.zju.edu.cn/postgresql/ 4.MariaDB中国电信天翼云：http://mirrors.ctyun.cn/MariaDB/ 5.VideoLAN大连东软信息学院：http://mirrors.neusoft.edu.cn/videolan/中国科技大学：http://mirrors.ustc.edu.cn/videolan-ftp/ 开发工具类1.eclipse中国科技大学：http://mirrors.ustc.edu.cn/eclipse/中国科学院：http://mirrors.opencas.cn/eclipse/东北大学：http://ftp.neu.edu.cn/mirrors/eclipse/，http://mirror.neu.edu.cn/eclipse/ 2.安卓SDK中国科学院：http://mirrors.opencas.ac.cn/android/repository/南洋理工学院：http://mirror.nyist.edu.cn/android/repository/中国科学院：http://mirrors.opencas.cn/android/repository/腾讯：http://android-mirror.bugly.qq.com:8080/android/repository/（限流，不推荐）大连东软信息学院：http://mirrors.neusoft.edu.cn/android/repository/（同步效果不如中科院的镜像，不推荐） 3.Xcode腾讯：http://android-mirror.bugly.qq.com:8080/Xcode/（从7.2之后不再更新，建议直接从官网下载） 官方镜像列表状态地址CentOS：http://mirror-status.centos.org/#cnArchlinux：https://www.archlinux.org/mirrors/status/Ubuntu：https://launchpad.net/ubuntu/+cdmirrorsDebian：http://mirror.debian.org/status.htmlFedora Linux/Fedora EPEL：https://admin.fedoraproject.org/mirrormanager/mirrorsApache：http://www.apache.org/mirrors/#cnCygwin：https://www.cygwin.com/mirrors.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux,运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tcpdump 学习笔记]]></title>
    <url>%2F2017%2F09%2F29%2Ftcpdump%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[简介 dump the traffic on a network，根据使用者的定义对网络上的数据包进行截获的包分析工具。 tcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。它支持针对网络层、协议、主机、网络或端口的过滤，并提供and、or、not等逻辑语句来帮助你去掉无用的信息。 Linux 抓包原理 Linux抓包是通过注册一种虚拟的底层网络协议来完成对网络报文(准确的说是网络设备)消息的处理权。当网卡接收到一个网络报文之后，它会遍历系统中所有已经注册的网络协议，例如以太网协议、x25协议处理模块来尝试进行报文的解析处理，这一点和一些文件系统的挂载相似，就是让系统中所有的已经注册的文件系统来进行尝试挂载，如果哪一个认为自己可以处理，那么就完成挂载。 当抓包模块把自己伪装成一个网络协议的时候，系统在收到报文的时候就会给这个伪协议一次机会，让它来对网卡收到的报文进行一次处理，此时该模块就会趁机对报文进行窥探，也就是把这个报文完完整整的复制一份，假装是自己接收到的报文，汇报给抓包模块。 WiresharkWireshark是一个网络协议检测工具，支持Windows平台、Unix平台、Mac平台，一般只在图形界面平台下使用Wireshark，如果是Linux的话，直接使用tcpdump了，因为一般而言Linux都自带的tcpdump，或者用tcpdump抓包以后用Wireshark打开分析。 在Mac平台下，Wireshark通过WinPcap进行抓包，封装的很好，使用起来很方便，可以很容易的制定抓包过滤器或者显示过滤器，具体简单使用下面会介绍。Wireshark是一个免费的工具，只要google一下就能很容易找到下载的地方。 所以，tcpdump是用来抓取数据非常方便，Wireshark则是用于分析抓取到的数据比较方便。 使用语法tcpdump [ -AdDefIKlLnNOpqRStuUvxX ] [ -B buffer_size ] [ -c count ] [ -C file_size ] [ -G rotate_seconds ] [ -F file ] [ -i interface ] [ -m module ] [ -M secret ] [ -r file ] [ -s snaplen ] [ -T type ] [ -w file ] [ -W filecount ] [ -E spi@ipaddr algo:secret,... ] [ -y datalinktype ] [ -z postrotate-command ] [ -Z user ] [ expression ] 类型关键字 host(缺省类型): 指明一台主机，如：host 210.27.48.net: 指明一个网络地址，如：net 202.0.0.0port: 指明端口号，如：port 23 确定方向关键字 src: src 210.27.48.2, IP包源地址是210.27.48.2dst: dst net 202.0.0.0, 目标网络地址是202.0.0.0dst or src(缺省值)dst and src 协议的关键字：缺省值是监听所有协议的信息包 fddiiparprarptcpudp 其他关键字 gatewaybroadcastlessgreater 常用表达式：多条件时可以用括号，但是得用\转义 非：! or “not” (去掉双引号)且：&amp;&amp; or “and”或：|| or “or” 选项-A：以ASCII编码打印每个报文（不包括链路层的头），这对分析网页来说很方便； -a：将网络地址和广播地址转变成名字； -c&lt;数据包数目&gt;：在收到指定的包的数目后，tcpdump就会停止； -C：用于判断用 -w 选项将报文写入的文件的大小是否超过这个值，如果超过了就新建文件（文件名后缀是1、2、3依次增加）； -d：将匹配信息包的代码以人们能够理解的汇编格式给出； -dd：将匹配信息包的代码以c语言程序段的格式给出； -ddd：将匹配信息包的代码以十进制的形式给出； -D：列出当前主机的所有网卡编号和名称，可以用于选项 -i； -e：在输出行打印出数据链路层的头部信息； -f：将外部的Internet地址以数字的形式打印出来； -F&lt;表达文件&gt;：从指定的文件中读取表达式,忽略其它的表达式； -i&lt;网络界面&gt;：监听主机的该网卡上的数据流，如果没有指定，就会使用最小网卡编号的网卡（在选项-D可知道，但是不包括环路接口），linux 2.2 内核及之后的版本支持 any 网卡，用于指代任意网卡； -l：如果没有使用 -w 选项，就可以将报文打印到 标准输出终端（此时这是默认）； -n：显示ip，而不是主机名； -N：不列出域名； -O：不将数据包编码最佳化； -p：不让网络界面进入混杂模式； -q：快速输出，仅列出少数的传输协议信息； -r&lt;数据包文件&gt;：从指定的文件中读取包(这些包一般通过-w选项产生)； -s&lt;数据包大小&gt;：指定抓包显示一行的宽度，-s0表示可按包长显示完整的包，经常和-A一起用，默认截取长度为60个字节，但一般ethernet MTU都是1500字节。所以，要抓取大于60字节的包时，使用默认参数就会导致包数据丢失； -S：用绝对而非相对数值列出TCP关联数； -t：在输出的每一行不打印时间戳； -tt：在输出的每一行显示未经格式化的时间戳记； -T&lt;数据包类型&gt;：将监听到的包直接解释为指定的类型的报文，常见的类型有rpc （远程过程调用）和snmp（简单网络管理协议）； -v：输出一个稍微详细的信息，例如在ip包中可以包括ttl和服务类型的信息； -vv：输出详细的报文信息； -x/-xx/-X/-XX：以十六进制显示包内容，几个选项只有细微的差别，详见man手册； -w&lt;数据包文件&gt;：直接将包写入文件中，并不分析和打印出来； expression：用于筛选的逻辑表达式； 命令实践 直接启动tcpdump，将抓取所有经过第一个网络接口上的数据包 tcpdump 控制台输出： @dl  sudo tcpdump [sudo] dl 的密码： tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on wlp2s0, link-type EN10MB (Ethernet), capture size 262144 bytes 23:56:46.929328 IP 192.168.1.131.50220 &gt; 192.168.1.1.domain: 47168+ A? baidu.com. (27) 23:56:46.929357 IP 192.168.1.131.50220 &gt; 192.168.1.1.domain: 10125+ AAAA? baidu.com. (27) 23:56:46.929918 IP 192.168.1.131.40552 &gt; 192.168.1.1.domain: 15187+ PTR? 1.1.168.192.in-addr.arpa. (42) 23:56:46.936167 ARP, Request who-has 192.168.1.131 tell 192.168.1.1, length 28 抓取所有经过 en0，目的或源地址是 10.37.63.255 的网络数据： tcpdump -i en0 host 10.37.63.255 抓取主机10.37.63.255和主机10.37.63.61或10.37.63.95的通信： tcpdump host 10.37.63.255 and \(10.37.63.61 or 10.37.63.95 \) taomingkais-MacBook-Pro:~ TaoBangren$ sudo tcpdump host 10.37.63.255 and \(10.37.63.61 or 10.37.63.95 \) tcpdump: data link type PKTAP tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on pktap, link-type PKTAP (Packet Tap), capture size 262144 bytes 11:10:38.395320 IP 10.37.63.61.netbios-ns &gt; 10.37.63.255.netbios-ns: NBT UDP PACKET(137): QUERY; REQUEST; BROADCAST 11:10:39.234047 IP 10.37.63.61.netbios-ns &gt; 10.37.63.255.netbios-ns: NBT UDP PACKET(137): QUERY; REQUEST; BROADCAST 11:10:39.962286 IP 10.37.63.61.netbios-ns &gt; 10.37.63.255.netbios-ns: NBT UDP PACKET(137): QUERY; REQUEST; BROADCAST 11:10:48.422443 IP 10.37.63.61.netbios-ns &gt; 10.37.63.255.netbios-ns: NBT UDP PACKET(137): QUERY; REQUEST; BROADCAST 11:10:49.153630 IP 10.37.63.61.netbios-ns &gt; 10.37.63.255.netbios-ns: NBT UDP PACKET(137): QUERY; REQUEST; BROADCAST 11:10:49.894146 IP 10.37.63.61.netbios-ns &gt; 10.37.63.255.netbios-ns: NBT UDP PACKET(137): QUERY; REQUEST; BROADCAST 11:10:52.600297 IP 10.37.63.61.netbios-ns &gt; 10.37.63.255.netbios-ns: NBT UDP PACKET(137): QUERY; REQUEST; BROADCAST 抓取主机10.37.63.3所有在TCP 80端口接收到的数据包： tcpdump -i en0 host 10.37.63.3 and dst tcp port 80 抓取所有经过 en0，目标 MAC 地址是 00:01:02:03:04:05 的 ICMP 数据 tcpdump -i eth1 &#39;((icmp) and ((ether dst host 00:01:02:03:04:05)))&#39; 抓SYN，ACK tcpdump -i en0 &#39;tcp[tcpflags] &amp; tcp-syn != 0 and tcp[tcpflags] &amp; tcp-ack != 0&#39; 抓 SMTP 数据，抓取数据区开始为”MAIL”的包，”MAIL”的十六进制为 0x4d41494c tcpdump -i en0 &#39;((port 25) and (tcp[(tcp[12]&gt;&gt;2):4] = 0x4d41494c))&#39; 抓 HTTP GET 数据，”GET “的十六进制是 0x47455420```tcpdump -i en0 ‘tcp[(tcp[12]&gt;&gt;2):4] = 0x47455420’ 0x4745 为”GET”前两个字母”GE”,0x4854 为”HTTP”前两个字母”HT”tcpdump -XvvennSs 0 -i en0 tcp[20:2]=0x4745 or tcp[20:2]=0x4854 9. 抓 SSH 返回，&quot;SSH-&quot;的十六进制是 0x5353482D tcpdump -i en0 ‘tcp[(tcp[12]&gt;&gt;2):4] = 0x5353482D’ 抓老版本的 SSH 返回信息，如”SSH-1.99..”tcpdump -i en0 ‘(tcp[(tcp[12]&gt;&gt;2):4] = 0x5353482D) and (tcp[((tcp[12]&gt;&gt;2)+4):2] = 0x312E)’ 10. 高级包头过滤 **如前两个的包头过滤，首先了解如何从包头过滤信息：** proto[x:y] : 过滤从x字节开始的y字节数。比如ip[2:2]过滤出3、4字节（第一字节从0开始排） proto[x:y] &amp; z = 0 : proto[x:y]和z的与操作为0 proto[x:y] &amp; z !=0 : proto[x:y]和z的与操作不为0 proto[x:y] &amp; z = z : proto[x:y]和z的与操作为z proto[x:y] = z : proto[x:y]等于z &gt;操作符 : &gt;, &lt;, &gt;=, &lt;=, =, != **抓取端口大于1024的TCP数据包：** ``` shell tcpdump -i en0 &#39;tcp[0:2] &gt; 1024&#39; 抓 DNS 请求数据 tcpdump -i en0 udp dst port 53 其他-c 参数对于运维人员来说也比较常用，因为流量比较大的服务器，靠人工 CTRL+C 还是抓的太多，于是可以用-c 参数指定抓多少个包。time tcpdump -nn -i en0 &#39;tcp[tcpflags] = tcp-syn&#39; -c 10000 &gt; /dev/null 上面的命令计算抓 10000 个 SYN 包花费多少时间，可以判断访问量大概是多少。 实时抓取端口号8000的GET包，然后写入GET.log tcpdump -i en0 &#39;((port 8000) and (tcp[(tcp[12]&gt;&gt;2):4]=0x47455420))&#39; -nnAl -w /tmp/GET.log 转自： 作者：陶邦仁 链接：http://www.jianshu.com/p/a62ed1bb5b20 來源：简书]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell,网络,运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络常见面试题]]></title>
    <url>%2F2017%2F06%2F11%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[OSI，TCP/IP，五层协议的体系结构分层 OSI分层（7层）：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层。 TCP/IP分层（4层）：网络接口层、网际层、运输层、应用层。 五层协议（5层）：物理层、数据链路层、网络层、运输层、应用层。 每一层的作用 物理层：激活、维持、关闭通信端点之间的机械特性、电气特性、功能特性以及过程特性。该层为上层协议提供了一个传输数据的物理媒体。 数据链路层：数据链路层在不可靠的物理介质上提供可靠的传输。该层的作用包括：物理地址寻址、数据的成帧、流量控制、数据的检错、重发等。 网络层：网络层负责对子网间的数据包进行路由选择。此外，网络层还可以实现拥塞控制、网际互连等功能。 传输层：第一个端到端，即主机到主机的层次。传输层负责将上层数据分段并提供端到端的、可靠的或不可靠的传输。此外，传输层还要处理端到端的差错控制和流量控制问题。 会话层：会话层管理主机之间的会话进程，即负责建立、管理、终止进程之间的会话。会话层还利用在数据中插入校验点来实现数据的同步。 表示层：表示层对上层数据或信息进行变换以保证一个主机应用层信息可以被另一个主机的应用程序理解。表示层的数据转换包括数据的加密、压缩、格式转换等。 应用层：为操作系统或网络应用程序提供访问网络服务的接口。 每一层的协议 物理层：RJ45、CLOCK、IEEE802.3 （中继器，集线器，网关） 数据链路：PPP、FR、HDLC、VLAN、MAC （网桥，交换机） 网络层：IP、ICMP、ARP、RARP、OSPF、IPX、RIP、IGRP、 （路由器） 传输层：TCP、UDP、SPX 会话层：NFS、SQL、NETBIOS、RPC 表示层：JPEG、MPEG、ASII 应用层：FTP、DNS、Telnet、SMTP、HTTP、WWW、NFS IP地址的分类 A类地址：以0开头，第一个字节范围：0~127.0.0.0 - 126.255.255.255）； B类地址：以10开头，第一个字节范围：128~191（128.0.0.0 - 191.255.255.255）； C类地址：以110开头，第一个字节范围：192~223（192.0.0.0 - 223.255.255.255）； D类地址：以1110开头，第一个字节范围为224~239； 内网地址: 10.0.0.0—10.255.255.255， 172.16.0.0—172.31.255.255， 192.168.0.0—192.168.255.255。（Internet上保留地址用于内部） IP地址与子网掩码相与得到主机号 ARP协议的工作原理首先，每台主机都会在自己的ARP缓冲区中建立一个 ARP列表，以表示IP地址和MAC地址的对应关系。当源主机需要将一个数据包要发送到目的主机时，会首先检查自己 ARP列表中是否存在该 IP地址对应的MAC地址，如果有，就直接将数据包发送到这个MAC地址；如果没有，就向本地网段发起一个ARP请求的广播包，查询此目的主机对应的MAC地址。此ARP请求数据包里包括源主机的IP地址、硬件地址、以及目的主机的IP地址。网络中所有的主机收到这个ARP请求后，会检查数据包中的目的IP是否和自己的IP地址一致。如果不相同就忽略此数据包；如果相同，该主机首先将发送端的MAC地址和IP地址添加到自己的ARP列表中，如果ARP表中已经存在该IP的信息，则将其覆盖，然后给源主机发送一个 ARP响应数据包，告诉对方自己是它需要查找的MAC地址；源主机收到这个ARP响应数据包后，将得到的目的主机的IP地址和MAC地址添加到自己的ARP列表中，并利用此信息开始数据的传输。如果源主机一直没有收到ARP响应数据包，表示ARP查询失败。 RARP协议将局域网中某个主机的物理地址转换为IP地址，比如局域网中有一台主机只知道物理地址而不知道IP地址，那么可以通过RARP协议发出征求自身IP地址的广播请求，然后由RARP服务器负责回答。RARP协议广泛应用于无盘工作站引导时获取IP地址。 RARP允许局域网的物理机器从网管服务器ARP表或者缓存上请求其IP地址。 工作原理 主机发送一个本地的RARP广播，在此广播包中，声明自己的MAC地址并且请求任何收到此请求的RARP服务器分配一个IP地址。 本地网段上的RARP服务器收到此请求后，检查其RARP列表，查找该MAC地址对应的IP地址。 如果存在，RARP服务器就给源主机发送一个响应数据包并将此IP地址提供给对方主机使用。 如果不存在，RARP服务器对此不做任何的响应。 源主机收到从RARP服务器的响应信息，就利用得到的IP地址进行通讯；如果一直没有收到RARP服务器的响应信息，表示初始化失败。 常见的路由选择协议，以及它们的区别常见的路由选择协议有：RIP协议、OSPF协议。 RIP协议底层是贝尔曼福特算法，它选择路由的度量标准（metric)是跳数，最大跳数是15跳，如果大于15跳，它就会丢弃数据包。 OSPF协议底层是迪杰斯特拉算法，是链路状态路由选择协议，它选择路由的度量标准是带宽，延迟。 各种协议 ICMP协议： 因特网控制报文协议。它是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。 TFTP协议： 是TCP/IP协议族中的一个用来在客户机与服务器之间进行简单文件传输的协议，提供不复杂、开销不大的文件传输服务。 HTTP协议： 超文本传输协议，是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。 DHCP协议： 动态主机配置协议，是一种让系统得以连接到网络上，并获取所需要的配置参数手段。 NAT协议： 网络地址转换属接入广域网(WAN)技术，是一种将私有（保留）地址转化为合法IP地址的转换技术， DHCP协议： 一个局域网的网络协议，使用UDP协议工作，用途：给内部网络或网络服务供应商自动分配IP地址，给用户或者内部网络管理员作为对所有计算机作中央管理的手段。 TCP与UDP的区别 UDP是面向无连接的，不可靠的数据报服务； TCP是面向连接的，可靠的字节流服务。 TCP的可靠性如何保证？TCP的可靠性是通过顺序编号和确认（ACK）来实现的。 TCP三次握手和四次挥手的全过程 在浏览器中输入www.baidu.com后执行的全部过程现在假设如果我们在客户端（客户端）浏览器中输入 http://www.baidu.com ,而 baidu.com 为要访问的服务器（服务器），下面详细分析客户端为了访问服务器而执行的一系列关于协议的操作： 1、客户端浏览器通过DNS解析到www.baidu.com的IP地址220.181.27.48，通过这个IP地址找到客户端到服务器的路径。客户端浏览器发起一个HTTP会话到220.161.27.48，然后通过TCP进行封装数据包，输入到网络层。 2、在客户端的传输层，把HTTP会话请求分成报文段，添加源和目的端口，如服务器使用80端口监听客户端的请求，客户端由系统随机选择一个端口如5000，与服务器进行交换，服务器把相应的请求返回给客户端的5000端口。然后使用IP层的IP地址查找目的端。 3、客户端的网络层不用关系应用层或者传输层的东西，主要做的是通过查找路由表确定如何到达服务器，期间可能经过多个路由器，这些都是由路由器来完成的工作，我不作过多的描述，无非就是通过查找路由表决定通过那个路径到达服务器。 4、客户端的链路层，包通过链路层发送到路由器，通过邻居协议查找给定IP地址的MAC地址，然后发送ARP请求查找目的地址，如果得到回应后就可以使用ARP的请求应答交换的IP数据包现在就可以传输了，然后发送IP数据包到达服务器的地址。 HTTP协议包括哪些请求？GET：请求读取由URL所标志的信息。 POST：给服务器添加信息（如注释）。 PUT：在给定的URL下存储一个文档。 DELETE：删除给定的URL所标志的资源。 HTTP中，POST与GET的区别(1)Get是从服务器上获取数据，Post是向服务器传送数据。 (2)Get是把参数数据队列加到提交表单的Action属性所指向的URL中，值和表单内各个字段一一对应，在URL中可以看到。 (3)Get传送的数据量小，不能大于2KB；post传送的数据量较大，一般被默认为不受限制。 (4)根据HTTP规范，GET用于信息获取，而且应该是安全的和幂等的。 I.所谓安全的意味着该操作用于获取信息而非修改信息。换句话说，GET 请求一般不应产生副作用。就是说，它仅仅是获取资源信息，就像数据库查询一样，不会修改，增加数据，不会影响资源的状态。 II.幂等的意味着对同一URL的多个请求应该返回同样的结果。 TCP对应的协议和UDP对应的协议TCP对应的协议：（1） FTP：定义了文件传输协议，使用21端口。常说某某计算机开了FTP服务便是启动了文件传输服务。下载文件，上传主页，都要用到FTP服务。 （2） Telnet：它是一种用于远程登陆的端口，用户可以以自己的身份远程连接到计算机上，通过这种端口可以提供一种基于DOS模式下的通信服务。如以前的BBS是-纯字符界面的，支持BBS的服务器将23端口打开，对外提供服务。 （3） SMTP：定义了简单邮件传送协议，现在很多邮件服务器都用的是这个协议，用于发送邮件。如常见的免费邮件服务中用的就是这个邮件服务端口，所以在电子邮件设置-中常看到有这么SMTP端口设置这个栏，服务器开放的是25号端口。 （4） POP3：它是和SMTP对应，POP3用于接收邮件。通常情况下，POP3协议所用的是110端口。也是说，只要你有相应的使用POP3协议的程序（例如Fo-xmail或Outlook），就可以不以Web方式登陆进邮箱界面，直接用邮件程序就可以收到邮件（如是163邮箱就没有必要先进入网易网站，再进入自己的邮-箱来收信）。 （5）HTTP协议：是从Web服务器传输超文本到本地浏览器的传送协议。 UDP对应的协议：（1） DNS：用于域名解析服务，将域名地址转换为IP地址。DNS用的是53号端口。 （2） SNMP：简单网络管理协议，使用161号端口，是用来管理网络设备的。由于网络设备很多，无连接的服务就体现出其优势。 （3） TFTP(Trival File Transfer Protocal)，简单文件传输协议，该协议在熟知端口69上使用UDP服务。 NAT协议、DHCP协议、DNS协议的作用NAT协议：网络地址转换(NAT,Network AddressTranslation)属接入广域网(WAN)技术， 是一种将私有（保留）地址转化为合法IP地址的转换技术，它被广泛应用于各种类型Internet接入方式和各种类型的网络中。原因很简单，NAT不仅完美地解决了lP地址不足的问题，而且还能够有效地避免来自网络外部的攻击，隐藏并保护网络内部的计算机。 DHCP协议：动态主机设置协议（Dynamic Host ConfigurationProtocol, DHCP） 是一个局域网的网络协议，使用UDP协议工作，主要有两个用途：给内部网络或网络服务供应商自动分配IP地址，给用户或者内部网络管理员作为对所有计算机作中央管理的手段。 DNS协议：DNS 是域名系统 (Domain Name System) 的缩写，是因特网的一项核心服务，它作为可以将域名和IP地址相互映射的一个分布式数据库，能够使人更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。 了解交换机、路由器、网关的概念，并知道各自的用途交换机在计算机网络系统中，交换机是针对共享工作模式的弱点而推出的。交换机拥有一条高带宽的背部总线和内部交换矩阵。交换机的所有的端口都挂接在这条背 部总线上，当控制电路收到数据包以后，处理端口会查找内存中的地址对照表以确定目的MAC（网卡的硬件地址）的NIC（网卡）挂接在哪个端口上，通过内部 交换矩阵迅速将数据包传送到目的端口。目的MAC若不存在，交换机才广播到所有的端口，接收端口回应后交换机会“学习”新的地址，并把它添加入内部地址表 中。 交换机工作于OSI参考模型的第二层，即数据链路层。交换机内部的CPU会在每个端口成功连接时，通过ARP协议学习它的MAC地址，保存成一张 ARP表。在今后的通讯中，发往该MAC地址的数据包将仅送往其对应的端口，而不是所有的端口。因此，交换机可用于划分数据链路层广播，即冲突域；但它不 能划分网络层广播，即广播域。 交换机被广泛应用于二层网络交换，俗称“二层交换机”。 交换机的种类有：二层交换机、三层交换机、四层交换机、七层交换机分别工作在OSI七层模型中的第二层、第三层、第四层盒第七层，并因此而得名。 路由器路由器（Router）是一种计算机网络设备，提供了路由与转送两种重要机制，可以决定数据包从来源端到目的端所经过 的路由路径（host到host之间的传输路径），这个过程称为路由；将路由器输入端的数据包移送至适当的路由器输出端(在路由器内部进行)，这称为转 送。路由工作在OSI模型的第三层——即网络层，例如网际协议。 路由器的一个作用是连通不同的网络，另一个作用是选择信息传送的线路。 路由器与交换器的差别，路由器是属于OSI第三层的产品，交换器是OSI第二层的产品(这里特指二层交换机)。 网关网关（Gateway），网关顾名思义就是连接两个网络的设备，区别于路由器（由于历史的原因，许多有关TCP/IP 的文献曾经把网络层使用的路由器（Router）称为网关，在今天很多局域网采用都是路由来接入网络，因此现在通常指的网关就是路由器的IP），经常在家 庭中或者小型企业网络中使用，用于连接局域网和Internet。 网关也经常指把一种协议转成另一种协议的设备，比如语音网关。 在传统TCP/IP术语中，网络设备只分成两种，一种为网关（gateway），另一种为主机（host）。网关能在网络间转递数据包，但主机不能 转送数据包。在主机（又称终端系统，end system）中，数据包需经过TCP/IP四层协议处理，但是在网关（又称中介系 统，intermediate system）只需要到达网际层（Internet layer），决定路径之后就可以转送。在当时，网关 （gateway）与路由器（router）还没有区别。 在现代网络术语中，网关（gateway）与路由器（router）的定义不同。网关（gateway）能在不同协议间移动数据，而路由器（router）是在不同网络间移动数据，相当于传统所说的IP网关（IP gateway）。 网关是连接两个网络的设备，对于语音网关来说，他可以连接PSTN网络和以太网，这就相当于VOIP，把不同电话中的模拟信号通过网关而转换成数字信号，而且加入协议再去传输。在到了接收端的时候再通过网关还原成模拟的电话信号，最后才能在电话机上听到。 对于以太网中的网关只能转发三层以上数据包，这一点和路由是一样的。而不同的是网关中并没有路由表，他只能按照预先设定的不同网段来进行转发。网关最重要的一点就是端口映射，子网内用户在外网看来只是外网的IP地址对应着不同的端口，这样看来就会保护子网内的用户。 TCP的流量控制和拥塞控制见链接]]></content>
      <categories>
        <category>面试题</category>
      </categories>
      <tags>
        <tag>面试题</tag>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vsftpd配置文件]]></title>
    <url>%2F2017%2F06%2F09%2Fvsftpd%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[vsftpd配置文件 #禁用匿名用户登陆 anonymous_enable=NO #允许本地用户登陆 local_enable=YES #允许本地用户写入 write_enable=YES #注意：这个地方如果不配置，就会出现只有root用户可以登陆，普通用户不可以 check_shell=NO #掩码，决定了上传上来的文件的权限。设置为000使之有最大权限 local_umask=000 #允许记录日志 xferlog_enable=YES #允许数据流从20端口传输 connect_from_port_20=YES #日志路径 xferlog_file=/var/log/vsftpd.log #ftp欢迎语，可以随便设置 ftpd_banner=hi,guys! #注意：这个选项可以保证用户锁定在指定的家目录里，防止系统文件被修改。 chroot_local_user=YES #注意：这个不配置有可能出现只能下载不能上传 allow_writeable_chroot=YES #配置了可以以stand alone模式运行 listen=YES #注意：该选项不配置可能导致莫名其妙的530问题 seccomp_sandbox=NO #说明我们要指定一个userlist，里边放的是允许ftp登陆的本地用户。如果设置为YES，则文件里设置的是不允许登陆的本地用户 userlist_deny=NO userlist_enable=YES #记录允许本地登陆用户名的文件 userlist_file=/etc/vsftpd/allowed_users]]></content>
      <categories>
        <category>配置文件</category>
      </categories>
      <tags>
        <tag>ftp</tag>
        <tag>配置文件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell知识遗漏2]]></title>
    <url>%2F2017%2F06%2F09%2Fshell%E7%9F%A5%E8%AF%86%E9%81%97%E6%BC%8F2%2F</url>
    <content type="text"><![CDATA[比较与测试 if条件 else if 和 else #!/bin/bash read i if [ $i -gt 10 ];then echo &quot;i&gt;=10&quot; elif [ $i -le 10 ]&amp;&amp;[ $i -gt 0 ];then echo &quot;0&lt;i&lt;=10&quot; else echo &quot;i&lt;=0&quot; fi 3.小技巧 if 和 else 语句可以进行嵌套。 if 的条件判断部分可能会变得很长,但可以用逻辑运算符将它变得简洁一些: [ condition ] &amp;&amp; action; # 如果 condition 为真,则执行 action ; [ condition ] || action; # 如果 condition 为假,则执行 action 。 &amp;&amp; 是逻辑与运算符, || 是逻辑或运算符。编写Bash脚本时,这是一 个很有用的技巧。现在来了解一下条件和比较操作。 4.比较运算符 算数运算符: -gt :大于。 -lt :小于。 -ge :大于或等于。 -le :小于或等于。 文件系统相关测试: 我们可以使用不同的条件标志测试不同的文件系统相关的属性。 [ -f $file_var ] :如果给定的变量包含正常的文件路径或文件名,则返回真。(判断给定的文件,是否存在!只能判断文件!) [ -x $var ] :如果给定的变量包含的文件可执行,则返回真。 [ -d $var ] :如果给定的变量包含的是目录,则返回真。 [ -e $var ] :如果给定的变量包含的文件(文件文件夹都可以)存在,则返回真。 [ -c $var ] :如果给定的变量包含的是一个字符设备文件的路径,则返回真。 [ -b $var ] :如果给定的变量包含的是一个块设备文件的路径,则返回真。 [ -w $var ] :如果给定的变量包含的文件可写,则返回真。 [ -r $var ] :如果给定的变量包含的文件可读,则返回真。 [ -L $var ] :如果给定的变量包含的是一个符号链接,则返回真。 使用方法如下: fpath=&quot;/etc/passwd&quot; if [ -e $fpath ]; then echo File exists; else echo Does not exist; fi 字符串比较: 使用字符串比较时,最好用双中括号,因为有时候采用单个中括号会产生错误,所以最 好避开它们。 可以用下面的方法检查两个字符串,看看它们是否相同。 [[ $str1 = $str2 ]] :当 str1 等于 str2 时,返回真。也就是说, str1 和 str2 包含的文本是一模一样的。 [[ $str1 == $str2 ]] :这是检查字符串是否相等的另一种写法。 也可以检查两个字符串是否不同。 [[ $str1 != $str2 ]] :如果 str1 和 str2 不相同,则返回真。 我们还可以检查字符串的字母序情况,具体如下所示。 [[ $str1 &gt; $str2 ]] :如果 str1 的字母序比 str2 大,则返回真。 [[ $str1 &lt; $str2 ]] :如果 str1 的字母序比 str2 小,则返回真。 [[ -z $str1 ]] :如果 str1 包含的是空字符串,则返回真。 [[ -n $str1 ]] :如果 str1 包含的是非空字符串,则返回真。 注意在 = 前后各有一个空格。如果忘记加空格,那就不是比较关系了,而变成了赋值语句。 多条件组合 使用逻辑运算符 &amp;&amp; 和 || 能够很容易地将多个条件组合起来: if [[ -n $str1 ]] &amp;&amp; [[ -z $str2 ]] ; then commands; fi 例如: str1=&quot;Not empty &quot; str2=&quot;&quot; if [[ -n $str1 ]] &amp;&amp; [[ -z $str2 ]]; then echo str1 is nonempty and str2 is empty string. fi 输出如下: str1 is nonempty and str2 is empty string. test命令 test 命令可以用来执行条件检测。用 test 可以避免使用过多的括号。之前讲过的 [] 中的测试条件同样可以用于 test 命令。 例如: if [ $var -eq 0 ]; then echo &quot;True&quot;; fi 也可以写成: if test $var -eq 0 ; then echo &quot;True&quot;; fi 录制并回放终端回话暂且跳过,用的不多 ##]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[py自动化运维第一章]]></title>
    <url>%2F2017%2F06%2F07%2Fpy%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4%E7%AC%AC%E4%B8%80%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[第一章 系统基础信息模块详解系统性能信息模块psutil实例：https://github.com/giampaolo/psutil 文档：https://pythonhosted.org/psutil/#recipes/ shell中常用监控命令ps:top:lsof:netstat:ifconfig:who:df:kill:free:nice:ionice:iostat:iotop:uptime:pidof:tty:taskset:pmap: 获取系统性能信息 CPU信息```python import psutilpsutil.cpu_times()scputimes(user=3961.46, nice=169.729, system=2150.659, idle=16900.540, iowait=629.59, irq=0.0, softirq=19.42, steal=0.0, guest=0, nice=0.0) for x in range(3):… psutil.cpu_percent(interval=1)…4.05.93.8 for x in range(3):… psutil.cpu_percent(interval=1, percpu=True)…[4.0, 6.9, 3.7, 9.2][7.0, 8.5, 2.4, 2.1][1.2, 9.0, 9.9, 7.2] for x in range(3):… psutil.cpu_times_percent(interval=1, percpu=False)…scputimes(user=1.5, nice=0.0, system=0.5, idle=96.5, iowait=1.5, irq=0.0, softirq=0.0, steal=0.0, guest=0.0, guest_nice=0.0)scputimes(user=1.0, nice=0.0, system=0.0, idle=99.0, iowait=0.0, irq=0.0, softirq=0.0, steal=0.0, guest=0.0, guest_nice=0.0)scputimes(user=2.0, nice=0.0, system=0.0, idle=98.0, iowait=0.0, irq=0.0, softirq=0.0, steal=0.0, guest=0.0, guest_nice=0.0) psutil.cpu_count()4psutil.cpu_count(logical=False)2 psutil.cpu_stats()scpustats(ctx_switches=20455687, interrupts=6598984, soft_interrupts=2134212, syscalls=0) psutil.cpu_freq()scpufreq(current=931.42925, min=800.0, max=3500.0) tip: irq:硬件中断 softirq：软件中断 2. 内存信息 ```python &gt;&gt;&gt; import psutil &gt;&gt;&gt; psutil.virtual_memory() #内存完整信息 svmem(total=10367352832, available=6472179712, percent=37.6, used=8186245120, free=2181107712, active=4748992512, inactive=2758115328, buffers=790724608, cached=3500347392, shared=787554304) &gt;&gt;&gt; psutil.swap_memory() #获取交换分区信息 sswap(total=2097147904, used=296128512, free=1801019392, percent=14.1, sin=304193536, sout=677842944) &gt;&gt;&gt; tip: total:内存总数 used：已经使用的内存数 free：空闲内存数 buffers：缓冲使用数 cache：缓冲使用数 swap：交换分区使用数 free命令中cached和buffers的区别 磁盘信息 &gt;&gt;&gt; import psutil &gt;&gt;&gt; psutil.disk_partitions() [sdiskpart(device=&#39;/dev/sda1&#39;, mountpoint=&#39;/&#39;, fstype=&#39;ext4&#39;, opts=&#39;rw,nosuid&#39;), sdiskpart(device=&#39;/dev/sda2&#39;, mountpoint=&#39;/home&#39;, fstype=&#39;ext, opts=&#39;rw&#39;)] &gt;&gt;&gt; &gt;&gt;&gt; psutil.disk_usage(&#39;/&#39;) sdiskusage(total=21378641920, used=4809781248, free=15482871808, percent=22.5) &gt;&gt;&gt; &gt;&gt;&gt; psutil.disk_io_counters(perdisk=False) sdiskio(read_count=719566, write_count=1082197, read_bytes=18626220032, write_bytes=24081764352, read_time=5023392, write_time=63199568, read_merged_count=619166, write_merged_count=812396, busy_time=4523412) &gt;&gt;&gt; 网络信息 &gt;&gt;&gt; import psutil &gt;&gt;&gt; psutil.net_io_counters(pernic=True) {&#39;eth0&#39;: netio(bytes_sent=485291293, bytes_recv=6004858642, packets_sent=3251564, packets_recv=4787798, errin=0, errout=0, dropin=0, dropout=0), &#39;lo&#39;: netio(bytes_sent=2838627, bytes_recv=2838627, packets_sent=30567, packets_recv=30567, errin=0, errout=0, dropin=0, dropout=0)} &gt;&gt;&gt; &gt;&gt;&gt; psutil.net_connections() [pconn(fd=115, family=&lt;AddressFamily.AF_INET: 2&gt;, type=&lt;SocketType.SOCK_STREAM: 1&gt;, laddr=(&#39;10.0.0.1&#39;, 48776), raddr=(&#39;93.186.135.91&#39;, 80), status=&#39;ESTABLISHED&#39;, pid=1254), pconn(fd=117, family=&lt;AddressFamily.AF_INET: 2&gt;, type=&lt;SocketType.SOCK_STREAM: 1&gt;, laddr=(&#39;10.0.0.1&#39;, 43761), raddr=(&#39;72.14.234.100&#39;, 80), status=&#39;CLOSING&#39;, pid=2987), pconn(fd=-1, family=&lt;AddressFamily.AF_INET: 2&gt;, type=&lt;SocketType.SOCK_STREAM: 1&gt;, laddr=(&#39;10.0.0.1&#39;, 60759), raddr=(&#39;72.14.234.104&#39;, 80), status=&#39;ESTABLISHED&#39;, pid=None), pconn(fd=-1, family=&lt;AddressFamily.AF_INET: 2&gt;, type=&lt;SocketType.SOCK_STREAM: 1&gt;, laddr=(&#39;10.0.0.1&#39;, 51314), raddr=(&#39;72.14.234.83&#39;, 443), status=&#39;SYN_SENT&#39;, pid=None) ...] &gt;&gt;&gt; &gt;&gt;&gt; psutil.net_if_addrs() {&#39;lo&#39;: [snic(family=&lt;AddressFamily.AF_INET: 2&gt;, address=&#39;127.0.0.1&#39;, netmask=&#39;255.0.0.0&#39;, broadcast=&#39;127.0.0.1&#39;, ptp=None), snic(family=&lt;AddressFamily.AF_INET6: 10&gt;, address=&#39;::1&#39;, netmask=&#39;ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff&#39;, broadcast=None, ptp=None), snic(family=&lt;AddressFamily.AF_LINK: 17&gt;, address=&#39;00:00:00:00:00:00&#39;, netmask=None, broadcast=&#39;00:00:00:00:00:00&#39;, ptp=None)], &#39;wlan0&#39;: [snic(family=&lt;AddressFamily.AF_INET: 2&gt;, address=&#39;192.168.1.3&#39;, netmask=&#39;255.255.255.0&#39;, broadcast=&#39;192.168.1.255&#39;, ptp=None), snic(family=&lt;AddressFamily.AF_INET6: 10&gt;, address=&#39;fe80::c685:8ff:fe45:641%wlan0&#39;, netmask=&#39;ffff:ffff:ffff:ffff::&#39;, broadcast=None, ptp=None), snic(family=&lt;AddressFamily.AF_LINK: 17&gt;, address=&#39;c4:85:08:45:06:41&#39;, netmask=None, broadcast=&#39;ff:ff:ff:ff:ff:ff&#39;, ptp=None)]} &gt;&gt;&gt; &gt;&gt;&gt; psutil.net_if_stats() {&#39;eth0&#39;: snicstats(isup=True, duplex=&lt;NicDuplex.NIC_DUPLEX_FULL: 2&gt;, speed=100, mtu=1500), &#39;lo&#39;: snicstats(isup=True, duplex=&lt;NicDuplex.NIC_DUPLEX_UNKNOWN: 0&gt;, speed=0, mtu=65536)} &gt;&gt;&gt; 其他系统信息&gt;&gt;&gt; import psutil &gt;&gt;&gt; psutil.users() [suser(name=&#39;giampaolo&#39;, terminal=&#39;pts/2&#39;, host=&#39;localhost&#39;, started=1340737536.0, pid=1352), suser(name=&#39;giampaolo&#39;, terminal=&#39;pts/3&#39;, host=&#39;localhost&#39;, started=1340737792.0, pid=1788)] &gt;&gt;&gt; &gt;&gt;&gt; psutil.boot_time() 1365519115.0 &gt;&gt;&gt; 系统进程管理方法 进程信息插入一条关于进程控制信号捕获的博客，常考笔试题（sigkill和sigstop不可被捕捉，sigint可以被捕捉）：http://blog.csdn.net/madpointer/article/details/13091705 popen类的使用 &gt;&gt;&gt; import psutil &gt;&gt;&gt; from subprocess import PIPE &gt;&gt;&gt; p = psutil.Popen([&quot;/usr/bin/python&quot;, &quot;-c&quot;, &quot;print(&#39;hello&#39;)&quot;], stdout=PIPE) &gt;&gt;&gt; p.name() &#39;python&#39; &gt;&gt;&gt; p.username() &#39;giampaolo&#39; &gt;&gt;&gt; p.communicate() (&#39;hello\n&#39;, None) &gt;&gt;&gt; p.wait(timeout=2) 0 &gt;&gt;&gt; 实用的IP地址处理模块IPy#!/usr/bin/env python from IPy import IP ip_s = raw_input(&#39;Please input an IP or net-range: &#39;) ips = IP(ip_s) if len(ips) &gt; 1: print(&#39;net: %s&#39; % ips.net()) #输出网络地址 print(&#39;netmask: %s&#39; % ips.netmask()) #输出网络掩码地址 print(&#39;broadcast: %s&#39; % ips.broadcast()) #输出广播地址 print(&#39;reverse address: %s&#39; % ips.reverseNames()[0]) #输出地址反向解析 print(&#39;subnet: %s&#39; % len(ips)) #输出网络子网数 else: print(&#39;reverse address: %s&#39; % ips.reverseNames()[0]) print(&#39;hexadecimal: %s&#39; % ips.strHex()) #十六进制地址 print(&#39;binary ip: %s&#39; % ips.strBin()) #二进制地址 print(&#39;iptype: %s&#39; % ips.iptype()) #地址类型 DNS处理模块dnspython插播新知识：dig命令 模块域名解析方法详解常见的DNS解析类型A记录： 将域名指向一个IPv4地址（例如：100.100.100.100），需要增加A记录 CNAME记录： 如果将域名指向一个域名，实现与被指向域名相同的访问效果，需要增加CNAME记录。这个域名一般是主机服务商提供的一个域名 MX记录： 建立电子邮箱服务，将指向邮件服务器地址，需要设置MX记录。建立邮箱时，一般会根据邮箱服务商提供的MX记录填写此记录 NS记录： 域名解析服务器记录，如果要将子域名指定某个域名服务器来解析，需要设置NS记录 TXT记录： 可任意填写，可为空。一般做一些验证记录时会使用此项，如：做SPF（反垃圾邮件）记录 AAAA记录： 将主机名（或域名）指向一个IPv6地址（例如：ff03:0:0:0:0:0:0:c1），需要添加AAAA记录 SRV记录： 添加服务记录服务器服务记录时会添加此项，SRV记录了哪台计算机提供了哪个服务。格式为：服务的名字.协议的类型（例如：_example-server._tcp）。 SOA记录： SOA叫做起始授权机构记录，NS用于标识多台域名解析服务器，SOA记录用于在众多NS记录中那一台是主服务器 PTR记录： PTR记录是A记录的逆向记录，又称做IP反查记录或指针记录，负责将IP反向解析为域名 显性URL转发记录： 将域名指向一个http(s)协议地址，访问域名时，自动跳转至目标地址。例如：将www.liuht.cn显性转发到www.itbilu.com后，访问www.liuht.cn时，地址栏显示的地址为：www.itbilu.com。 隐性UR转发记录L： 将域名指向一个http(s)协议地址，访问域名时，自动跳转至目标地址，隐性转发会隐藏真实的目标地址。例如：将www.liuht.cn显性转发到www.itbilu.com后，访问www.liuht.cn时，地址栏显示的地址仍然是：www.liuht.cn。 DNS解析中一些问题 2.1 A记录与CNAME记录 A记录是把一个域名解析到一个IP地址，而CNAME记录是把域名解析到另外一个域名，而这个域名最终会指向一个A记录，在功能实现在上A记录与CNAME记录没有区别。 CNAME记录在做IP地址变更时要比A记录方便。CNAME记录允许将多个名字映射到同一台计算机，当有多个域名需要指向同一服务器IP，此时可以将一个域名做A记录指向服务器IP，然后将其他的域名做别名(即：CNAME)到A记录的域名上。当服务器IP地址变更时，只需要更改A记录的那个域名到新IP上，其它做别名的域名会自动更改到新的IP地址上，而不必对每个域名做更改。 2.2 A记录与AAAA记录 二者都是指向一个IP地址，但对应的IP版本不同。A记录指向IPv4地址，AAAA记录指向IPv6地址。AAAA记录是A记录的升级版本。 2.3 IPv4与IPv6 IPv4，是互联网协议（Internet Protocol，IP）的第四版，也是第一个被广泛使用的版本，是构成现今互联网技术的基础协议。IPv4 的下一个版本就是IPv6，在将来将取代目前被广泛使用的IPv4。 IPv4中规定IP地址长度为32位（按TCP/IP参考模型划分) ，即有2^32-1个地址。IPv6的提出最早是为了解决，随着互联网的迅速发展IPv4地址空间将被耗尽的问题。为了扩大地址空间，IPv6将IP地址的长度由32位增加到了128位。在IPv6的设计过程中除了一劳永逸地解决了地址短缺问题以外，还解决了IPv4中的其它问题，如：端到端IP连接、服务质量（QoS）、安全性、多播、移动性、即插即用等。 2.4 TTL值 TTL－生存时间（Time To Live），表示解析记录在DNS服务器中的缓存时间，TTL的时间长度单位是秒，一般为3600秒。比如：在访问www.itbilu.com时，如果在DNS服务器的缓存中没有该记录，就会向某个NS服务器发出请求，获得该记录后，该记录会在DNS服务器上保存TTL的时间长度，在TTL有效期内访问www.itbilu.com，DNS服务器会直接缓存中返回刚才的记录。 DNS轮询（不完善）#!/usr/bin/python #coding:utf-8 import dns.resolver import os import httplib iplist=[] #定义域名IP列表变量 appdomain=&quot;fdl66.github.io&quot; #定义业务域名 def get_iplist(domain=&quot;&quot;): #域名解析函数，解析成功IP将追加到iplist try: cname = dns.resolver.query(domain, &#39;CNAME&#39;) domains = [] for i in cname.response.answer: for j in i.items: print j.to_text()+&quot;debug&quot; domains.append(j) for dom in domains: A=dns.resolver.query(str(dom),&#39;A&#39;) # 解析A记录类型 for i in A.response.answer: for j in i.items: print j.address+&quot;debug&quot; iplist.append(j.address) # 追加到iplist except Exception,e: print &quot;dns resolver error:&quot;+str(e) return return True def checkip(ip): checkurl=ip+&quot;:80&quot; getcontent=&quot;&quot; httplib.socket.setdefaulttimeout(5) #定义http连接超时时间(5秒) conn=httplib.HTTPConnection(checkurl) #创建http连接对象 try: conn.request(&quot;GET&quot;, &quot;/&quot;,headers = {&quot;Host&quot;: appdomain}) #发起URL请求，添加host主机头 r=conn.getresponse() getcontent =r.read(15) #获取URL页面前15个字符，以便做可用性校验 finally: print getcontent+&quot;debug&quot; if getcontent==&quot;&lt;!doctype html&gt;&quot;: #监控URL页的内容一般是事先定义好，比如“HTTP200”等 print ip+&quot; [OK]&quot; else: print ip+&quot; [Error]&quot; #此处可放告警程序，可以是邮件、短信通知 if __name__==&quot;__main__&quot;: if get_iplist(appdomain) and len(iplist)&gt;0: #条件：域名解析正确且至少要返回一个IP for ip in iplist: checkip(ip) else: print &quot;dns resolver error.&quot;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[逻辑块与物理块的对应关系]]></title>
    <url>%2F2017%2F06%2F07%2F%E9%80%BB%E8%BE%91%E5%9D%97%E4%B8%8E%E7%89%A9%E7%90%86%E5%9D%97%E7%9A%84%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[物理块的大小设定我们把Ext2、Minix、Ext等实际可使用的文件系统称为具体文件系统。具体文件系统管理的是一个逻辑空间，这个逻辑空间就象一个大的数组，数组的每个元素就是文件系统操作的基本单位——逻辑块，逻辑块是从0开始编号的，而且，逻辑块是连续的。与逻辑块相对的是物理块，物理块是数据在磁盘上的存取单位，也就是每进行一次I/O操作，最小传输的数据大小。我们知道数据是存储在磁盘的扇区中的，那么扇区是不是物理块呢？或者物理块是多大呢？这涉及到文件系统效率的问题。 如果物理块定的比较大，比如一个柱面大小，这时，即使是1个字节的文件都要占用整个一个柱面，假设Linux环境下文件的平均大小为1K，那么分配32K的柱面将浪费97%的磁盘空间，也就是说，大的存取单位将带来严重的磁盘空间浪费。另一方面，如果物理块过小，则意味着对一个文件的操作将进行更多次的寻道延迟和旋转延迟，因而读取由小的物理块组成的文件将非常缓慢！可见，时间效率和空间效率在本质上是相互冲突的。 因此，最优的方法是计算出Linux环境下文件的平均大小，然后将物理块大小定为最接近扇区的整数倍大小。在Ext2中，物理块的大小是可变化的，这取决于你在创建文件系统时的选择，之所以不限制大小，也正体现了Ext2的灵活性和可扩充性，一是因为要适应近年来文件的平均长度缓慢增长的趋势，二是为了适应不同的需要。比如，如果一个文件系统主要用于BBS服务，考虑到BBS上的文章通常很短小，所以，物理块选的小一点是恰当的。通常，Ext2的物理块占一个或几个连续的扇区，显然，物理块的数目是由磁盘容量等硬件因素决定的。逻辑块与物理块的关系类似于虚拟内存中的页与物理内存中的页面的关系。 逻辑块与物理块之间的关系具体文件系统所操作的基本单位是逻辑块，只在需要进行I/O操作时才进行逻辑块到物理块的映射，这显然避免了大量的I/O操作，因而文件系统能够变得高效。逻辑块作为一个抽象的概念，它必然要映射到具体的物理块上去，因此，逻辑块的大小必须是物理块大小的整数倍，一般说来，两者是一样大的。 通常，一个文件占用的多个物理块在磁盘上是不连续存储的，因为如果连续存储，则经过频繁的删除、建立、移动文件等操作，最后磁盘上将形成大量的空洞，很快磁盘上将无空间可供使用。因此，必须提供一种方法将一个文件占用的多个逻辑块映射到对应的非连续存储的物理块上去，Ext2等类文件系统是用索引节点解决这个问题的，具体实现方法后面再予以介绍。 为了更好的说明逻辑块和物理块的关系，我们来看一个例子。 假设用户要对一个已有文件进行写操作，用户进程必须先打开这个文件，file结构记录了该文件的当前位置。然后用户把一个指向用户内存区的指针和请求写的字节数传送给系统，请求写操作，这时系统要进行两次映射。 （1）一组字节到逻辑块的映射。 这个映射过程就是找到起始字节到结束字节所占用的所有逻辑块号。这是因为在逻辑空间，文件传输的基本单位是逻辑块而不是字节。 （2）逻辑块到物理块的映射。 这个过程必须要用到索引节点结构，该结构中有一个物理块指针数组，以逻辑块号为索引，通过这些指针找到磁盘上的物理块，具体实现将在介绍Ext2索引节点时再进行介绍。 图1是由一组请求的字节到物理块的映射过程示意图。 有了逻辑块和物理块的概念，我们也就知道通常所说的数据块是指逻辑块，以下没有特别说明，块或数据块指的是逻辑块。 在Ext2中，还有一个重要的概念：片（fragment），它的作用是什么？ 每个文件必然占用整数个逻辑块，除非每个文件大小都恰好是逻辑块的整数倍，否则最后一个逻辑块必然有空间未被使用，实际上，每个文件的最后一个逻辑块平均要浪费一半的空间，显然最终浪费的还是物理块。在一个有很多文件的系统中，这种浪费是很大的。Ext2使用片来解决这个问题。 片片也是一个逻辑空间中的概念，其大小在1K至4K之间，但片的大小总是不大于逻辑块。假设逻辑块大小为4K，片大小为1K，物理块大小也是1K，当你要创建一个3K大小的文件时，实际上分配给你了3个片，而不会给你一个逻辑块，当文件大小增加到4K时，文件系统则分配一个逻辑块给你，而原来的四个片被清空。如果文件又增加到5K时，则占用1个逻辑块和1个片。上述三种情况下，所占用的物理块分别是3个、4个、5个，如果不采用片，则要用到4个、4个、8个物理块，可见，使用片，减少了磁盘空间的浪费。当然，在物理块和逻辑块大小一样时，片就没有意义了。由上面分析也可看出： 物理块大小&lt;=片大小&lt;=逻辑块大小]]></content>
      <categories>
        <category>文件系统</category>
      </categories>
      <tags>
        <tag>数据重删</tag>
        <tag>文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell知识遗漏1]]></title>
    <url>%2F2017%2F05%2F16%2Fshell%E7%9F%A5%E8%AF%86%E9%81%97%E6%BC%8F1%2F</url>
    <content type="text"><![CDATA[数组和关联数组Bash从4.0版本之后才开始支持关联数组。(1) 定义数组的方法有很多种。可以在单行中使用一列值来定义一个数组: array_var=(1 2 3 4 5 6) #这些值将会存储在以0为起始索引的连续位置上 另外,还可以将数组定义成一组“索引 - 值”: array_var[0]=&quot;test1&quot; array_var[1]=&quot;test2&quot; array_var[2]=&quot;test3&quot; array_var[3]=&quot;test4&quot; array_var[4]=&quot;test5&quot; array_var[5]=&quot;test6&quot; (2) 打印出特定索引的数组元素内容: echo ${array_var[0]} test1 index=5 echo ${array_var[$index]} test6 (3) 以清单形式打印出数组中的所有值: $ echo ${array_var[*]} test1 test2 test3 test4 test5 test6 也可以这样使用: $ echo ${array_var[@]} test1 test2 test3 test4 test5 test6 (4) 打印数组长度(即数组中元素的个数): $ echo ${#array_var[*]} 6 数组plus1).定义关联数组在关联数组中,我们可以用任意的文本作为数组索引。首先,需要使用声明语句将一个变量名声明为关联数组。像下面这样: $ declare -A ass_array 声明之后,可以用两种方法将元素添加到关联数组中。利用内嵌“索引 - 值”列表的方法,提供一个“索引 - 值”列表: $ ass_array=([index1]=val1 [index2]=val2) 使用独立的“索引 - 值”进行赋值: $ ass_array[index1]=val1 $ ass_array&#39;index2]=val2 举个例子,试想如何用关联数组为水果制定价格: $ declare -A fruits_value $ fruits_value=([apple]=&#39;100dollars&#39; [orange]=&#39;150 dollars&#39;) 用下面的方法显示数组内容: $ echo &quot;Apple costs ${fruits_value[apple]}&quot; Apple costs 100 dollars 2).列出数组索引每一个数组元素都有一个索引用于查找。普通数组和关联数组具有不同的索引类型。我们可以用下面的方法获取数组的索引列表: $ echo ${!array_var[*]} 也可以使用: $ echo ${!array_var[@] 以先前提到的 fruits_value 数组为例,运行如下命令: $ echo ${!fruits_value[*]} orange apple 对于普通数组,这个方法同样可行。 调试脚本函数和参数 $1 是第一个参数。 $2 是第二个参数。 $n 是第n个参数。 &quot;$@&quot; 被扩展成 &quot;$1&quot; &quot;$2&quot; &quot;$3&quot; 等。 &quot;$*&quot; 被扩展成 &quot;$1c$2c$3&quot; ,其中 c 是IFS的第一个字符。 &quot;$@&quot; 要比 &quot;$*&quot; 用得多。由于 &quot;$*&quot; 将所有的参数当做单个字符串,因此它很少被使用。 $? 上一条命令执行的返回值 $# 参数个数 字段分隔符和迭代器 #!/bin/bash #用途: 演示IFS的用法 line=&quot;root:x:0:0:root:/root:/bin/bash&quot; oldIFS=$IFS; IFS=&quot;:&quot; count=0 for item in $line; do [ $count -eq 0 ] &amp;&amp; user=$item; [ $count -eq 6 ] &amp;&amp; shell=$item; let count++ done; IFS=$oldIFS echo $user\&#39;s shell is $shell; 输出为: root&#39;s shell is /bin/bash 循环for 循环for var in list; do commands; #使用变量$var done list 可以是一个字符串,也可以是一个序列。我们可以轻松地生成不同的序列。echo {1..50} 能够生成一个从1~50的数字列表。 echo {a..z} 或 {A..Z} 或 {a..h} 可以生 成字母列表。同样,我们可以将这些方法结合起来对数据进行拼接(concatenate)。下面的代码中,变量 i 在每次迭代的过程里都会保存一个字符,范围从 a ~ z : for i in {a..z}; do actions; done; for 循环也可以采用C语言中 for 循环的格式。例如: for((i=0;i&lt;10;i++)) { commands; #使用变量$i } while 循环while condition do commands; done 用 true 作为循环条件能够产生无限循环。 until 循环在Bash中还可以使用一个特殊的循环 until 。它会一直执行循环,直到给定的条件为真。例如: x=0; until [ $x -eq 9 ]; #条件是[$x -eq 9 ] do let x++; echo $x; done]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDE系列]]></title>
    <url>%2F2017%2F05%2F07%2FIDE%E7%B3%BB%E5%88%97%2F</url>
    <content type="text"><![CDATA[JetBrains 我所见过的最好的IDE，没有之一。 网址：jetbrains Python 地址：pycharm 激活：Java 地址：IntelliJ IDEA 激活：http://www.cnblogs.com/suiyueqiannian/p/6754091.html (2017-6-6测试可用)C/C++ 地址：CLion 激活：http://xclient.info/a/f0b9738a-36fd-8a97-a966-0d3db497092d.html (2017-6-6测试可用)golang 地址：golang 激活：主题下载 地址：主题地址 推荐主题：（1）. Sublime Text 2 （2）. Monokai Sublime Text 3 详细教程：地址 得良说 能够熟练使用一个好的IDE，会大幅提高你的工作效率，不用为一些无关紧要的事情浪费时间。就比如这个jetbrains系列，是我见过的最好的ide系列，挺全的常用的语言基本都有，而且风格都一样，你熟练了一种，其他的自然无师自通。 我觉的比较赞 的功能： 1. 可以同步git，简单粗暴 2. 各种包直接搜索安装，简单粗暴 3. 多种语言，一个风格，简单粗暴 4. 竟然支持markdown实时预览，哇这个功能是真的6,6的飞起 5. debug超级方便，简单粗暴 6. 各种漂亮主题直接下载导入，简单粗暴外加漂亮]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>IDE</tag>
        <tag>敏捷开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell正则]]></title>
    <url>%2F2017%2F05%2F05%2Fshell%E6%AD%A3%E5%88%99%2F</url>
    <content type="text"><![CDATA[字符1.特定字符 &#39;a&#39; 2.范围内字符 []单个字符 数字字符:[0-9],[259] 小写字母:[a-z] 大写字母:[A-Z] 符号:[,;:] 取反:[^0-9] 3.任意字符 .:单个任意字符(注意:[.]和\. , 这里就只表示点) 其他符号1.边界字符:头尾字符 ^: ^root 表示以root开头的行 $: false$ 表示以false结束的行 空行的表示: ^$ 2.元字符(代表普通字符或者特殊字符) \w: 匹配任何字类字符,包括下划线([A-Za-z0-9_]) \W: 匹配任何非字类字符([^A-Za-z0-9_]) \b: 单词的分隔(不只是空格或者制表符) dear@dear3442:~/code/sh$ egrep &#39;\b[0-9]+\b&#39; passwd root:x:0:0:root:/root:/bin/bash daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin bin:x:2:2:bin:/bin:/usr/sbin/nologin sys:x:3:3:sys:/dev:/usr/sbin/nologin sync:x:4:65534:sync:/bin:/bin/sync games:x:5:60:games:/usr/games:/usr/sbin/nologin man:x:6:12:man:/var/cache/man:/usr/sbin/nologin lp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin 字符串 &#39;asdf&#39; ,&#39;asdf&#39; [0-9][0-9][0-9],[a-z][a-z][a-z] 重复,逻辑 重复: 1. *:零次或者多次 匹配前面的字符或子表达式 2. \+:一次或者多次 匹配前面的字符或子表达式(注意grep使用的时候,要用 \+ ) 3. \?:零次或者一次 匹配前面的字符或子表达式(注意grep使用的时候,要用 \? ) 4. \{n,m\}: 重复n次到m次 分组: $ grep &#39;\(se\)*&#39; test.txt #表示匹配se多次 任意字符串: $ grep &#39;.*&#39; test.txt #可能会贪婪匹配 逻辑: 1. 逻辑或: | : &#39;/bin/\(false\|true\)&#39; 案例 4-10位的QQ号 grep &#39;^[0-9]\{4-10\}$&#39; qq.txt 2.匹配密码(有数字,26个字母和下划线组成) grep &#39;^\w\+$&#39; qq.txt 总结]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python多线程之threading模块]]></title>
    <url>%2F2017%2F04%2F23%2Fpython%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B9%8Bthreading%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[threading 模块使用threading模块(mtsleepC.py)threading模块的Thread类有一个join()方法,可以让主线程等待所有线程执行完毕 #!/usr/bin/env python # coding=utf-8 import threading from time import sleep,ctime loops=[4,2] def loop(nloop,nsec): print &#39;start loop:&#39;,nloop,&#39; done at:&#39;,ctime() sleep(nsec) print &#39;loop&#39;,nloop,&#39;done at:&#39;,ctime() def main(): print &#39;starting at:&#39;,ctime() threads=[] nloops=range(len(loops)) for i in nloops: t=threading.Thread(target=loop,args=(i,loops[i])) threads.append(t) for i in nloops: threads[i].start() for i in nloops: threads[i].join() print &#39;all DONE at:&#39;,ctime() if __name__ == &#39;__main__&#39;: main() 子类化的Thread(mtsleepE.py)本例对Thread子类化,而不是直接对其实例化,这将使我们在定制线程对象是拥有更多的灵活性,也能够简化线程调用的过程. #!/usr/bin/env python # coding=utf-8 import threading from time import sleep ,ctime loops=(4,2) class MyThread(threading.Thread): def __init__(self,func,args,name=&#39;&#39;): threading.Thread.__init__(self) self.name = name self.func = func self.args = args def run(self): self.func(*self.args) def loop(nloop,nsec): print &#39;start loop&#39;,nloop,&#39;at:&#39;,ctime() sleep(nsec) print &#39;loop&#39;,nloop,&#39;done at:&#39;,ctime() def main(): print &#39;starting at:&#39;,ctime() threads = [] nloops=range(len(loops)) for i in nloops: t=MyThread(loop,(i,loops[i]),loop.__name__) threads.append(t) for i in nloops: threads[i].start() for i in nloops: threads[i].join() print &#39;all DONE at:&#39;,ctime() if __name__ == &#39;__main__&#39;: main()]]></content>
  </entry>
  <entry>
    <title><![CDATA[python多线程]]></title>
    <url>%2F2017%2F04%2F22%2Fpython%E5%A4%9A%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[thread 模块使用单线程执行循环代码: #!/usr/bin/env python # coding=utf-8 from time import sleep , ctime def loop0(): print &#39;start loop 0 at : &#39;, ctime() sleep(4) print &#39;loop 0 done ate : &#39;, ctime() def loop1(): print &#39;start loop 1 at : &#39;, ctime() sleep(2) print &#39;loop 1 done ate : &#39;, ctime() def main(): print &quot;starting at : &quot;,ctime() loop0() loop1() print &quot;all DONE at : &quot;,ctime() if __name__ == &#39;__main__&#39;: main() 执行结果: 顺序执行 使用thread模块(mtsleepA.py)代码#!/usr/bin/env python # coding=utf-8 import thread from time import sleep , ctime def loop0(): print &#39;start loop 0 at : &#39;,ctime() sleep(4) print &#39;loop 0 done at : &#39;,ctime() def loop1(): print &#39;start loop 1 at :&#39;,ctime() sleep(2) print &#39;loop 1 done at :&#39;,ctime() def main(): print &#39;starting at :&#39;,ctime() thread.start_new_thread(loop0,()) thread.start_new_thread(loop1,()) sleep(6) print &#39;all done at :&#39;,ctime() if __name__ == &#39;__main__&#39;: main() 执行结果 并行执行 修改mtsleepA.py 后#!/usr/bin/env python # coding=utf-8 import thread from time import sleep , ctime def loop0(): print &#39;start loop 0 at : &#39;,ctime() sleep(4) print &#39;loop 0 done at : &#39;,ctime() def loop1(): print &#39;start loop 1 at :&#39;,ctime() sleep(2) print &#39;loop 1 done at :&#39;,ctime() def main(): print &#39;starting at :&#39;,ctime() thread.start_new_thread(loop0,()) thread.start_new_thread(loop1,()) #sleep(6) print &#39;all done at :&#39;,ctime() if __name__ == &#39;__main__&#39;: main() 注释掉了主线程中的sleep函数,发生了什么,反映了什么? 执行结果 子线程隶属于父线程,父线程生命周期结束时,子线程也会结束. 使用线程和锁 (mtsleepB.py)#!/usr/bin/env python # coding=utf-8 import thread from time import sleep , ctime loops = [4,2] def loop(nloop,nsec,lock): print &#39;start loop &#39;,nloop,&#39;at:&#39;,ctime() sleep(nsec) print &#39;loop &#39;,nloop ,&#39;done at :&#39;,ctime() lock.release() def main(): print &#39;starting at:&#39;,ctime() locks=[] nloops = range(len(loops)) #为线程创建锁 for i in nloops: lock = thread.allocate_lock() lock.acquire() locks.append(lock) #开始执行各个线程 for i in nloops: thread.start_new_thread(loop,(i,loops[i],locks[i])) #主线程等待所有的线程的锁完全释放 for i in nloops: while locks[i].locked():pass print &#39;all DONE at:&#39;,ctime() if __name__ == &#39;__main__&#39; : main() 执行结果:]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux内核模块编程]]></title>
    <url>%2F2017%2F04%2F21%2FLinux%E6%A8%A1%E5%9D%97%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运维面试题整理]]></title>
    <url>%2F2017%2F04%2F16%2F%E8%BF%90%E7%BB%B4%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[linux如何挂在windows下的共享目录 mount.cifs //192.168.1.3/server /mnt/server -o user=administrator,pass=123456 linux 下的server需要自己手动建一个 后面的user与pass 是windows主机的账号和密码 注意空格 和逗号 查看http的并发请求数与其TCP连接状态 netstat -n | awk &#39;/^tcp/ {++b[$NF]} END {for(a in b) print a, b[a]}&#39; 还有ulimit -n查看linux系统打开最大的文件描述符，这里默认1024，不修改这里web服务器修改再大也没用。若要用就修改很几个办法，这里说其中一个：修改/etc/security/limits.conf * soft nofile 10240 * hard nofile 10240 重启后生效 用tcpdump嗅探80端口的访问看看谁最高 tcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F&quot;.&quot; &#39;{print $1&quot;.&quot;$2&quot;.&quot;$3&quot;.&quot;$4}&#39; | sort | uniq -c | sort -nr |head -5 ; 查看/var/log目录下文件数 ls /var/log/ -lR| grep &quot;^-&quot; |wc -l 查看当前系统每个IP的连接数 netstat -n | awk &#39;/^tcp/ {print $5}&#39;| awk -F: &#39;{print $1}&#39; | sort | uniq -c | sort -rn shell下32位随机密码生成 cat /dev/urandom | head -1 | md5sum | head -c 32 &gt;&gt; /pass 将生成的32位随机数 保存到/pass文件里了 统计出apache的access.log中访问量最多的5个IP cat access_log | awk &#39;{print $1}&#39; | sort | uniq -c | sort -n -r | head -5 如何查看二进制文件的内容 我们一般通过hexdump命令 来查看二进制文件的内容。hexdump -C XXX(文件名) -C是参数 不同的参数有不同的意义-C 是比较规范的 十六进制和ASCII码显示-c 是单字节字符显示-b 单字节八进制显示-o 是双字节八进制显示-d 是双字节十进制显示-x 是双字节十六进制显示等等等等 ps aux 中的VSZ代表什么意思，RSS代表什么意思 VSZ:虚拟内存集,进程占用的虚拟内存空间RSS:物理内存集,进程占用的实际物理内存空间 检测并修复/dev/hda5 fsck用来检查和维护不一致的文件系统。若系统掉电或磁盘发生问题，可利用fsck命令对文件系统进行检查,用法： Linux系统的开机启动顺序 加载BIOS–&gt;读取MBR–&gt;Boot Loader–&gt;加载内核–&gt;用户层init一句inittab文件来设定系统运行的等级(一般3或者5，3是多用户命令行，5是界面)–&gt;init进程执行rc.syninit–&gt;启动内核模块–&gt;执行不同级别运行的脚本程序–&gt;执行/etc/rc.d/rc.local(本地运行服务)–&gt;执行/bin/login,就可以登录了。 符号链接与硬链接的区别 我们可以把符号链接，也就是软连接 当做是 windows系统里的 快捷方式。硬链接 就好像是 又复制了一份.ln 3.txt 4.txt 这是硬链接，相当于复制，不可以跨分区，但修改3,4会跟着变，若删除3,4不受任何影响。ln -s 3.txt 4.txt 这是软连接，相当于快捷方式。修改4,3也会跟着变，若删除3,4就坏掉了。不可以用了。 保存当前磁盘分区的分区表 dd 命令是以个强大的命令，在复制的同时进行转换 dd if=/dev/sda of=./mbr.txt bs=1 count=512 如何在文本里面进行复制、粘贴，删除行，删除全部，按行查找和按字母查找。 以下操作全部在命令行状态操作，不要在编辑状态操作。在文本里 移动到想要复制的行 按yy 想复制到哪就移动到哪，然后按P 就黏贴了删除行 移动到改行 按dd删除全部 dG 这里注意G一定要大写按行查找 :90 这样就是找到第90行按字母查找 /path 这样就是 找到path这个单词所在的位置，文本里可能存在多个,多次查找会显示在不同的位置。 手动安装grub grub-install /dev/sda 修改内核参数vi /etc/sysctl.conf 这里修改参数 sysctl -p 刷新后可用 在1-39内取随机数 expr $[$RANDOM%39] + 1 RANDOM 随机数%39 取余数 范围 0-38 限制apache每秒新建连接数为1，峰值为3 每秒新建连接数 一般都是由防火墙来做，apache本身好像无法设置每秒新建连接数，只能设置最大连接： iptables -A INPUT -d 172.16.100.1 -p tcp --dport 80 -m limit --limit 1/second -j ACCEPT 硬件防火墙设置更简单，有界面化，可以直接填写数字。。。最大连接 apache本身可以设置MaxClients 3 ,修改apache最大连接 前提还是要修改系统默认tcp连接数。我博客里也说了，这就不说了。 FTP的主动模式和被动模式 FTP协议有两种工作方式：PORT方式和PASV方式，中文意思为主动式和被动式。PORT（主动）方式的连接过程是：客户端向服务器的FTP端口（默认是21）发送连接请 求，服务器接受连接，建立一条命令链路。当需要传送数据时，客户端在命令链路上用PORT 命令告诉服务器：“我打开了XX端口，你过来连接我”。于是服务器从20端口向客户端的 XX端口发送连接请求，建立一条数据链路来传送数据。PASV（被动）方式的连接过程是：客户端向服务器的FTP端口（默认是21）发送连接请 求，服务器接受连接，建立一条命令链路。当需要传送数据时，服务器在命令链路上用PASV 命令告诉客户端：“我打开了XX端口，你过来连接我”。于是客户端向服务器的XX端口 发送连接请求，建立一条数据链路来传送数据。从上面可以看出，两种方式的命令链路连接方法是一样的，而数据链路的建立方法就完 全不同。 显示/etc/inittab中以#开头，且后面跟了一个或者多个空白字符，而后又跟了任意非空白字符的行 grep &quot;^# \{1,\}[^ ]&quot; /etc/inittab 显示/etc/inittab中包含了:一个数字:(即两个冒号中间一个数字)的行 grep &quot;\:[0-9]\{1\}\:&quot; /etc/inittab 怎么把脚本添加到系统服务里，即用service来调用 在脚本里加入 #!/bin/bash # chkconfig: 345 85 15 # description: httpd 然后保存chkconfig httpd –add 创建系统服务现在就可以使用service 来 start or restart 写一个脚本，实现批量添加20个用户，用户名为user01-20，密码为user后面跟5个随机字符 #!/bin/bash #description: useradd for i in `seq -f&quot;%02g&quot; 1 20`;do useradd user$i echo &quot;user$i-`echo $RANDOM|md5sum|cut -c 1-5`&quot;|passwd –stdinuser$i &gt;/dev/null 2&gt;&amp;1 done 写一个脚本，实现判断192.168.1.0/255网络里，当前在线的IP有哪些，能ping通则认为在线 Shell多线程 #!/bin/bash for ip in `seq 1 255` do { ping -c 1 192.168.1.$ip &gt; /dev/null 2&gt;&amp;1 if [ $? -eq 0 ]; then echo 192.168.1.$ip UP else echo 192.168.1.$ip DOWN fi }&amp; done wait 写一个脚本，判断一个指定的脚本是否是语法错误；如果有错误，则提醒用户键入Q或者q无视错误并退出其它任何键可以通过vim打开这个指定的脚本 [root@localhost tmp]# cat checksh.sh #!/bin/bash read -p &quot;please input check script-&gt; &quot; file if [ -f $file ]; then sh -n $file &gt; /dev/null 2&gt;&amp;1 if [ $? -ne 0 ]; then read -p &quot;You input $file syntax error,[Type q to exit or Type vim to edit]&quot; answer case $answer in q | Q) exit 0 ;; vim ) vim $file ;; *） exit 0 ;; esac fi else echo &quot;$file not exist&quot; exit 1 fi 写一个脚本：(26包括3个小题) 1、创建一个函数，能接受两个参数：1)第一个参数为URL，即可下载的文件；第二个参数为目录，即下载后保存的位置；2)如果用户给的目录不存在，则提示用户是否创建；如果创建就继续执行，否则，函数返回一个51的错误值给调用脚本；3)如果给的目录存在，则下载文件；下载命令执行结束后测试文件下载成功与否；如果成功，则返回0给调用脚本，否则，返回52给调用脚本； [root@localhost tmp]# cat downfile.sh #!/bin/bash url=$1 dir=$2 download() { cd $dir &gt;&gt; /dev/null 2&gt;&amp;1 if [ $? -ne 0 ];then read -p &quot;$dir No such file or directory,create?(y/n)&quot; answer if [ &quot;$answer&quot; == &quot;y&quot; ];then mkdir -p $dir cd $dir wget $url 1&gt; /dev/null 2&gt;&amp;1 else return &quot;51&quot; fi fi if [ $? -ne 0 ]; then return &quot;52&quot; fi } download $url $dir echo $? 写一个脚本：（27包括2个小题） 1、创建一个函数，可以接受一个磁盘设备路径（如/dev/sdb）作为参数;在真正开始后面步骤之前提醒用户有危险，并让用户选择是否继续；而后将此磁盘设备上的所有分区清空（提示，使用命令dd if=/dev/zero of=/dev/sdb bs=512 count=1实现，注意其中的设备路径不要写错了；如果此步骤失败，返回67给主程序；接着在此磁盘设备上创建两个主分区，一个大小为100M，一个大小为1G；如果此步骤失败，返回68给主程序；格式化此两分区，文件系统类型为ext3；如果此步骤失败，返回69给主程序；如果上述过程都正常，返回0给主程序；2、调用此函数；并通过接收函数执行的返回值来判断其执行情况，并将信息显示出来； local Darray=(`ls /dev/sd[a-z]`) for i in ${Darray};do [[ &quot;$i&quot; == &quot;$1&quot; ]] &amp;&amp; Sd=$i &amp;&amp;break done else return66 fi #当匹配成功，进入选择，告诉用户，是否继续，输错的话进入无限循环，当用户选择Y,则清空目标分区，且跳出while循环 while :;do read -p &quot;Warning!!!This operation will clean $Sd data.Next=y,Quit=n [y|n]:&quot; Choice case $Choice in y) dd if=/dev/zero of=$Sd bs=512 count=1 &amp;&gt; /dev/null &amp;&amp;break || return 67 ;; n) exit 88 ;; *) echo &quot;Invalid choice,please choice again.&quot; ;; esac done #使用echo传递给fdisk进行分区，如果此命令失败，则跳转出去，错误值68，需要注意的是，有时候这个返回值很诡异，笔者之前成功与否都是返回的1，后来重启之后，就好了，如果慎重的话，可以对创建的分区，进行判断，不过就需要使用其他工具截取相关字段了，虽有些小麻烦，但无大碍 echo-e &quot;n\np\n1\n\n+100M\nn\np\n2\n\n+1024M\nw\n&quot;|fdisk /dev/sdb&amp;&gt; /dev/null || return 68 #格式化之前，让内核重新读取磁盘分区表，值得注意的是，有的系统版本，使用partprobe无效，譬如笔者的环境是rhel5.8，而rhel6.0以后，这个命令就很危险了，而使用partx -a /dev/sdb则效果更好…此项需慎重，如果格式化失败，则告知把失败的分区定义成变量，且跳出函数，并带出错误值69 `partprobe` Part=`fdisk -l /dev/$Sd|tail -2|cut -d” ” -f1` for M in ${Part};do mke2fs -j $M &amp;&gt; /dev/null &amp;&amp; ErrorPart=$M &amp;&amp;return 69 done return 0 } #下面代码，调用函数，接收函数返回值，根据返回值进行判断哪里出错。 Disk_Mod $1 Res=$? [ $Res-eq 0 ] &amp;&amp; exit 0 [ $Res-eq 66 ] &amp;&amp; echo &quot;Error! Invalid input.&quot; [ $Res-eq 67 ] &amp;&amp; echo &quot;Error! Command -&gt; dd &lt;- Faild.&quot; [ $Res-eq 68 ] &amp;&amp; echo &quot;Error! Command -&gt; fdisk &lt;- Faild.&quot; [ $Res-eq 69 ] &amp;&amp; echo &quot;Error! Command -&gt; mke2fs &lt;- Faild.&quot;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器搭建之路]]></title>
    <url>%2F2017%2F04%2F13%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%E4%B9%8B%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[Linux下Nagios的安装与配置 在Ubuntu上安装配置Ganglia]]></content>
      <categories>
        <category>服务器搭建</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>服务器</tag>
        <tag>监控工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内核内存池-mempool]]></title>
    <url>%2F2017%2F04%2F07%2F%E5%86%85%E6%A0%B8%E5%86%85%E5%AD%98%E6%B1%A0-mempool%2F</url>
    <content type="text"><![CDATA[内存池(Memery Pool)技术是在真正使用内存之前，先申请分配一定数量的、大小相等(一般情况下)的内存块留作备用。当有新的内存需求时，就从内存池中分出一部分内存块，若内存块不够再继续申请新的内存。这样做的一个显著优点是尽量避免了内存碎片，使得内存分配效率得到提升。 不仅在用户态应用程序中被广泛使用，同时在Linux内核也被广泛使用，在内核中有不少地方内存分配不允许失败。作为一个在这些情况下确保分配的方式，内核开发者创建了一个已知为内存池(或者是 “mempool” )的抽象，内核中内存池真实地只是相当于后备缓存，它尽力一直保持一个空闲内存列表给紧急时使用，而在通常情况下有内存需求时还是从公共的内存中直接分配，这样的做法虽然有点霸占内存的嫌疑，但是可以从根本上保证关键应用在内存紧张时申请内存仍然能够成功。 下面看下内核内存池的源码，内核内存池的源码在中，实现上非常简洁，描述内存池的结构mempool_t在头文件中定义，结构描述如下： typedef struct mempool_s { spinlock_t lock; /*保护内存池的自旋锁*/ int min_nr; /*内存池中最少可分配的元素数目*/ int curr_nr; /*尚余可分配的元素数目*/ void **elements; /*指向元素池的指针*/ void *pool_data; /*内存源，即池中元素真实的分配处*/ mempool_alloc_t *alloc; /*分配元素的方法*/ mempool_free_t *free; /*回收元素的方法*/ wait_queue_head_t wait; /*被阻塞的等待队列*/ } mempool_t; 内存池的创建函数mempool_create的函数原型如下： mempool_t *mempool_create(int min_nr, mempool_alloc_t *alloc_fn, mempool_free_t *free_fn, void *pool_data) { return mempool_create_node(min_nr,alloc_fn,free_fn, pool_data,-1); } 函数原型指定内存池可以容纳元素的个数、申请元素的方法、释放元素的方法，以及一个可选的内存源(通常是一个cache)，内存池对象创建完成后会自动调用alloc方法从pool_data上分配min_nr个元素用来填充内存池。内存池的释放函数mempool_destory函数的原型很简单，应该也能猜到是依次将元素对象从池中移除，再释放给pool_data，最后释放池对象，如下： void mempool_destroy(mempool_t *pool) { while (pool-&gt;curr_nr) { void *element = remove_element(pool); pool-&gt;free(element, pool-&gt;pool_data); } kfree(pool-&gt;elements); kfree(pool); } 值得注意的是内存池分配和回收对象的函数：mempool_alloc和mempool_free。mempool_alloc的作用是从指定的内存池中申请/获取一个对象，函数原型如下： void * mempool_alloc(mempool_t *pool, gfp_t gfp_mask){ ...... element = pool-&gt;alloc(gfp_temp, pool-&gt;pool_data); if (likely(element != NULL)) return element; spin_lock_irqsave(&amp;pool-&gt;lock, flags); if (likely(pool-&gt;curr_nr)) { element = remove_element(pool);/*从内存池中提取一个对象*/ spin_unlock_irqrestore(&amp;pool-&gt;lock, flags); /* paired with rmb in mempool_free(), read comment there */ smp_wmb(); return element; } ...... } 函数先是从pool_data中申请元素对象，当从pool_data无法成功申请到时，才会从池中提取对象使用，因此可以发现内核内存池mempool其实是一种后备池，在内存紧张的情况下才会真正从池中获取，这样也就能保证在极端情况下申请对象的成功率，单也不一定总是会成功，因为内存池的大小毕竟是有限的，如果内存池中的对象也用完了，那么进程就只能进入睡眠，也就是被加入到pool-&gt;wait的等待队列，等待内存池中有可用的对象时被唤醒，重新尝试从池中申请元素： init_wait(&amp;wait); prepare_to_wait(&amp;pool-&gt;wait, &amp;wait, TASK_UNINTERRUPTIBLE); spin_unlock_irqrestore(&amp;pool-&gt;lock, flags); io_schedule_timeout(5*HZ); finish_wait(&amp;pool-&gt;wait, &amp;wait); 池回收对象的函数mempool_free的原型如下： void mempool_free(void *element, mempool_t *pool) { if (pool-&gt;curr_nr min_nr) { spin_lock_irqsave(&amp;pool-&gt;lock, flags); if (pool-&gt;curr_nr min_nr) { add_element(pool, element); spin_unlock_irqrestore(&amp;pool-&gt;lock, flags); wake_up(&amp;pool-&gt;wait); return; } spin_unlock_irqrestore(&amp;pool-&gt;lock, flags); } pool-&gt;free(element, pool-&gt;pool_data); } 其实原则跟mempool_alloc是对应的，释放对象时先看池中的可用元素是否充足(pool-&gt;curr_nr == pool-&gt;min_nr)，如果不是则将元素对象释放回池中，否则将元素对象还给pool-&gt;pool_data。 此外mempool也提供或者说指定了几对alloc/free函数，及在mempool_create创建池时必须指定的alloc和free函数，分别适用于不同大小或者类型的元素的内存池，具体如下： void *mempool_alloc_slab(gfp_t gfp_mask, void *pool_data) { struct kmem_cache *mem = pool_data; return kmem_cache_alloc(mem, gfp_mask); } void mempool_free_slab(void *element, void *pool_data) { struct kmem_cache *mem = pool_data; kmem_cache_free(mem, element); } void *mempool_kmalloc(gfp_t gfp_mask, void *pool_data) { size_t size = (size_t)pool_data; return kmalloc(size, gfp_mask); } void mempool_kfree(void *element, void *pool_data) { kfree(element); } void *mempool_alloc_pages(gfp_t gfp_mask, void *pool_data) { int order = (int)(long)pool_data; return alloc_pages(gfp_mask, order); } void mempool_free_pages(void *element, void *pool_data) { int order = (int)(long)pool_data; __free_pages(element, order); } 总体上来讲mempool的实现很简约，但是不简单，而且非常轻便易用，这也是内核奥妙之所在。 原文地址]]></content>
      <categories>
        <category>linux系统知识</category>
      </categories>
      <tags>
        <tag>内核</tag>
        <tag>存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[块设备驱动详解]]></title>
    <url>%2F2017%2F04%2F06%2F%E5%9D%97%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[块设备与字符设备的区别1、 从字面上理解，块设备和字符设备最大的区别在于读写数据的基本单元不同。块设备读写数据的基本单元为块，例如磁盘通常为一个sector，而字符设备的基本单元为字节。所以Linux中块设备驱动往往为磁盘设备的驱动，但是由于磁盘设备的IO性能与CPU相比很差，因此，块设备的数据流往往会引入文件系统的Cache机制。 2、 从实现角度来看，Linux为块设备和字符设备提供了两套机制。 字符设备实现的比较简单，内核例程和用户态API一一对应，用户层的Read函数直接对应了内核中的Read例程，这种映射关系由字符设备的file_operations维护。块设备接口相对于字符设备复杂，read、write API没有直接到块设备层，而是直接到文件系统层，然后再由文件系统层发起读写请求。 块设备读写流程在学习块设备原理的时候，我最关系块设备的数据流程，从应用程序调用Read或者Write开始，数据在内核中到底是如何流通、处理的呢？然后又如何抵达具体的物理设备的呢？下面对一个带Cache功能的块设备数据流程进行分析。 1、 用户态程序通过open()打开指定的块设备，通过systemcall机制陷入内核，执行blkdev_open()函数，该函数注册到文件系统方法（file_operations）中的open上。在blkdev_open函数中调用bd_acquire()函数，bd_acquire函数完成文件系统inode到块设备bdev的转换，具体的转换方法通过hash查找实现。得到具体块设备的bdev之后，调用do_open()函数完成设备打开的操作。在do_open函数中会调用到块设备驱动注册的open方法，具体调用如下：gendisk-&gt;fops-&gt;open(bdev-&gt;bd_inode, file)。 2、 用户程序通过read、write函数对设备进行读写，文件系统会调用相应的方法，通常会调用如下两个函数：generic_file_read和blkdev_file_write。在读写过程中采用了多种策略，首先分析读过程。 3、 用户态调用了read函数，内核执行generic_file_read，如果不是direct io方式，那么直接调用do_generic_file_read-&gt;do_generic_mapping_read()函数，在do_generic_mapping_read（函数位于filemap.c）函数中，首先查找数据是否命中Cache，如果命中，那么直接将数据返回给用户态；否则通过address_space-&gt;a_ops-&gt;readpage函数发起一个真实的读请求。在readpage函数中，构造一个buffer_head，设置bh回调函数end_buffer_async_read，然后调用submit_bh发起请求。在submit_bh函数中，根据buffer_head构造bio，设置bio的回调函数end_bio_bh_io_sync，最后通过submit_bio将bio请求发送给指定的快设备。 4、 如果用户态调用了一个write函数，内核执行blkdev_file_write函数，如果不是direct io操作方式，那么执行buffered write操作过程，直接调用generic_file_buffered_write函数。Buffered write操作方法会将数据直接写入Cache，并进行Cache的替换操作，在替换操作过程中需要对实际的快设备进行操作，address_space-&gt;a_ops提供了块设备操作的方法。当数据被写入到Cache之后，write函数就可以返回了，后继异步写入的任务绝大部分交给了pdflush daemon（有一部分在替换的时候做了） 5、 数据流操作到这一步，我们已经很清楚用户的数据是如何到内核了。与用户最接近的方法是file_operations，每种设备类型都定义了这一方法（由于Linux将所有设备都看成是文件，所以为每类设备都定义了文件操作方法，例如，字符设备的操作方法为def_chr_fops，块设备为def_blk_fops，网络设备为bad_sock_fops）。每种设备类型底层操作方法是不一样的，但是通过file_operations方法将设备类型的差异化屏蔽了，这就是Linux能够将所有设备都理解为文件的缘由。到这里，又提出一个问题：既然这样，那设备的差异化又该如何体现呢？在文件系统层定义了文件系统访问设备的方法，该方法就是address_space_operations，文件系统通过该方法可以访问具体的设备。对于字符设备而言，没有实现address_space_operations方法，也没有必要，因为字符设备的接口与文件系统的接口是一样的，在字符设备open操作的过程中，将inode所指向的file_operations替换成cdev所指向的file_operations就可以了。这样用户层读写字符设备可以直接调用cdev中file_operations方法了。 6、 截至到步骤（4），读操作在没有命中Cache的情况下通过address_space_operations方法中的readpage函数发起块设备读请求；写操作在替换Cache或者Pdflush唤醒时发起块设备请求。发起块设备请求的过程都一样，首先根据需求构建bio结构，bio结构中包含了读写地址、长度、目的设备、回调函数等信息。构造完bio之后，通过简单的submit_bio函数将请求转发给具体的块设备。从这里可以看出，块设备接口很简单，接口方法为submit_bio（更底层函数为generic_make_request），数据结构为struct bio。 7、 submit_bio函数通过generic_make_request转发bio，generic_make_request是一个循环，其通过每个块设备下注册的q-&gt;make_request_fn函数与块设备进行交互。如果访问的块设备是一个有queue的设备，那么会将系统的__make_request函数注册到q-&gt;make_request_fn中；否则块设备会注册一个私有的方法。在私有的方法中，由于不存在queue队列，所以不会处理具体的请求，而是通过修改bio中的方法实现bio的转发，在私有make_request方法中，往往会返回1，告诉generic_make_request继续转发比bio。Generic_make_request的执行上下文可能有两种，一种是用户上下文，另一种为pdflush所在的内核线程上下文。 8、 通过generic_make_request的不断转发，最后请求一定会到一个存在queue队列的块设备上，假设最终的那个块设备是某个scsi disk（/dev/sda）。generic_make_request将请求转发给sda时，调用make_request，该函数是Linux提供的块设备请求处理函数。在该函数中实现了极其重要的操作，通常所说的IO Schedule就在该函数中实现。在该函数中试图将转发过来的bio merge到一个已经存在的request中，如果可以合并，那么将新的bio请求挂载到一个已经存在request中。如果不能合并，那么分配一个新的request，然后将bio添加到其中。这一切搞定之后，说明通过generic_make_request转发的bio已经抵达了内核的一个站点——request，找到了一个临时归宿。此时，还没有真正启动物理设备的操作。在make_request退出之前，会判断一个bio中的sync标记，如果该标记有效，说明请求的bio是一个是实时性很强的操作，不能在内核中停留，因此调用了generic_unplug_device函数，该函数将触发下一阶段的操作；如果该标记无效的话，那么该请求就需要在queue队列中停留一段时间，等到queue队列触发闹钟响了之后，再触发下一阶段的操作。make_request函数返回0，告诉generic_make_request无需再转发bio了，bio转发结束。 9、 到目前为止，文件系统（pdflush或者address_space_operations）发下来的bio已经merge到request queue中，如果为sync bio，那么直接调用__generic_unplug_device，否则需要在unplug timer的软中断上下文中执行q-&gt;unplug_fn。后继request的处理方法应该和具体的物理设备相关，但是在标准的块设备上如何体现不同物理设备的差异性呢？这种差异性就体现在queue队列的方法上，不同的物理设备，queue队列的方法是不一样的。举例中的sda是一个scsi设备，在scsi middle level将scsi_request_fn函数注册到了queue队列的request_fn方法上。在q-&gt;unplug_fn（具体方法为：generic_unplug_device）函数中会调用request队列的具体处理函数q-&gt;request_fn。Ok，到这一步实际上已经将块设备层与scsi总线驱动层联系在了一起，他们的接口方法为request_fn（具体函数为scsi_request_fn）。 10、明白了第（9）点之后，接下来的过程实际上和具体的scsi总线操作相关了。在scsi_request_fn函数中会扫描request队列，通过elv_next_request函数从队列中获取一个request。在elv_next_request函数中通过scsi总线层注册的q-&gt;prep_rq_fn（scsi层注册为scsi_prep_fn）函数将具体的request转换成scsi驱动所能认识的scsi command。获取一个request之后，scsi_request_fn函数直接调用scsi_dispatch_cmd函数将scsi command发送给一个具体的scsi host。到这一步，有一个问题：scsi command具体转发给那个scsi host呢？秘密就在于q-&gt;queuedata中，在为sda设备分配queue队列时，已经指定了sda块设备与底层的scsi设备（scsi device）之间的关系，他们的关系是通过request queue维护的。 11、 在scsi_dispatch_cmd函数中，通过scsi host的接口方法queuecommand将scsi command发送给scsi host。通常scsi host的queuecommand方法会将接收到的scsi command挂到自己维护的队列中，然后再启动DMA过程将scsi command中的数据发送给具体的磁盘。DMA完毕之后，DMA控制器中断CPU，告诉CPU DMA过程结束，并且在中断上下文中设置DMA结束的中断下半部。DMA中断服务程序返回之后触发软中断，执行SCSI中断下半部。 12、 在SCSi中断下半部中，调用scsi command结束的回调函数，这个函数往往为scsi_done，在scsi_done函数调用blk_complete_request函数结束请求request，每个请求维护了一个bio链，所以在结束请求过程中回调每个请求中的bio回调函数，结束具体的bio。Bio又有文件系统的buffer head生成，所以在结束bio时，回调buffer_head的回调处理函数bio-&gt;bi_end_io（注册为end_bio_bh_io_sync）。自此，由中断引发的一系列回调过程结束，总结一下回调过程如下：scsi_done-&gt;end_request-&gt;end_bio-&gt;end_bufferhead。 13、 回调结束之后，文件系统引发的读写操作过程结束。]]></content>
  </entry>
  <entry>
    <title><![CDATA[nginx学习]]></title>
    <url>%2F2017%2F04%2F06%2Fnginx%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[##模块按功能划分: handles(处理器模块) filers(过滤器模块) proxies(代理类模块)]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[响应码]]></title>
    <url>%2F2017%2F04%2F03%2F%E5%93%8D%E5%BA%94%E7%A0%81%2F</url>
    <content type="text"><![CDATA[1XX: 信息2XX: 成功类的状态码3XX: 提示需进一步提供信息的状态码4XX: 客户端错误5XX: 服务端错误]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用shell]]></title>
    <url>%2F2017%2F04%2F03%2F%E5%B8%B8%E7%94%A8shell%2F</url>
    <content type="text"><![CDATA[##查看当前开启的服务 ls /etc/rc`runlevel|sed &#39;s/N.//&#39;`.d|awk &#39;!/K/ {print}&#39;|sed &#39;s/S[0-9][0-9]//&#39; sudo service --status-all]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大创构思]]></title>
    <url>%2F2017%2F04%2F02%2F%E5%A4%A7%E5%88%9B%E6%9E%84%E6%80%9D%2F</url>
    <content type="text"><![CDATA[更新点概述 增加网页IDE,功能 查重功能 分步计分 论坛 天梯训练模式 教学统计查看 当前oj功能完善 分工 网页IDE 徐瑶琨 论坛 范得良 天梯训练模式 马琨 教学统计功能,查重,分步计分,当前OJ功能完善,整合 李闯 OnlineJudgeOpenAPI文档为了方便与Virtual Judge和第三方论坛等进行集成，开放了获取题目详细信息、提交代码、获取代码运行结果和用户SSO单点登录四个API。 在使用API之前，请先申请appkey，在个人设置页面可以看到，如果没有申请过，请联系OJ的管理员在后台开通。 API说明所有的返回值都是{&quot;code&quot;: , data: }的形式，只有code为0的时候代表正常返回了，data为数据内容。其余code表示出现错误，data为错误提示。 所有的POST请求和响应都是json格式的，POST请求的Content-Type确保为application/json。 获取题目详细信息request GET /api/open/problem/?appkey=&amp;problem_id=response { &quot;code&quot;: 0, &quot;data&quot;: { // 题目的id &quot;id&quot;: 1, // 样例输入和输出 &quot;samples&quot;: [ { &quot;input&quot;: &quot;1 1&quot;, &quot;output&quot;: &quot;2&quot; }, { &quot;input&quot;: &quot;1 1&quot;, &quot;output&quot;: &quot;2&quot; }, { &quot;input&quot;: &quot;1 -1&quot;, &quot;output&quot;: &quot;0&quot; } ], // 标签 &quot;tags&quot;: [ { &quot;id&quot;: 1, &quot;name&quot;: &quot;简单&quot; } ], // 创建用户 &quot;created_by&quot;: { &quot;username&quot;: &quot;root&quot; }, // 题目 &quot;title&quot;: &quot;A + B Problem&quot;, // 描述 HTML格式 &quot;description&quot;: &quot;请计算两个整数的和并输出结果。注意不要有不必要的输出，比如&amp;quot;请输入 a 和 b 的值: &amp;quot;，示例代码见隐藏部分。&quot;, // 输入说明 &quot;input_description&quot;: &quot;两个用空格分开的整数.&quot;, // 输出说明 &quot;output_description&quot;: &quot;两数之和&quot;, // 提示 没有提示就是空字符串 &quot;hint&quot;: &quot;测试题目&quot;, // 创建时间 &quot;create_time&quot;: &quot;2015-09-02T13:02:26Z&quot;, // 最后修改时间 如果没有修改过，就是NULL &quot;last_update_time&quot;: &quot;2016-02-02T03:43:34.244046Z&quot;, // 时间限制 单位ms &quot;time_limit&quot;: 1000, // 内存限制 单位M &quot;memory_limit&quot;: 512, // 总共提交次数 &quot;total_submit_number&quot;: 1128, // 总共ac次数 &quot;total_accepted_number&quot;: 521, // 难度 1-3 简单到难 &quot;difficulty&quot;: 1, // 题目来源 &quot;source&quot;: &quot;经典题目&quot; } } 提交题目request post /api/open/submission/ { // appkey &quot;appkey&quot;: &quot;example_appkey&quot;, // 代码 &quot;code&quot;: &quot;example code&quot;, // 语言 1:C 2:C++ 3:Java &quot;language&quot;: 1, // 题目id &quot;problem_id&quot;: 1 } response提交代码后，服务器立即返回，并异步判题。 { &quot;code&quot;: 0, &quot;data&quot;: { // 提交id &quot;submission_id&quot;: &quot;4e49416e087f79fd3d0822b1899d601c&quot; } } 要注意的是，每个用户都有自己的提交频率限制。开源代码中，默认使用的TokenBucket进行的限制，每个用户默认有50个token，然后每分钟可以创建2个token，但是也是50个token封顶，每提交一道题就消耗一个token。开始的50个token可以保证一定时间的并发需求，如果超过频率限制将返回错误和需要等待的时间。 获取提交结果request GET /api/open/submission/?appkey=&amp;submission_id= response { &quot;code&quot;: 0, &quot;data&quot;: { &quot;id&quot;: &quot;9d4610ef9ae6b30e588c650891ba6858&quot;, &quot;result&quot;: 0, &quot;create_time&quot;: &quot;2016-02-16T03:54:10Z&quot;, &quot;language&quot;: 1, // info可能是None或者字符串 // 在编译错误和系统错误的时候info为错误详情，可能会很长，其余的情况为一个json字符串 &quot;info&quot;: &quot;[{\&quot;cpu_time\&quot;: 0, \&quot;exit_status\&quot;: 0, \&quot;signal\&quot;: 0, \&quot;output_md5\&quot;: \&quot;33d6548e48d4318ceb0e3916a79afc84\&quot;, \&quot;flag\&quot;: 0, \&quot;result\&quot;: 0, \&quot;memory\&quot;: 7602176, \&quot;real_time\&quot;: 4}, {\&quot;cpu_time\&quot;: 0, \&quot;exit_status\&quot;: 0, \&quot;signal\&quot;: 0, \&quot;output_md5\&quot;: \&quot;e4da3b7fbbce2345d7772b0674a318d5\&quot;, \&quot;flag\&quot;: 0, \&quot;result\&quot;: 0, \&quot;memory\&quot;: 7602176, \&quot;real_time\&quot;: 2}]&quot; } } result的对应关系 { &quot;accepted&quot;: 0, &quot;runtime_error&quot;: 1, &quot;time_limit_exceeded&quot;: 2, &quot;memory_limit_exceeded&quot;: 3, &quot;compile_error&quot;: 4, &quot;format_error&quot;: 5, &quot;wrong_answer&quot;: 6, &quot;system_error&quot;: 7, &quot;waiting&quot;: 8 } SSO单点登录request GET /account/sso/?callback= 然后用户确认登录之后，会跳转到http://callback_url?token=上，需要获取token参数，然后 request POST /account/sso/ { &quot;appkey&quot;: &quot;example_appkey&quot;, &quot;token&quot;: &quot;example_token&quot; } response { &quot;code&quot;: 0, &quot;data&quot;: { &quot;username&quot;: &quot;root&quot;, &quot;admin_type&quot;: 2, &quot;id&quot;: 1, &quot;avatar&quot;: &quot;/static/img/avatar/avatar-10.png&quot; } } 注意回调的token和appkey并没有关系，这个token只能一次性使用。]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>Diary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用Git命令清单]]></title>
    <url>%2F2017%2F04%2F01%2F%E5%B8%B8%E7%94%A8Git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95%2F</url>
    <content type="text"><![CDATA[简介 Workspace：工作区 Index / Stage：暂存区 Repository：仓库区（或本地仓库） Remote：远程仓库 新建代码库# 在当前目录新建一个Git代码库 $ git init # 新建一个目录，将其初始化为Git代码库 $ git init [project-name] # 下载一个项目和它的整个代码历史 $ git clone [url] 配置Git的设置文件为.gitconfig，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。 # 显示当前的Git配置 $ git config --list # 编辑Git配置文件 $ git config -e [--global] # 设置提交代码时的用户信息 $ git config [--global] user.name &quot;[name]&quot; $ git config [--global] user.email &quot;[email address]&quot; 增加/删除文件# 添加指定文件到暂存区 $ git add [file1] [file2] ... # 添加指定目录到暂存区，包括子目录 $ git add [dir] # 添加当前目录的所有文件到暂存区 $ git add . # 添加每个变化前，都会要求确认 # 对于同一个文件的多处变化，可以实现分次提交 $ git add -p # 删除工作区文件，并且将这次删除放入暂存区 $ git rm [file1] [file2] ... # 停止追踪指定文件，但该文件会保留在工作区 $ git rm --cached [file] # 改名文件，并且将这个改名放入暂存区 $ git mv [file-original] [file-renamed] 代码提交# 提交暂存区到仓库区 $ git commit -m [message] # 提交暂存区的指定文件到仓库区 $ git commit [file1] [file2] ... -m [message] # 提交工作区自上次commit之后的变化，直接到仓库区 $ git commit -a # 提交时显示所有diff信息 $ git commit -v # 使用一次新的commit，替代上一次提交 # 如果代码没有任何新变化，则用来改写上一次commit的提交信息 $ git commit --amend -m [message] # 重做上一次commit，并包括指定文件的新变化 $ git commit --amend [file1] [file2] ... 分支# 列出所有本地分支 $ git branch # 列出所有远程分支 $ git branch -r # 列出所有本地分支和远程分支 $ git branch -a # 新建一个分支，但依然停留在当前分支 $ git branch [branch-name] # 新建一个分支，并切换到该分支 $ git checkout -b [branch] # 新建一个分支，指向指定commit $ git branch [branch] [commit] # 新建一个分支，与指定的远程分支建立追踪关系 $ git branch --track [branch] [remote-branch] # 切换到指定分支，并更新工作区 $ git checkout [branch-name] # 切换到上一个分支 $ git checkout - # 建立追踪关系，在现有分支与指定的远程分支之间 $ git branch --set-upstream [branch] [remote-branch] # 合并指定分支到当前分支 $ git merge [branch] # 选择一个commit，合并进当前分支 $ git cherry-pick [commit] # 删除分支 $ git branch -d [branch-name] # 删除远程分支 $ git push origin --delete [branch-name] $ git branch -dr [remote/branch] 标签# 列出所有tag $ git tag # 新建一个tag在当前commit $ git tag [tag] # 新建一个tag在指定commit $ git tag [tag] [commit] # 删除本地tag $ git tag -d [tag] # 删除远程tag $ git push origin :refs/tags/[tagName] # 查看tag信息 $ git show [tag] # 提交指定tag $ git push [remote] [tag] # 提交所有tag $ git push [remote] --tags # 新建一个分支，指向某个tag $ git checkout -b [branch] [tag] 查看信息# 显示有变更的文件 $ git status # 显示当前分支的版本历史 $ git log # 显示commit历史，以及每次commit发生变更的文件 $ git log --stat # 搜索提交历史，根据关键词 $ git log -S [keyword] # 显示某个commit之后的所有变动，每个commit占据一行 $ git log [tag] HEAD --pretty=format:%s # 显示某个commit之后的所有变动，其&quot;提交说明&quot;必须符合搜索条件 $ git log [tag] HEAD --grep feature # 显示某个文件的版本历史，包括文件改名 $ git log --follow [file] $ git whatchanged [file] # 显示指定文件相关的每一次diff $ git log -p [file] # 显示过去5次提交 $ git log -5 --pretty --oneline # 显示所有提交过的用户，按提交次数排序 $ git shortlog -sn # 显示指定文件是什么人在什么时间修改过 $ git blame [file] # 显示暂存区和工作区的差异 $ git diff # 显示暂存区和上一个commit的差异 $ git diff --cached [file] # 显示工作区与当前分支最新commit之间的差异 $ git diff HEAD # 显示两次提交之间的差异 $ git diff [first-branch]...[second-branch] # 显示今天你写了多少行代码 $ git diff --shortstat &quot;@{0 day ago}&quot; # 显示某次提交的元数据和内容变化 $ git show [commit] # 显示某次提交发生变化的文件 $ git show --name-only [commit] # 显示某次提交时，某个文件的内容 $ git show [commit]:[filename] # 显示当前分支的最近几次提交 $ git reflog 远程同步# 下载远程仓库的所有变动 $ git fetch [remote] # 显示所有远程仓库 $ git remote -v # 显示某个远程仓库的信息 $ git remote show [remote] # 增加一个新的远程仓库，并命名 $ git remote add [shortname] [url] # 取回远程仓库的变化，并与本地分支合并 $ git pull [remote] [branch] # 上传本地指定分支到远程仓库 $ git push [remote] [branch] # 强行推送当前分支到远程仓库，即使有冲突 $ git push [remote] --force # 推送所有分支到远程仓库 $ git push [remote] --all 撤销# 恢复暂存区的指定文件到工作区 $ git checkout [file] # 恢复某个commit的指定文件到暂存区和工作区 $ git checkout [commit] [file] # 恢复暂存区的所有文件到工作区 $ git checkout . # 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变 $ git reset [file] # 重置暂存区与工作区，与上一次commit保持一致 $ git reset --hard # 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变 $ git reset [commit] # 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致 $ git reset --hard [commit] # 重置当前HEAD为指定commit，但保持暂存区和工作区不变 $ git reset --keep [commit] # 新建一个commit，用来撤销指定commit # 后者的所有变化都将被前者抵消，并且应用到当前分支 $ git revert [commit] # 暂时将未提交的变化移除，稍后再移入 $ git stash $ git stash pop 其他# 生成一个可供发布的压缩包 $ git archive 使用问题记录git pull 出现错误 由于git pull的内容与本地commit的内容产生了冲突。解决方法 产生冲突后，git会自动在本地记录冲突，修改本地的文件后，git add -u git push origin master即可 转自]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tr命令]]></title>
    <url>%2F2017%2F03%2F31%2Ftr%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[简介 通过使用 tr，您可以非常容易地实现 sed 的许多最基本功能。您可以将 tr 看作为 sed 的（极其）简化的变体：它可以用一个字符来替换另一个字符，或者可以完全除去一些字符。您也可以用它来除去重复字符。这就是所有 tr 所能够做的。 tr用来从标准输入中通过替换或删除操作进行字符转换。tr主要用于删除文件中控制字符或进行字符转换。使用tr时要转换两个字符串：字符串1用于查询，字符串2用于处理各种转换。tr刚执行时，字符串1中的字符被映射到字符串2中的字符，然后转换操作开始。 带有最常用选项的tr命令格式为：tr -c -d -s [“string1_to_translate_from”] [“string2_to_translate_to”] input-file 参数-c 用字符串1中字符集的补集替换此字符集，要求字符集为ASCII。 -d 删除字符串1中所有输入字符。 -s 删除所有重复出现字符序列，只保留第一个；即将重复出现字符串压缩为一个字符串。 input-file是转换文件名。虽然可以使用其他格式输入，但这种格式最常用。 字符范围指定字符串1或字符串2的内容时，只能使用单字符或字符串范围或列表。 [a-z] a-z内的字符组成的字符串。 [A-Z] A-Z内的字符组成的字符串。 [0-9] 数字串。 \octal 一个三位的八进制数，对应有效的ASCII字符。 [O*n] 表示字符O重复出现指定次数n。因此[O*2]匹配OO的字符串。 tr中特定控制字符的不同表达方式 速记符含义八进制方式\a Ctrl-G 铃声\007 \b Ctrl-H 退格符\010 \f Ctrl-L 走行换页\014 \n Ctrl-J 新行\012 \r Ctrl-M 回车\015 \t Ctrl-I tab键\011 \v Ctrl-X \030 实例：1.将文件file中出现的”abc”替换为”xyz” cat file | tr &quot;abc&quot; &quot;xyz&quot; &gt; new_file 【注意】这里，凡是在file中出现的”a”字母，都替换成”x”字母，”b”字母替换为”y”字母，”c”字母替换为”z”字母。而不是将字符串”abc”替换为字符串”xyz”。 2.使用tr命令“统一”字母大小写 （小写 --&gt; 大写） cat file | tr [a-z] [A-Z] &gt; new_file （大写 --&gt; 小写） cat file | tr [A-Z] [a-z] &gt; new_file 3.把文件中的数字0-9替换为a-j cat file | tr [0-9] [a-j] &gt; new_file 4、删除文件file中出现的”Snail”字符 cat file | tr -d &quot;Snail&quot; &gt; new_file 【注意】这里，凡是在file文件中出现的’S’,’n’,’a’,’i’,’l’字符都会被删除！而不是紧紧删除出现的”Snail”字符串。 5、删除文件file中出现的换行’\n’、制表’\t’字符 cat file | tr -d &quot;\n\t&quot; &gt; new_file 不可见字符都得用转义字符来表示的，这个都是统一的。 6、删除“连续着的”重复字母，只保留第一个 cat file | tr -s [a-zA-Z] &gt; new_file 7、删除空行 cat file | tr -s &quot;\n&quot; &gt; new_file 8、删除Windows文件“造成”的’^M’字符 cat file | tr -d &quot;\r&quot; &gt; new_file 或者 cat file | tr -s &quot;\r&quot; &quot;\n&quot; &gt; new_file 【注意】这里-s后面是两个参数”\r”和”\n”，用后者替换前者 9、用空格符\040替换制表符\011 cat file | tr -s &quot;\011&quot; &quot;\040&quot; &gt; new_file 10、把路径变量中的冒号”:”，替换成换行符”\n” echo $PATH | tr -s &quot;:&quot; &quot;\n&quot;]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用apt命令参数]]></title>
    <url>%2F2017%2F03%2F31%2F%E5%B8%B8%E7%94%A8apt%E5%91%BD%E4%BB%A4%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[常用的APT命令参数： apt-cache search package 搜索包 apt-cache show package 获取包的相关信息，如说明、大小、版本等 sudo apt-get install package 安装包 sudo apt-get install package - - reinstall 重新安装包 sudo apt-get -f install 修复安装”-f = ——fix-missing” sudo apt-get remove package 删除包 sudo apt-get remove package - - purge 删除包，包括删除配置文件等 sudo apt-get update 更新源 sudo apt-get upgrade 更新已安装的包 sudo apt-get dist-upgrade 升级系统 sudo apt-get dselect-upgrade 使用 dselect 升级 apt-cache depends package 了解使用依赖 apt-cache rdepends package 是查看该包被哪些包依赖 sudo apt-get build-dep package 安装相关的编译环境 apt-get source package 下载该包的源代码 sudo apt-get clean &amp;&amp; sudo apt-get autoclean 清理无用的包 sudo apt-get check 检查是否有损坏的依赖]]></content>
      <tags>
        <tag>知识点</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决Ubuntu 16.04 搜狗输入法 只有悬浮窗中文不能自动联想的问题]]></title>
    <url>%2F2017%2F03%2F30%2F%E8%A7%A3%E5%86%B3Ubuntu-16-04-%E6%90%9C%E7%8B%97%E8%BE%93%E5%85%A5%E6%B3%95-%E5%8F%AA%E6%9C%89%E6%82%AC%E6%B5%AE%E7%AA%97%E4%B8%AD%E6%96%87%E4%B8%8D%E8%83%BD%E8%87%AA%E5%8A%A8%E8%81%94%E6%83%B3%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[一直用得好好的，不知道下载了什么更新导致搜狗输入法，在输入中文的时候，只显示一个悬浮窗。打字的时候什么反应都没有。中文也联想不出来。 找了半天，重新安装fcitx/搜狗输入法N次无果，在网上论坛找到了答案，修复了这个问题，记录一下。 直接删除其配置文件： rm -rf ~/.config/SogouPY* ~/.config/sogou* 然后直接在右上角点fcitx图标，下拉列表里面重启fcitx输入法 转载自]]></content>
      <categories>
        <category>Ubuntu使用</category>
      </categories>
      <tags>
        <tag>小问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP和UDP套接字C语言实现]]></title>
    <url>%2F2017%2F03%2F28%2FTCP%E5%92%8CUDP%E5%A5%97%E6%8E%A5%E5%AD%97C%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[字符串传输TCP客户端#include #include #include #include #include #include #include #include #include #include #define MYPORT 8887 #define BUFFER_SIZE 1024 int main() { ///定义sockfd int sock_cli = socket(AF_INET,SOCK_STREAM, 0); ///定义sockaddr_in struct sockaddr_in servaddr; memset(&amp;servaddr, 0, sizeof(servaddr)); servaddr.sin_family = AF_INET; servaddr.sin_port = htons(MYPORT); ///服务器端口 servaddr.sin_addr.s_addr = inet_addr(&quot;127.0.0.1&quot;); ///服务器ip ///连接服务器，成功返回0，错误返回-1 if (connect(sock_cli, (struct sockaddr *)&amp;servaddr, sizeof(servaddr)) &lt; 0) { perror(&quot;connect&quot;); exit(1); } char sendbuf[BUFFER_SIZE]; char recvbuf[BUFFER_SIZE]; while (fgets(sendbuf, sizeof(sendbuf), stdin) != NULL) { send(sock_cli, sendbuf, strlen(sendbuf),0); ///发送 if(strcmp(sendbuf,&quot;exit\n&quot;)==0) break; recv(sock_cli, recvbuf, sizeof(recvbuf),0); ///接收 fputs(recvbuf, stdout); memset(sendbuf, 0, sizeof(sendbuf)); memset(recvbuf, 0, sizeof(recvbuf)); } close(sock_cli); return 0; } 服务端#include #include #include #include #include #include #include #include #include #include #define MYPORT 8887 #define QUEUE 20 #define BUFFER_SIZE 1024 int main() { ///定义sockfd int server_sockfd = socket(AF_INET,SOCK_STREAM, 0); ///定义sockaddr_in struct sockaddr_in server_sockaddr; server_sockaddr.sin_family = AF_INET; server_sockaddr.sin_port = htons(MYPORT); server_sockaddr.sin_addr.s_addr = htonl(INADDR_ANY); ///bind，成功返回0，出错返回-1 if(bind(server_sockfd,(struct sockaddr *)&amp;server_sockaddr,sizeof(server_sockaddr))==-1) { perror(&quot;bind&quot;); exit(1); } ///listen，成功返回0，出错返回-1 if(listen(server_sockfd,QUEUE) == -1) { perror(&quot;listen&quot;); exit(1); } ///客户端套接字 char buffer[BUFFER_SIZE]; struct sockaddr_in client_addr; socklen_t length = sizeof(client_addr); ///成功返回非负描述字，出错返回-1 int conn = accept(server_sockfd, (struct sockaddr*)&amp;client_addr, &amp;length); if(conn&lt;0) { perror(&quot;connect&quot;); exit(1); } while(1) { memset(buffer,0,sizeof(buffer)); int len = recv(conn, buffer, sizeof(buffer),0); if(strcmp(buffer,&quot;exit\n&quot;)==0) break; fputs(buffer, stdout); for(int i=0;i&lt;len;i++){ if(buffer[i]&gt;=97&amp;&amp;buffer[i]&lt;=122)buffer[i]-=32; } send(conn, buffer, len, 0); } close(conn); close(server_sockfd); return 0; } 运行截图tcp_client: tcp_server: UDP客户端#include #include #include #include #include #define SERVER_PORT 8888 #define BUFF_LEN 512 #define SERVER_IP &quot;172.0.5.182&quot; void udp_msg_sender(int fd, struct sockaddr* dst) { socklen_t len; char sendbuf[BUFF_LEN]; char recvbuf[BUFF_LEN]; struct sockaddr_in src; while(fgets(sendbuf,sizeof(sendbuf),stdin)!=NULL){ len=sizeof(*dst); sendto(fd,sendbuf,BUFF_LEN,0,dst,len); if(strcmp(sendbuf,&quot;exit\n&quot;)==0)break; recvfrom(fd,recvbuf,BUFF_LEN,0,(struct sockaddr*)&amp;src,&amp;len); fputs(recvbuf,stdout); memset(sendbuf,0,sizeof(sendbuf)); memset(recvbuf,0,sizeof(recvbuf)); } } /* client: socket--&gt;sendto--&gt;revcfrom--&gt;close */ int main(int argc, char* argv[]) { int client_fd; struct sockaddr_in ser_addr; client_fd = socket(AF_INET, SOCK_DGRAM, 0); if(client_fd &lt; 0) { printf(&quot;create socket fail!\n&quot;); return -1; } memset(&amp;ser_addr, 0, sizeof(ser_addr)); ser_addr.sin_family = AF_INET; //ser_addr.sin_addr.s_addr = inet_addr(SERVER_IP); ser_addr.sin_addr.s_addr = htonl(INADDR_ANY); //注意网络序转换 ser_addr.sin_port = htons(SERVER_PORT); //注意网络序转换 udp_msg_sender(client_fd, (struct sockaddr*)&amp;ser_addr); close(client_fd); return 0; } 服务端#include #include #include #include #include #define SERVER_PORT 8888 #define BUFF_LEN 1024 void handle_udp_msg(int fd) { char buf[BUFF_LEN]; //接收缓冲区，1024字节 socklen_t len; int count; struct sockaddr_in clent_addr; //clent_addr用于记录发送方的地址信息 while(1) { memset(buf, 0, BUFF_LEN); len = sizeof(clent_addr); count = recvfrom(fd, buf, BUFF_LEN, 0, (struct sockaddr*)&amp;clent_addr, &amp;len); //recvfrom是拥塞函数，没有数据就一直拥塞 if(count == -1) { printf(&quot;recieve data fail!\n&quot;); return; } if(strcmp(buf,&quot;exit\n&quot;)==0)break; fputs(buf,stdout); for(int i=0;i&lt;count;i++){ if(buf[i]&gt;=97&amp;&amp;buf[i]&lt;=122)buf[i]-=32; } sendto(fd, buf, BUFF_LEN, 0, (struct sockaddr*)&amp;clent_addr, len); //发送信息给client，注意使用了clent_addr结构体指针 } } /* server: socket--&gt;bind--&gt;recvfrom--&gt;sendto--&gt;close */ int main(int argc, char* argv[]) { int server_fd, ret; struct sockaddr_in ser_addr; server_fd = socket(AF_INET, SOCK_DGRAM, 0); //AF_INET:IPV4;SOCK_DGRAM:UDP if(server_fd &lt; 0) { printf(&quot;create socket fail!\n&quot;); return -1; } memset(&amp;ser_addr, 0, sizeof(ser_addr)); ser_addr.sin_family = AF_INET; ser_addr.sin_addr.s_addr = htonl(INADDR_ANY); //IP地址，需要进行网络序转换，INADDR_ANY：本地地址 ser_addr.sin_port = htons(SERVER_PORT); //端口号，需要网络序转换 ret = bind(server_fd, (struct sockaddr*)&amp;ser_addr, sizeof(ser_addr)); if(ret &lt; 0) { printf(&quot;socket bind fail!\n&quot;); return -1; } handle_udp_msg(server_fd); //处理接收到的数据 close(server_fd); return 0; } 运行截图udp_client udp_server 文件传输TCP客户端#include #include #include #include #include #include #include #include #include #include #define MAXLINE 1024 void usage(char *command) { printf(&quot;usage :%s ipaddr portnum filename\n&quot;, command); exit(0); } int main(int argc,char **argv) { struct sockaddr_in serv_addr; char buf[MAXLINE]; int sock_id; int read_len; int send_len; FILE *fp; int i_ret; if (argc != 4) { usage(argv[0]); } /* open the file to be transported commented by guoqingbo*/ if ((fp = fopen(argv[3],&quot;r&quot;)) == NULL) { perror(&quot;Open file failed\n&quot;); exit(0); } /* create the socket commented by guoqingbo*/ if ((sock_id = socket(AF_INET,SOCK_STREAM,0)) &lt; 0) { perror(&quot;Create socket failed\n&quot;); exit(0); } memset(&amp;serv_addr, 0, sizeof(serv_addr)); serv_addr.sin_family = AF_INET; serv_addr.sin_port = htons(atoi(argv[2])); inet_pton(AF_INET, argv[1], &amp;serv_addr.sin_addr); /* connect the server commented by guoqingbo*/ i_ret = connect(sock_id, (struct sockaddr *)&amp;serv_addr, sizeof(struct sockaddr)); if (-1 == i_ret) { printf(&quot;Connect socket failed\n&quot;); return -1; } /* transported the file commented by guoqingbo*/ bzero(buf, MAXLINE); while ((read_len = fread(buf, sizeof(char), MAXLINE, fp)) &gt;0 ) { send_len = send(sock_id, buf, read_len, 0); if ( send_len &lt; 0 ) { perror(&quot;Send file failed\n&quot;); exit(0); } bzero(buf, MAXLINE); } fclose(fp); close(sock_id); printf(&quot;Send Finish\n&quot;); return 0; } 服务端#include #include #include #include #include #include #include #include #include #define MAXLINE 1024 void usage(char *command) { printf(&quot;usage :%s portnum filename\n&quot;, command); exit(0); } int main(int argc,char **argv) { struct sockaddr_in serv_addr; struct sockaddr_in clie_addr; char buf[MAXLINE]; int sock_id; int link_id; int recv_len; int write_leng; int clie_addr_len; FILE *fp; if (argc != 3) { usage(argv[0]); } if ((fp = fopen(argv[2], &quot;w&quot;)) == NULL) { perror(&quot;Open file failed\n&quot;); exit(0); } if ((sock_id = socket(AF_INET, SOCK_STREAM, 0)) &lt; 0) { perror(&quot;Create socket failed\n&quot;); exit(0); } /*fill the server sockaddr_in struct commented by guoqingbo*/ memset(&amp;serv_addr, 0, sizeof(serv_addr)); serv_addr.sin_family = AF_INET; serv_addr.sin_port = htons(atoi(argv[1])); serv_addr.sin_addr.s_addr = htonl(INADDR_ANY); if (bind(sock_id, (struct sockaddr *)&amp;serv_addr, sizeof(serv_addr)) &lt; 0 ) { perror(&quot;Bind socket failed\n&quot;); exit(0); } if (-1 == listen(sock_id, 10)) { perror(&quot;Listen socket failed\n&quot;); exit(0); } /* server part commented by guoqingbo*/ while (1) { clie_addr_len = sizeof(clie_addr); link_id = accept(sock_id, (struct sockaddr *)&amp;clie_addr, &amp;clie_addr_len); if (-1 == link_id) { perror(&quot;Accept socket failed\n&quot;); exit(0); } bzero(buf, MAXLINE); while (recv_len = recv(link_id, buf, MAXLINE, 0)) { /* receiver data part commented by guoqingbo*/ if(recv_len &lt; 0) { printf(&quot;Recieve Data From Server Failed!\n&quot;); break; } printf(&quot;#&quot;); write_leng = fwrite(buf, sizeof(char), recv_len, fp); if (write_leng &lt; recv_len) { printf(&quot;Write file failed\n&quot;); break; } bzero(buf,MAXLINE); } printf(&quot;\nFinish Recieve\n&quot;); fclose(fp); close(link_id); } close(sock_id); return 0; } 截图tcp_file_client tcp_file_servier UDP客户端#include #include #include #include #include #include #include #include #include #include #define FINISH_FLAG &quot;FILE_TRANSPORT_FINISH&quot; #define MAXLINE 1024 void usage(char *command) { printf(&quot;usage :%s ipaddr portnum filename\n&quot;, command); exit(0); } int main(int argc,char **argv) { FILE *fp; struct sockaddr_in serv_addr; char buf[MAXLINE]; int sock_id; int read_len; int send_len; int serv_addr_len; int i_ret; int i; if (argc != 4) { usage(argv[0]); } /* open the file to be transported commanted by guoqingbo*/ if ((fp = fopen(argv[3],&quot;r&quot;)) == NULL) { perror(&quot;Open file failed\n&quot;); exit(0); } /* create the socket commanted by guoqingbo*/ if ((sock_id = socket(AF_INET, SOCK_DGRAM, 0)) &lt; 0) { perror(&quot;Create socket failed&quot;); exit(0); } memset(&amp;serv_addr,0,sizeof(serv_addr)); serv_addr.sin_family = AF_INET; serv_addr.sin_port = htons(atoi(argv[2])); inet_pton(AF_INET, argv[1], &amp;serv_addr.sin_addr); serv_addr_len = sizeof(serv_addr); /* connect the server commanted by guoqingbo*/ i_ret = connect(sock_id, (struct sockaddr *)&amp;serv_addr, sizeof(struct sockaddr)); if (-1 == i_ret) { perror(&quot;Connect socket failed!\n&quot;); exit(0); } /* transport the file commented by guoqingbo*/ bzero(buf, MAXLINE); while ( (read_len = fread(buf, sizeof(char), MAXLINE, fp)) &gt; 0 ) { send_len = send(sock_id, buf, read_len, 0); if ( send_len &lt; 0 ) { perror(&quot;Send data failed\n&quot;); exit(0); } bzero(buf, MAXLINE); } fclose(fp); /* send the end_flag commented by guoqingbo*/ bzero(buf, MAXLINE); strcpy(buf, FINISH_FLAG); buf[strlen(buf)] = &#39;\0&#39;; for (i = 1000; i&gt;0; i--) { send_len = send(sock_id, buf, strlen(buf)+1, 0); if ( send_len &lt; 0 ) { printf(&quot;Finish send the end string\n&quot;); break; } } close(sock_id); printf(&quot;Send finish\n&quot;); return 0; } 服务端#include #include #include #include #include #include #include #include #include #define FINISH_FLAG &quot;FILE_TRANSPORT_FINISH&quot; #define MAXLINE 1024 void usage(char *command) { printf(&quot;usage :%s portnum filename\n&quot;, command); exit(0); } int main(int argc,char **argv) { struct sockaddr_in serv_addr; struct sockaddr_in clie_addr; char buf[MAXLINE]; int sock_id; int recv_len; int clie_addr_len; FILE *fp; if (argc != 3) { usage(argv[0]); } /* Create the the file commented by guoqingbo*/ if ((fp = fopen(argv[2], &quot;w&quot;)) == NULL) { perror(&quot;Creat file failed&quot;); exit(0); } if ((sock_id = socket(AF_INET,SOCK_DGRAM,0)) &lt; 0) { perror(&quot;Create socket failed\n&quot;); exit(0); } /*fill the server sockaddr_in struct commented by guoqingbo*/ memset(&amp;serv_addr,0,sizeof(serv_addr)); serv_addr.sin_family = AF_INET; serv_addr.sin_port = htons(atoi(argv[1])); serv_addr.sin_addr.s_addr = htonl(INADDR_ANY); if (bind(sock_id,(struct sockaddr *)&amp;serv_addr,sizeof(serv_addr)) &lt; 0 ) { perror(&quot;Bind socket faild\n&quot;); exit(0); } /* server part commented by guoqingbo*/ clie_addr_len = sizeof(clie_addr); bzero(buf, MAXLINE); while (recv_len = recvfrom(sock_id, buf, MAXLINE, 0,(struct sockaddr *)&amp;clie_addr, &amp;clie_addr_len)) { if(recv_len &lt; 0) { printf(&quot;Recieve data from client failed!\n&quot;); break; } printf(&quot;#&quot;); if ( strstr(buf, FINISH_FLAG) != NULL ) { printf(&quot;\nFinish receiver finish_flag\n&quot;); break; } int write_length = fwrite(buf, sizeof(char), recv_len, fp); if (write_length &lt; recv_len) { printf(&quot;File write failed\n&quot;); break; } bzero(buf, MAXLINE); } printf(&quot;Finish recieve\n&quot;); fclose(fp); close(sock_id); return 0; } 截图udp_file_client udp_file_server]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
        <tag>作业</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux块设备的详解]]></title>
    <url>%2F2017%2F03%2F27%2Flinux%E5%9D%97%E8%AE%BE%E5%A4%87%E7%9A%84%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[本文讲解linux操作系统的块设备，linux快设备类型的根本区别在于它们是否可以被随机访问——换句话说就是，能否在访问设备时随意地从一个位置跳转到另一个位置。 linux块设备，字符设备字符设备还是块设备的定义属于操作系统的设备访问层，与实际物理设备的特性无必然联系。设备访问层下面是驱动程序，所以只要驱动程序提供的方式，都可以。也就是说驱动程序支持stream方式，那么就可以用这种方式访问，驱动程序如果还支持block方式，那么你想用哪种方式访问都可以，典型的比如硬盘式的裸设备，两种都支持。 块设备（blockdevice） 是一种具有一定结构的随机存取设备，对这种设备的读写是按块进行的，他使用缓冲区来存放暂时的数据，待条件成熟后，从缓存一次性写入设备或从设备中一次性读出放入到缓冲区，如磁盘和文件系统等 字符设备（Characterdevice）： 这是一个顺序的数据流设备，对这种设备的读写是按字符进行的，而且这些字符是连续地形成一个数据流。他不具备缓冲区，所以对这种设备的读写是实时的，如终端、磁带机等。 系统中能够随机（不需要按顺序）访问固定大小数据片（chunks）的设备被称作块设备，这些数据片就称作块。最常见的块设备是硬盘，除此以外，还有软盘驱动器、CD-ROM驱动器和闪存等等许多其他块设备。注意，它们都是以安装文件系统的方式使用的——这也是块设备一般的访问方式。另一种基本的设备类型是字符设备。字符设备按照字符流的方式被有序访问，像串口和键盘就都属于字符设备。如果一个硬件设备是以字符流的方式被访问的话，那就应该将它归于字符设备；反过来，如果一个设备是随机（无序的）访问的，那么它就属于块设备。 linux块设备这两种类型的根本区别在于它们是否可以被随机访问——换句话说就是，能否在访问设备时随意地从一个位置跳转到另一个位置。举个例子，键盘这种设备提供的就是一个数据流，当你敲入“fox”这个字符串时，键盘驱动程序会按照和输入完全相同的顺序返回这个由三个字符组成的数据流。如果让键盘驱动程序打乱顺序来读字符串，或读取其他字符，都是没有意义的。所以键盘就是一种典型的字符设备，它提供的就是用户从键盘输入的字符流。对键盘进行读操作会得到一个字符流，首先是“f”，然后是“o”，最后是“x”，最终是文件的结束(EOF)。当没人敲键盘时，字符流就是空的。硬盘设备的情况就不大一样了。硬盘设备的驱动可能要求读取磁盘上任意块的内容，然后又转去读取别的块的内容，而被读取的块在磁盘上位置不一定要连续，所以说硬盘可以被随机访问，而不是以流的方式被访问，显然它是一个块设备。 内核管理块设备要比管理字符设备细致得多，需要考虑的问题和完成的工作相比字符设备来说要复杂许多。这是因为字符设备仅仅需要控制一个位置—当前位置—而块设备访问的位置必须能够在介质的不同区间前后移动。所以事实上内核不必提供一个专门的子系统来管理字符设备，但是对块设备的管理却必须要有一个专门的提供服务的子系统。不仅仅是因为块设备的复杂性远远高于字符设备，更重要的原因是块设备对执行性能的要求很高；对硬盘每多一分利用都会对整个系统的性能带来提升，其效果要远远比键盘吞吐速度成倍的提高大得多。]]></content>
      <categories>
        <category>linux系统知识</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据重删论文1]]></title>
    <url>%2F2017%2F03%2F27%2F%E6%95%B0%E6%8D%AE%E9%87%8D%E5%88%A0%E8%AE%BA%E6%96%871%2F</url>
    <content type="text"><![CDATA[Dmdedup: Device Mapper Target for Data Deduplication概述dmdedup这个软件是一个适用于常规应用者和研究人员的,多功能实用性的主存数据重删平台.在块级别进行操作,对应用和系统都是有用的.因为大多数据重删研究,设计和完善了一个后端接口,方便研究人员,构建和评估元数据管理的方法.通过下面三个方式,完善了后端: RAM_TAB:内存中的哈希表 DISK_TAB:磁盘哈希表 基于B树的DISK_TAB:持续的写时拷贝的B树 主存重删与数据集备份相比带来的挑战有: 访问局部性不太明显； 延迟的限制更严格； 更少的副本是可用的（约2×与备份10×）； 和重复数据删除引擎必须与其他进程竞争CPU和RAM。 为了方便在主存储器中的重复数据删除技术的研究，我们开发了，这里提出了一个灵活的、完全可操作的主存储重复数据删除系统，Dmdedup，在Linux内核中实现。除了其吸引人的特性为普通用户，它可以作为实验的重复数据删除算法和研究主存储数据和工作负载的基础平台。 它和RAID , LVM 在同一层对linux内核块设备进行操作. 设计分类数据重删层面 应用层 文件系统层 实现方式: 1. 修改现有的文件系统,比如EXT3或者WAFL. 2. 在内核或者利用用户空间文件系统创建一个可折叠的文件系统. 3. 从零开始实现一个重复数据删除的文件系统,比如,EMC 数据域的文件系统. block level 缺点: 1. 它必须保持一个额外的映射（超出文件系统的)逻辑和物理块之间的映射； 2. 文件系统和应用程序有用的上下文丢失. 3. variable length chunking is more difficult at the block layer. 时效性DM:设备映射器Device Mapper 是 Linux2.6 内核中支持逻辑卷管理的通用设备映射机制，它为实现用于存储资源管理的块设备驱动提供了一个高度模块化的内核架构. Dmdedup的组成 数据重删的逻辑,块存储,计算hash值,协调其他部件. 一个hash表,用来索引hash值与块的位置. 逻辑块号到物理块号的映射. 空间管理器,在物理设备上索引空间,定位新的块,维护计数,回收没有引用的块. 块存储. 写需求分块索引Dmdedup软件里的hash值生成方法,它支持30多种哈希函数(内核的加密库),作者实验用的是128位的MD5 hash值.hash值不能太短,容易发生碰撞,不能太长,增加了元数据的大小.磁盘发生错误的概率是10^(-18)—10^(-15),128位的hash串,发生碰撞的概率低于磁盘发生错误的概率. 哈希索引和逻辑块号映射查询 利用hash索引物理块号PBN(new) 利用逻辑块号映射物理块号PBN(old) 元数据更新 垃圾回收垃圾回收,不是实时的,是一个离线的定时的回收. 读请求控制后端元数据API强制: 初始化 销毁 块的定位,查找,插入,删除,关联数的控制 可选: 垃圾回收 元数据同步写入 API类型 线性(linear):Dmdedup uses a linear store (from zero to the size of the Dmdedup device)for LBN mapping 稀疏型(sparse):and a sparse one for the hash index. INRAM 重删的元数据一直存在RAM上 允许我们自定义给多少CPU用于重删. 他能很快算出工作负载的重删率 在电容和电池的支持下可用于生产环境 用静态定位的哈希表用于键值存储,用一个数组用于线性存储. 线性映射数组的大小基于目标实例的大小. 用于离散存储的哈希表的大小基于数据设备的大小(预测最多可能有的不同数据块的数目). 用数组记录关联数 用数组定位新的块 DTB和INRAM用了相同的数据结构,但是是将数据保存在硬盘上(持久存储体).没有缓冲区的话,每一次操作都是一次IO,严重影响dmdedup的性能. 我们用了Linux的dm-bufio子系统. CBTLinux写时拷贝技术(copy-on-write) B树 设备大小设备逻辑大小可以改变 实验实验组设置 原生的设备 INRAM DTB CBT 元数据cache大小设置:0.3% 25% 50% 75% 100% 135% Dmdedup通过连续的和随机的读写来测试其性能. Micro-workloads三种工作负载: Unique,独一无二的数据:通过linux的/dev/urandom 设备产生的. All-duplicates,全是重复的:每个块4kb,重复146GB linux-kernel : 40个linux内核 两种类型: 大量的连续写(I/O SIZE: 640KB) 少量的随机写(I/O SIZE: 4KB) Unique连续写: 重删率是1,不包括元数据.这种情况下重删系统的性能是最差的,因为重删的工作还得做.INRAM的性能和原生设备的一样(这是在CPU和RAM足够快去做数据重删,没有任何明显的性能影响的情况下),CPU的使用率在65%. 元数据的更新确实是个瓶颈,4M大小的cache下,DTB的性能仅有原生设备的25%,cache大小在75%-100%之间,性能得到了很大的提升,因为100%的cache不需要元数据的读了,135%的cache下,元数据的写也避免了,所以DTB达到了INRAM的性能. 随机写:原生的设备实现了420IOPS,Dmdedup比原生的要好很多,670-11100IOPS,因为他使随机的写变得有序,连续的定位新的块是重删系统的一个一般的策略. All-duplicatesLinux KernelsTrace Replay Web Mail Homes]]></content>
      <categories>
        <category>数据重删</category>
      </categories>
      <tags>
        <tag>数据重删</tag>
        <tag>论文</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[要完成的任务]]></title>
    <url>%2F2017%2F03%2F24%2F%E8%A6%81%E5%AE%8C%E6%88%90%E7%9A%84%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[终极目标阿里,腾讯运维研发岗位 要完成的任务 shell精通 python精通 计算机网络,操作系统,数据结构与算法 常用服务器的搭建,配置,调优,监控 shellpython计算机网络网络编程 操作系统Unix环境高级编程 服务器的搭建,配置,调优运维软件工具虚拟化docker,openstack自动化运维:理念,编程]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>Diary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[原]C++文件操作]]></title>
    <url>%2F2017%2F03%2F15%2FC-%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[string getFileContext(const string&amp;amp; filename) { string str; str.clear(); char buf[1024]; char *p; p = buf; memset(buf, 0, 1024); ifstream in; in.open(filename); while ((*p = in.get()) != EOF) { p++; } cout &amp;lt;&amp;lt; &quot;Buf&quot; &amp;lt;&amp;lt; endl; puts(buf); str += buf; cout &amp;lt;&amp;lt; str &amp;lt;&amp;lt; endl; in.close(); return str; } 作者：qq_27803491 发表于2017/3/15 11:22:40 [原文链接](http://blog.csdn.net/qq_27803491/article/details/62217799) 阅读：13 评论：0 [查看评论](http://blog.csdn.net/qq_27803491/article/details/62217799#comments)]]></content>
  </entry>
  <entry>
    <title><![CDATA[[原]ubuntu16.04 安装shadowsocks,番羽土啬]]></title>
    <url>%2F2017%2F02%2F27%2Fubuntu16-04-%E5%AE%89%E8%A3%85shadowsocks-%E7%95%AA%E7%BE%BD%E5%9C%9F%E5%95%AC%2F</url>
    <content type="text"><![CDATA[安装步骤 安装shadowsocks-qt5 统一安装教程 ubuntu16.04安装,执行如下命令: sudo add-apt-repository ppa:hzwhuang/ss-qt5 sudo apt-get update sudo apt-get install shadowsocks-qt5` `完成之后,在图形界面下找到shadowsocks-qt5的图标启动,或者命令行运行:/usr/bin/ss-qt5 然后配置ss,connection--&amp;gt;add--&amp;gt;manually--&amp;gt;填写相关参数 ` 配置chrome浏览器下载chrome插件:SwitchyOmega2.3.21下载地址 ////分隔符///// SwitchyOmega最新版网址 安装该插件(不会安装,百度crx插件安装办法) 然后配置该插件,参考: 1. 设置代理地址 安装好插件会自动跳到设置选项，有提示你可以跳过。左边新建情景模式-选择代理服务器-比如命名为SS（叫什么无所谓）其他默认之后创建，之后在代理协议选择SOCKS5，地址为127.0.0.1,端口默认1080 。然后保存即应用选项。![1](https://aitanlu.com/wp-content/uploads/2016/04/shadowsocks-0.png)![2](https://aitanlu.com/wp-content/uploads/2016/04/shadowsocks-1.png) 设置自动切换 接着点击自动切换 ( Auto switch）上面的不用管，在按照规则列表匹配请求后面选择刚才新建的SS，默认情景模式选择直接连接。点击应用选项保存。再往下规则列表设置选择AutoProxy 然后将这个地址填进去，点击下面的立即更新情景模式，会有提示更新成功！ 图片中7填写的是: https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt1. 然后就可以成功打开 google.com 了![这里写图片描述](http://img.blog.csdn.net/20170227200806973?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjc4MDM0OTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast) 开机启动运行:`gnome-session-properties 打开这个,然后添加 如下填写后保存退出即可! 参考教程 ubuntu16.04下载安装shadowsocks+配置chrome的过程记录 linux-ubuntu使用shadowsocks客户端配置 ubuntu 使用图形化配置 shadowsocks -qt5 开机自动启动（配置开机启动） 作者：qq_27803491 发表于2017/2/27 20:11:34 [原文链接](http://blog.csdn.net/qq_27803491/article/details/58233565) 阅读：20 评论：0 [查看评论](http://blog.csdn.net/qq_27803491/article/details/58233565#comments)]]></content>
  </entry>
  <entry>
    <title><![CDATA[[原]C申请内存函数]]></title>
    <url>%2F2017%2F02%2F23%2FC%E7%94%B3%E8%AF%B7%E5%86%85%E5%AD%98%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[#include &amp;lt;iostream&amp;gt; using namespace std; //传值调用 void GetMemory( char **p ) { *p = (char *) malloc( 100 ); } //引用调用 void GetMemory_1(char *&amp;amp;p) { p = (char *) malloc (100); } int main() { char *str = NULL; char *str1 = NULL; GetMemory( &amp;amp;str ); GetMemory_1( str1 ); strcpy( str, &quot;hello world&quot; ); strcpy( str1, &quot;hello world1&quot; ); cout&amp;lt;&amp;lt;str&amp;lt;&amp;lt;endl; cout&amp;lt;&amp;lt;str1&amp;lt;&amp;lt;endl; free(str); free(str1); return 0; } 作者：qq_27803491 发表于2017/2/23 18:04:15 [原文链接](http://blog.csdn.net/qq_27803491/article/details/56677396) 阅读：20 评论：0 [查看评论](http://blog.csdn.net/qq_27803491/article/details/56677396#comments)]]></content>
  </entry>
  <entry>
    <title><![CDATA[[原]markdown 语法]]></title>
    <url>%2F2017%2F02%2F08%2Fmarkdown-%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[欢迎使用Markdown编辑器写博客本Markdown编辑器使用[StackEdit][6]修改而来，用它写博客，将会带来全新的体验哦： Markdown和扩展Markdown简洁的语法 代码块高亮 图片链接和图片上传 LaTex数学公式 UML序列图和流程图 离线写博客 导入导出Markdown文件 丰富的快捷键 快捷键 加粗 Ctrl + B 斜体 Ctrl + I 引用 Ctrl + Q 插入链接 Ctrl + L 插入代码 Ctrl + K 插入图片 Ctrl + G 提升标题 Ctrl + H 有序列表 Ctrl + O 无序列表 Ctrl + U 横线 Ctrl + R 撤销 Ctrl + Z 重做 Ctrl + Y Markdown及扩展 Markdown 是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档，然后转换成格式丰富的HTML页面。 —— [ 维基百科 ] 使用简单的符号标识不同的标题，将某些文字标记为粗体或者斜体，创建一个链接等，详细语法参考帮助？。 本编辑器支持 Markdown Extra , 扩展了很多好用的功能。具体请参考Github. 表格Markdown Extra 表格语法： 项目 价格 Computer $1600 Phone $12 Pipe $1 可以使用冒号来定义对齐方式： 项目 价格 数量 Computer 1600 元 5 Phone 12 元 12 Pipe 1 元 234 定义列表Markdown Extra 定义列表语法：项目１项目２定义 A 定义 B 项目３定义 C 定义 D 定义D内容 代码块代码块语法遵循标准markdown代码，例如： @requires_authorization def somefunc(param1=&#39;&#39;, param2=0): &#39;&#39;&#39;A docstring&#39;&#39;&#39; if param1 &amp;gt; param2: # interesting print &#39;Greater&#39; return (param2 - param1 + 1) or None class SomeClass: pass &amp;gt;&amp;gt;&amp;gt; message = &#39;&#39;&#39;interpreter ... prompt&#39;&#39;&#39; 脚注生成一个脚注1. 欢迎使用Markdown编辑器写博客 * [快捷键](#快捷键) Markdown及扩展 * [表格](#表格) 定义列表 代码块 脚注 数学公式 UML 图 离线写博客 浏览器兼容 数学公式使用MathJax渲染LaTex 数学公式，详见math.stackexchange.com. 行内公式，数学公式为：Γ(n)=(n−1)!∀n∈N\Gamma(n) = (n-1)!\quad\forall n\in\mathbb N。 块级公式： x=−b±b2−4ac−−−−−−−√2a x = \dfrac{-b \pm \sqrt{b^2 - 4ac}}{2a} 更多LaTex语法请参考 这儿. UML 图:可以渲染序列图： Created with Raphaël 2.1.0张三张三李四李四嘿，小四儿, 写博客了没?李四愣了一下，说：忙得吐血，哪有时间写。 或者流程图： Created with Raphaël 2.1.0开始我的操作确认？结束yesno 关于 序列图 语法，参考 这儿, 关于 流程图 语法，参考 这儿. 离线写博客即使用户在没有网络的情况下，也可以通过本编辑器离线写博客（直接在曾经使用过的浏览器中输入write.blog.csdn.net/mdeditor即可。Markdown编辑器使用浏览器离线存储将内容保存在本地。 用户写博客的过程中，内容实时保存在浏览器缓存中，在用户关闭浏览器或者其它异常情况下，内容不会丢失。用户再次打开浏览器时，会显示上次用户正在编辑的没有发表的内容。 博客发表后，本地缓存将被删除。 用户可以选择 把正在写的博客保存到服务器草稿箱，即使换浏览器或者清除缓存，内容也不会丢失。 注意：虽然浏览器存储大部分时候都比较可靠，但为了您的数据安全，在联网后，请务必及时发表或者保存到服务器草稿箱。 浏览器兼容 目前，本编辑器对Chrome浏览器支持最为完整。建议大家使用较新版本的Chrome。 IE９以下不支持 IE９，１０，１１存在以下问题 1. 不支持离线功能 IE9不支持文件导入导出 IE10不支持拖拽文件导入 这里是 脚注 的 内容. 目录 用 [TOC]来生成目录：[6]: https://github.com/benweet/stackedit ↩ 作者：qq_27803491 发表于2017/2/8 22:19:58 [原文链接](http://blog.csdn.net/qq_27803491/article/details/54933885) 阅读：19 评论：0 [查看评论](http://blog.csdn.net/qq_27803491/article/details/54933885#comments)]]></content>
  </entry>
  <entry>
    <title><![CDATA[[原]大三寒假(2017.1.18)]]></title>
    <url>%2F2017%2F01%2F18%2F%E5%A4%A7%E4%B8%89%E5%AF%92%E5%81%87-2017-1-18%2F</url>
    <content type="text"><![CDATA[计划 shell脚本精通,linux命令行与shell脚本编程大全,linux shell脚本攻略,awk&amp;sed,ABS(1h/day) linux环境编程(15*4h=60h) docker(10h) 高性能linux服务器构建实战(14*4=56h) 英语六级(0.5h/day) 每日编程(1h/day) CCNA考试认证(1h/day) 考驾照,练车 3.5*30=105+60+10+56=231+60=291h 每天10h,吃饭2h,睡觉10h,加油,得良!!! 作者：qq_27803491 发表于2017/1/18 13:59:53 [原文链接](http://blog.csdn.net/qq_27803491/article/details/54600137) 阅读：17 评论：0 [查看评论](http://blog.csdn.net/qq_27803491/article/details/54600137#comments)]]></content>
  </entry>
  <entry>
    <title><![CDATA[[原]高斯消元（混合颜料）]]></title>
    <url>%2F2017%2F01%2F05%2F%E9%AB%98%E6%96%AF%E6%B6%88%E5%85%83%EF%BC%88%E6%B7%B7%E5%90%88%E9%A2%9C%E6%96%99%EF%BC%89%2F</url>
    <content type="text"><![CDATA[题目（网易2017内推编程题（二）的第一题）你就是一个画家！你现在想绘制一幅画，但是你现在没有足够颜色的颜料。为了让问题简单，我们用正整数表示不同颜色的颜料。你知道这幅画需要的n种颜色的颜料，你现在可以去商店购买一些颜料，但是商店不能保证能供应所有颜色的颜料，所以你需要自己混合一些颜料。混合两种不一样的颜色A和颜色B颜料可以产生(A XOR B)这种颜色的颜料(新产生的颜料也可以用作继续混合产生新的颜色,XOR表示异或操作)。本着勤俭节约的精神，你想购买更少的颜料就满足要求，所以兼职程序员的你需要编程来计算出最少需要购买几种颜色的颜料？ 输入描述: 第一行为绘制这幅画需要的颜色种数n (1 ≤ n ≤ 50) 第二行为n个数xi(1 ≤ xi ≤ 1,000,000,000)，表示需要的各种颜料. 输出描述: 输出最少需要在商店购买的颜料颜色种数，注意可能购买的颜色不一定会使用在画中，只是为了产生新的颜色。 输入例子: 3 1 7 3 输出例子: 3 题解该题是利用行列式解决异或问题，通过求行列式的秩来求最少需要多少种颜色，没接触过这种题目的同学应该很难将它们联系到一块，不过仔细想想： 化简行列式的过程与本题求解的过程，这道题，你上来如果暴力的话，复杂度O(n^3),而且可能会涉及到重复的计算。利用行列式化简（高斯消元）的方法，就是利用到了： 7：0111 3：0011 2：0010 1：0001 这样的话，7是不可能被异或得出来的，因为他的最高位为1，其他数的最高位为0，而行列式化简，化简成上三角行列式也相同的过程。 本题中只涉及到二进制的异或化简，所以利用高斯消元法较为简单。 ` ## 代码 ` #include&amp;lt;iostream&amp;gt; #include&amp;lt;cstdio&amp;gt; #include&amp;lt;cstring&amp;gt; #include&amp;lt;algorithm&amp;gt; #include&amp;lt;vector&amp;gt; using namespace std; int getbit(int x) { int cnt=0; while(x){ x&amp;gt;&amp;gt;=1; cnt++; } return cnt; } bool cmp(const int&amp;amp; a,const int&amp;amp; b) { return a&amp;gt;b; } int main() { int n; while(scanf(&quot;%d&quot;,&amp;amp;n)!=EOF){ vector&amp;lt;int&amp;gt; v; int ans=0; for(int i=0;i&amp;lt;n;i++){ int a; scanf(&quot;%d&quot;,&amp;amp;a); v.push_back(a); } while(v.size()&amp;gt;=1){ sort(v.begin(),v.end(),cmp); if(v[0]==0){ ans+=v.size(); break; } vector&amp;lt;int&amp;gt;::iterator it=v.begin(); int fnb=getbit(v[0]); for(++it;it!=v.end();it++){ if(getbit(*it)==fnb){ (*it)=(*it)^v[0]; } else break; } v.erase(v.begin()); } cout&amp;lt;&amp;lt;n-ans&amp;lt;&amp;lt;endl; } return 0; } /* 15 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 */ 收获 熟悉了高斯消元法求解化简行列式，高斯（约当）消元法：就是每次把要消去位上含有最大的元素的行调到最高的地方。 了解了异或运算与行列式化简的联系。 作者：qq_27803491 发表于2017/1/5 12:33:55 [原文链接](http://blog.csdn.net/qq_27803491/article/details/54091966) 阅读：31 评论：0 [查看评论](http://blog.csdn.net/qq_27803491/article/details/54091966#comments)]]></content>
  </entry>
  <entry>
    <title><![CDATA[[原]googleSRE运维——减少琐事]]></title>
    <url>%2F2016%2F12%2F29%2FgoogleSRE%E8%BF%90%E7%BB%B4%E2%80%94%E2%80%94%E5%87%8F%E5%B0%91%E7%90%90%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[琐事的属性 手动性的 重复性的 可以被自动化的 战术性的（不是太懂，原文是这样的）：琐事是突然出现的、对应式的工作，而非策略驱动和主动安排的。处理紧急警报是琐事。我们可能永远都无法完全消除这种类型的工作，但我们必须继续努力减少它。 没有持久价值 与服务同步线性增长 琐事过多的危害 职业停滞 士气低落 造成误解 进展缓慢 开创先例：如果SRE过于愿意承担琐事，研发同事就更倾向于加入更多的琐事，有时候甚至将本来研发团队应承担的运维工作转给SRE来承担。其他团队也会开始指望SRE来接受这样的工作，这显然是不好的。 促进摩擦产生 违反承诺 宗旨 通过工程工作（符合长期战略的会对你的服务进行长久性的改善的工作）消除一点点的琐事，就可以持续行地整顿服务。我们可以将更多的力量投入到扩大服务规模的工程工作上去，或者是进行下一代的服务的架构设计，又或者是建立一套跨SRE使用的工具链。 多做创新，少干琐事。 对生或中琐事的思考（待续，过一个有条理的生活，因为对我来说，有条理就是自信、充实）生活中的琐事 刷空间 刷朋友圈 生活中的不可避免的事情 日常洗漱 睡觉 吃饭 学习 工作 生活中有意义的能够使自己变得优秀的事情 看书 跑步 看一些有意义的电影 拍照发现生活中细小的美 作者：qq_27803491 发表于2016/12/29 17:37:17 [原文链接](http://blog.csdn.net/qq_27803491/article/details/53930796) 阅读：68 评论：0 [查看评论](http://blog.csdn.net/qq_27803491/article/details/53930796#comments)]]></content>
  </entry>
  <entry>
    <title><![CDATA[[原]运维之下 笔记 三（运维平台）]]></title>
    <url>%2F2016%2F12%2F22%2F%E8%BF%90%E7%BB%B4%E4%B9%8B%E4%B8%8B-%E7%AC%94%E8%AE%B0-%E4%B8%89%EF%BC%88%E8%BF%90%E7%BB%B4%E5%B9%B3%E5%8F%B0%EF%BC%89%2F</url>
    <content type="text"><![CDATA[两大运维平台： 1\. 资产管理平台 负责记录基础的物理信息； 主要用户是系统运维工程师，他们关注设备的出入、维修等管理工作，交付资源给上层业务； 2\. 服务管理平台 记录业务运维所需要的逻辑信息，提供一个基于树状结构（服务树）和权限绑定的管理模式。 用户主要是应用运维工程师、研发工程师和测试工程师，他们关注服务运行的相关数据。 3. 资产管理平台负责底层的物理信息管理，提供API供服务管理平台查询和同步。服务管理平台通过API获取新交付的服务器列表及其详细信息，将它们归属到服务树产品线节点，分配对应的权限。应用运维工程师在服务树上领取空闲服务器，进行一系列的环境初始化、服务部署、监控添加等工作。应用运维工程师在服务管理平台提交报修申请、服务器归还等操作，通过API将信息推送到资产管理平台，由系统运维工程师进行相应处理。 作者：qq_27803491 发表于2016/12/22 17:09:37 [原文链接](http://blog.csdn.net/qq_27803491/article/details/53817172) 阅读：119 评论：0 [查看评论](http://blog.csdn.net/qq_27803491/article/details/53817172#comments)]]></content>
  </entry>
  <entry>
    <title><![CDATA[[原]python3.4 验证码识别]]></title>
    <url>%2F2016%2F12%2F20%2Fpython3-4-%E9%AA%8C%E8%AF%81%E7%A0%81%E8%AF%86%E5%88%AB%2F</url>
    <content type="text"><![CDATA[需要安装 pillow、pytesseract、tesseract-ocr import pytesseract from PIL import Image image = Image.open(&#39;C:/Users/Dear/Pictures/code_img/2.jpg&#39;) vcode = pytesseract.image_to_string(image) print (vcode) 作者：qq_27803491 发表于2016/12/20 22:40:29 [原文链接](http://blog.csdn.net/qq_27803491/article/details/53770867) 阅读：147 评论：0 [查看评论](http://blog.csdn.net/qq_27803491/article/details/53770867#comments)]]></content>
  </entry>
  <entry>
    <title><![CDATA[[原]python3.4 信息门户登录请求]]></title>
    <url>%2F2016%2F12%2F20%2Fpython3-4-%E4%BF%A1%E6%81%AF%E9%97%A8%E6%88%B7%E7%99%BB%E5%BD%95%E8%AF%B7%E6%B1%82%2F</url>
    <content type="text"><![CDATA[python post请求import requests url = &#39;http://xx.xxxx.edu.cn/userPasswordValidate.portal&#39; user=20160001 parms={ &#39;Login.Token1&#39;: user, &#39;Login.Token2&#39;: &#39;123456&#39;, &#39;captchaField&#39;: &#39;485c&#39; } headers = { &#39;Connection&#39;:&#39;keep-alive&#39;, &#39;Content-Length&#39;: &#39;174&#39;, &#39;Cache-Control&#39;: &#39;max-age=0&#39;, &#39;Origin&#39;: &#39;http://xx.xxxx.edu.cn&#39;, &#39;Upgrade-Insecure-Requests&#39;: &#39;1&#39;, &#39;User-Agent&#39;: &#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36&#39;, &#39;Content-Type&#39;: &#39;application/x-www-form-urlencoded&#39;, &#39;Accept&#39;: &#39;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8&#39;, &#39;Referer&#39;: &#39;http://xx.xxxx.edu.cn/&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Accept-Language&#39;: &#39;zh-CN,zh;q=0.8&#39;, &#39;Cookie&#39;: &#39;JSESSIONID=0000O1UhImqKAdSpqQwJ6Nz9Tow:17kv91lok&#39; } resp = requests.post(url, data=parms, headers=headers) text = resp.text print(text) 作者：qq_27803491 发表于2016/12/20 22:31:02 [原文链接](http://blog.csdn.net/qq_27803491/article/details/53770779) 阅读：51 评论：0 [查看评论](http://blog.csdn.net/qq_27803491/article/details/53770779#comments)]]></content>
  </entry>
  <entry>
    <title><![CDATA[[原]python字符串方法基础]]></title>
    <url>%2F2016%2F12%2F20%2Fpython%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%96%B9%E6%B3%95%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[#FIND mystr=&#39;xxxSPAMxxx&#39; site=mystr.find(&#39;SPAM&#39;) print(site) #replace mystr=&#39;xxaaxxaa&#39; print(mystr.replace(&#39;aa&#39;,&#39;SPAM&#39;)) #in mystr=&quot;xxxspamxxx&quot; print(&#39;spam&#39; in mystr) #strip mystr=&#39;\t Ni\n&#39; print(mystr) print(mystr.strip()) print(mystr.rstrip()) print(mystr.lstrip()) #lower mystr=&#39;SHRUBBERY&#39; print(mystr.lower()) #isalpha print(mystr.isalpha()) #isdigit print(mystr.isdigit()) #split mystr=&#39;aaa,bbb,ccc&#39; print(mystr.split(&#39;,&#39;)) #split 默认分隔符为泛空格符 mystr=&#39;a b\nc\n d &#39; print(mystr.split()) #join delim=&#39;ni&#39; print(delim.join([&#39;aaa&#39;,&#39;bbb&#39;,&#39;ccc&#39;])) print(&#39; &#39;.join([&#39;aaa&#39;,&#39;bbb&#39;,&#39;ccc&#39;])) #list chars=list(&#39;lorreta&#39;) print(chars) chars.append(&#39;!&#39;) print(&#39;&#39;.join(chars)) #整形和字符串类型转换 int(&quot;42&quot;) eval(&quot;42&quot;) str(42) repr(42) print(&quot;%d&quot; %42) print(&#39;{:d}&#39;.format(42)) 作者：qq_27803491 发表于2016/12/20 12:45:17 [原文链接](http://blog.csdn.net/qq_27803491/article/details/53761679) 阅读：34 评论：0 [查看评论](http://blog.csdn.net/qq_27803491/article/details/53761679#comments)]]></content>
  </entry>
  <entry>
    <title><![CDATA[[原]Linux文件压缩及归档]]></title>
    <url>%2F2016%2F11%2F19%2FLinux%E6%96%87%E4%BB%B6%E5%8E%8B%E7%BC%A9%E5%8F%8A%E5%BD%92%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[压缩 解压缩命令压缩格式:gz,bz2,xz,zip, 压缩算法不同,压缩比也会不同; ` ## 压缩命令 `*不支持压缩目录* ` ### 早期:compress:FILENAME.Z ` umcompress ` ### gzip: .gz ` gzip /PATH/TO/SOURCEFILE 压缩完成后会删除原文件 -d:解压 -#:(1-9)指定压缩比,默认为6; gunzip: gunzip /PATH/TO/SOMEFILE.gz :解压完成后会删除原文件 zcat /PATH/TO/SOMEFILE.gz 表示在不解压的情况下,查看文本文件的内容 ` ### bzip2: .bz2 ` 比gzip有着更强大的压缩比的压缩工具,使用格式类似 -d: -#:(1-9) -k:压缩时保留原文件 bunzip2:解压 bzcat:同zcat ` ### xz: .xz ` 压缩比更大,用法同bzip2 unxz:解压 xzdec,解压.xz压缩文件, xzcat: ` ### zip:(压缩比较小)(归档而且压缩) ` $:zip FILENAME.zip file1 file2 ... : 压缩,且不删除原文件 unzip: unzip FILENAME.zip ` ## archive:归档,归档本身并不意味着压缩 ### tar:(归档工具) ` -c :创建归档文件 -f FILE.tar : 操作的归档文件 -x :展开归档 --xattrs:归档时保留其扩展属性信息 $:tar -cf FILE.tar file1 file2 ... (归档命令) $:tar -xf FILE.tar (展开归档命令) $:tar -tf FILE.tar (不展开文件,查看归档了哪些文件) -zcf:归档并调用gzip压缩 -zxf:调用gzip解压并展开压缩文件(解压时,z选项可省略,下面的解压,j,J都可省略) -jcf:调用bzip2 -jxf: -Jcf:调用xz -Jxf: ` ### cpio:归档工具 ## 补充 ### read命令 `read: 后面加上要输入的变量名 -p:打印内容,并输入 $:read -p &quot;打印的内容&quot; a b ... ` ### echo `echo: -n:不换行 ` ### 压缩文件的小脚本 `#!/bin/bash read -p &quot;Please input files&#39; name,which you want to compress:&quot; FILENAME read -p &quot;Please input Destination:&quot; DEST read -p &quot;Please input the compress type :&quot; TYPE case $TYPE in gzip) tar -zcf ${DEST}.tar.gz ${FILENAME} ;; bzip2) tar -jcf ${DEST}.tar.bz2 ${FILENAME} ;; xz) tar -Jcf ${DEST}.tar.xz ${FILENAME} ;; *) echo &quot;Unknown TYPE!&quot; exit 9 ;; esac 作者：qq_27803491 发表于2016/11/19 17:17:50 [原文链接](http://blog.csdn.net/qq_27803491/article/details/53232202) 阅读：132 评论：0 [查看评论](http://blog.csdn.net/qq_27803491/article/details/53232202#comments)]]></content>
  </entry>
  <entry>
    <title><![CDATA[[原]2016.11.16周三]]></title>
    <url>%2F2016%2F11%2F16%2F2016-11-16%E5%91%A8%E4%B8%89%2F</url>
    <content type="text"><![CDATA[计划距离找工作还有32周,实际学习时间还有26周 六级考试(这次说什么也要过了六级,没时间了,come on!得良) 每天百词斩完成任务 闲时听英语听力 两天背一篇作文,一篇听力 一天两篇阅读 工作准备07_01_vim编辑器详解.rar 07_02_bash脚本编程之六 使用脚本选项及组合条件测试.rar 07_03_Linux文件查找详解.rar 07_04_特殊权限SUID等详解.rar 08_01_facl及用户及Linux终端.rar 08_02_bash脚本编程之七 case语句及脚本选项进阶.rar 08_03_磁盘及文件系统管理详解之一.rar 08_04_磁盘及文件系统管理详解之二.rar 09_01_磁盘及文件系统管理详解之三.rar 09_02_磁盘及文件系统管理详解之五.rar 09_03_磁盘及文件系统管理详解之五.rar 09_04_Linux压缩及归档.rar 10_01_Raid及mdadm命令之一.rar 10_02_Raid及mdadm命令之二.rar 10_03_LVM之一.rar 10_04_LVM之二.rar 10_05_脚本编程之八 脚本完成磁盘分区格式化.rar 11_01_Linux网络配置之一.rar 11_02_Linux网络配置之二 IP报文.rar 11_03_Linux网络配置之三 TCP报文.rar 11_04_Linux网络配置之四 ifconfig及ip命令详解.rar 12_01_Linux软件管理之一 rpm.rar 12_02_Linux软件管理之二 rpm.rar 12_03_Linux软件管理之三 yum.rar 12_04_Linux软件管理之四 yum.rar 13_01_bash脚本编程之九 while循环.rar 13_02_bash脚本编程之十 函数.rar 13_03_Linux进程管理之一.rar 13_04_Linux进程管理之二.rar 14_01_Linux系统启动流程详解之一 运行级别及grub.rar 14_02_Linux系统启动流程之二 内核及init.rar 14_03_bash脚本编程之十一(Linux启动流程之三) SysV服务脚本.rar 14_04_Linux内核编译及系统裁减之一.rar 15_01_bash脚本编程之十二(Linux系统裁减之二) 系统函数库.rar 15_02_bash脚本编程之十三(Linux系统裁减之三) 系统函数库.rar 15_03_Linux系统裁减之四 自定义内核及busybox完成系统定制.rar 16_01_bash脚本编程之十四 信号捕捉及系统管理之任务计划.rar 16_02_Linux系统裁减之五.rar 16_03_Linux日志系统syslog.rar 16_04_Linux系统裁减之六 为系统添加ssh服务.rar 打卡总结我们离理想中的自己越来越远,很大程度上是因为我们一点点的辜负自己. 六级没有考过,任务没有完成,有些东西是靠积累得来的,不要被各种事情扰乱了生活,要在各种事情之间生活的游刃有余. 作者：qq_27803491 发表于2016/11/16 18:08:45 [原文链接](http://blog.csdn.net/qq_27803491/article/details/53189469) 阅读：70 评论：0 [查看评论](http://blog.csdn.net/qq_27803491/article/details/53189469#comments)]]></content>
  </entry>
  <entry>
    <title><![CDATA[[原]邮件服务器]]></title>
    <url>%2F2016%2F11%2F15%2F%E9%82%AE%E4%BB%B6%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[Mail Server SMTP(监听tcp25号端口)：发邮件 ESMTP POP3：收邮件 IMAP4 UUCP:Unix主机复制文件的协议 C/S smtpd,smtp MUA：邮件用户代理， Outlook，Foxmail Thundbird evolution mutt MTA:邮件传输代理，smtp服务器，sendmail，uucp， qmail, postfix:模块化设计，安全，与sendmail兼容性好，投递效率 exim： exchange：（windows，异步消息协作平台） MDA procmail： maildrop： MRA：邮件取回代理（pop3，IMAP4） cyrus-imap dovecot SASL：简单认证安全层只是一个框架，需要依靠控件来完成认证cyrus-saslcourier-authlib Webmail: Openwebmail（perl） Squirrelmail （php） Extmail（Extman） LDAP:Lightweight dirctory Access protocol:轻量级目录访问协议:读取速度快，写入速度慢（读快mysql一个数量级，写慢mysql一个数量级） mysql： 虚拟用户：仅用于访问某服务的数字表示 用户：字符串，凭证 搭建 Postfix+SASL(courier-authlib)+Mysql Dovecot+MySQL webmail：Extmail+Extman+httpd Postfix配置文件：模块化： master：/etc/postfix/master.cf mail：/etc/postfix/main.cf postconf：配置postfix-d:显示默认的配置-n:修改了的配置-m:显示支持的查找表类型-A:显示支持的sasl客户端插件类型-e:PARMATER=VALUE :更改某参数配置信息，并保存到main.cf文件中 作者：qq_27803491 发表于2016/11/15 21:38:12 [原文链接](http://blog.csdn.net/qq_27803491/article/details/53177971) 阅读：64 评论：0 [查看评论](http://blog.csdn.net/qq_27803491/article/details/53177971#comments)]]></content>
  </entry>
  <entry>
    <title><![CDATA[[原]poj3169（差分约束系统）]]></title>
    <url>%2F2016%2F11%2F08%2Fpoj3169%EF%BC%88%E5%B7%AE%E5%88%86%E7%BA%A6%E6%9D%9F%E7%B3%BB%E7%BB%9F%EF%BC%89%2F</url>
    <content type="text"><![CDATA[题目 网址：http://poj.org/problem?id=3169 大概题意：有N个点，其中有ml个限制条件：点a，点b，的最长距离为d，有md个限制条件，点a,点b，的最短距离为d；点按序号顺序排，求第一个点到最后一个点的最长距离。 解题思路：差分约束，其实我也不太清楚什么是差分约束，大概就是将各种限制条件，逐个加入，先假设N个点间的距离都为无穷大，然后，按下列顺序，（循环）N（N，ml，md），依次加入限制条件，就可以了，加入第一种限制时，点b的原距离与a点距离加上d，比较，取最小值为b点的最新距离,,min(b(原)，a+d)。加入第二种限制时，已知b求a，min（a（原），b-d）; 代码#include&amp;lt;iostream&amp;gt; #include&amp;lt;cstdio&amp;gt; #include&amp;lt;string&amp;gt; #include&amp;lt;cstring&amp;gt; #include&amp;lt;cmath&amp;gt; #include&amp;lt;algorithm&amp;gt; #define INF 0x3f3f3f3f using namespace std; int d[1010]; struct MLD{ int a,b,d; }ML[10010]; struct MDD{ int a,b,d; }MD[10010]; int main() { memset(d,INF,sizeof(d)); memset(ML,0,sizeof(ML)); memset(MD,0,sizeof(MD)); int n,ml,md; scanf(&quot;%d%d%d&quot;,&amp;amp;n,&amp;amp;ml,&amp;amp;md); d[0]=0; for(int i=0;i&amp;lt;ml;i++){ scanf(&quot;%d%d%d&quot;,&amp;amp;ML[i].a,&amp;amp;ML[i].b,&amp;amp;ML[i].d); } for(int i=0;i&amp;lt;md;i++){ scanf(&quot;%d%d%d&quot;,&amp;amp;MD[i].a,&amp;amp;MD[i].b,&amp;amp;MD[i].d); } for(int i=0;i&amp;lt;n;i++){ for(int j=0;j&amp;lt;n;j++){ if(d[j+1]&amp;lt;INF)d[j]=min(d[j],d[j+1]); } for(int j=0;j&amp;lt;ml;j++){ if(d[ML[j].a-1]&amp;lt;INF){ d[ML[j].b-1]=min(d[ML[j].a-1]+ML[j].d,d[ML[j].b-1]); } } for(int j=0;j&amp;lt;md;j++){ if(d[MD[j].b-1]&amp;lt;INF){ d[MD[j].a-1]=min(d[MD[j].b-1]-MD[j].d,d[MD[j].a-1]); } } } if(d[0]&amp;lt;0)printf(&quot;-1\n&quot;); else if(d[n-1]==INF)printf(&quot;-2\n&quot;); else { printf(&quot;%d\n&quot;,d[n-1]); } return 0; } 作者：qq_27803491 发表于2016/11/8 12:24:18 [原文链接](http://blog.csdn.net/qq_27803491/article/details/53080973) 阅读：61 评论：0 [查看评论](http://blog.csdn.net/qq_27803491/article/details/53080973#comments)]]></content>
  </entry>
  <entry>
    <title><![CDATA[[原]细节（水）题codeforce#378C]]></title>
    <url>%2F2016%2F11%2F04%2F%E7%BB%86%E8%8A%82%EF%BC%88%E6%B0%B4%EF%BC%89%E9%A2%98codeforce-378C%2F</url>
    <content type="text"><![CDATA[题目网址http://codeforces.com/contest/733/problem/C 大概题意给你N个数，然后再给你经过合并操作后的K个数，求中间合并操作？ AC代码#define _CRT_SECURE_NO_WARNINGS #include &amp;lt;iostream&amp;gt; #include &amp;lt;cstdio&amp;gt; #include &amp;lt;cstring&amp;gt; #include &amp;lt;algorithm&amp;gt; #include &amp;lt;stack&amp;gt; #include &amp;lt;string&amp;gt; #include &amp;lt;set&amp;gt; #include &amp;lt;cmath&amp;gt; #include &amp;lt;map&amp;gt; #include &amp;lt;queue&amp;gt; #include &amp;lt;sstream&amp;gt; #include &amp;lt;vector&amp;gt; #include &amp;lt;iomanip&amp;gt; #define m0(a) memset(a,0,sizeof(a)) #define mm(a) memset(a,0x3f,sizeof(a)) #define m_1(a) memset(a,-1,sizeof(a)) #define f(i,a,b) for(i = a;i&amp;lt;=b;i++) #define fi(i,a,b) for(i = a;i&amp;gt;=b;i--) #define lowbit(a) ((a)&amp;amp;(-a)) #define FFR freopen(&quot;data.in&quot;,&quot;r&quot;,stdin) #define FFW freopen(&quot;data.out&quot;,&quot;w&quot;,stdout) #define INF 0x3f3f3f3f #define DEBUG printf typedef long long ll; typedef long double ld; const ld PI = acos(-1.0); using namespace std; #define SIZE 550 int a[SIZE]; int b[SIZE]; struct Chuan{ int c_start; int c_end; int c_max; }; struct Print{ int num; char dire; }; vector&amp;lt;Chuan&amp;gt; chuan; queue&amp;lt;Print&amp;gt; print; int main() { int n,k; scanf(&quot;%d&quot;,&amp;amp;n); int i; f(i,1,n){ scanf(&quot;%d&quot;,&amp;amp;a[i]); } scanf(&quot;%d&quot;,&amp;amp;k); int site=1; bool flag=0; f(i,1,k){ scanf(&quot;%d&quot;,&amp;amp;b[i]); if(flag)continue; ll all=0; Chuan onechuan; onechuan.c_start=site; onechuan.c_max=0; int max_ele=0; while(all&amp;lt;b[i]){ if(a[site]&amp;gt;max_ele){ max_ele=a[site]; onechuan.c_max=site; } else if(a[site]==max_ele){ if(site-1&amp;gt;=onechuan.c_start&amp;amp;&amp;amp;a[site]&amp;gt;a[site-1]){ onechuan.c_max=site; } else if(site+1&amp;lt;=n&amp;amp;&amp;amp;all+a[site]+a[site+1]&amp;lt;=b[i]&amp;amp;&amp;amp;a[site]&amp;gt;a[site+1]){ onechuan.c_max=site; } } all+=a[site++]; } onechuan.c_end=site-1; if(all!=b[i])flag=1; chuan.push_back(onechuan); //DEBUG(&quot;%d %d %d \n&quot;,onechuan.c_start,onechuan.c_max,onechuan.c_end); } if(flag){ printf(&quot;NO\n&quot;); return 0; } if(site!=n+1){ printf(&quot;NO\n&quot;); return 0; } i=0; while(!print.empty()){ print.pop(); } for(vector&amp;lt;Chuan&amp;gt;::iterator it=chuan.begin();it&amp;lt;chuan.end();it++){ i++; if(it-&amp;gt;c_start==it-&amp;gt;c_end)continue; int pointer=it-&amp;gt;c_max; if(pointer-1&amp;gt;=it-&amp;gt;c_start&amp;amp;&amp;amp;a[pointer]&amp;gt;a[pointer-1]){ while(pointer&amp;gt;it-&amp;gt;c_start){ Print oneprint; oneprint.num=i+pointer-it-&amp;gt;c_start; pointer--; oneprint.dire=&#39;L&#39;; print.push(oneprint); } pointer=it-&amp;gt;c_max; while(pointer&amp;lt;it-&amp;gt;c_end){ Print oneprint; oneprint.num=i; pointer++; oneprint.dire=&#39;R&#39;; print.push(oneprint); } } else if(pointer+1&amp;lt;=it-&amp;gt;c_end&amp;amp;&amp;amp;a[pointer]&amp;gt;a[pointer+1]){ while(pointer&amp;lt;it-&amp;gt;c_end){ Print oneprint; oneprint.num=i+it-&amp;gt;c_max-it-&amp;gt;c_start; //DEBUG(&quot;hello world!\n&quot;); pointer++; oneprint.dire=&#39;R&#39;; print.push(oneprint); } pointer=it-&amp;gt;c_max; while(pointer&amp;gt;it-&amp;gt;c_start){ Print oneprint; oneprint.num=i+pointer-it-&amp;gt;c_start; pointer--; oneprint.dire=&#39;L&#39;; print.push(oneprint); } } else { printf(&quot;NO\n&quot;); while(!print.empty()){ print.pop(); } return 0; } //DEBUG(&quot;%d %d %d\n&quot;,it-&amp;gt;c_start,it-&amp;gt;c_max,it-&amp;gt;c_end); } puts(&quot;YES&quot;); while(!print.empty()){ Print oneprint=print.front(); print.pop(); printf(&quot;%d %c\n&quot;,oneprint.num,oneprint.dire); } return 0; } 经验教训 你离AC还差N个细节！ 其实还是心不够静，思维跟不上，静下来后，你的智商会变高！ 仔细阅读题意，然后注意关掉DEBUG！ 作者：qq_27803491 发表于2016/11/4 1:17:06 [原文链接](http://blog.csdn.net/qq_27803491/article/details/53029288) 阅读：89 评论：0 [查看评论](http://blog.csdn.net/qq_27803491/article/details/53029288#comments)]]></content>
  </entry>
  <entry>
    <title><![CDATA[[原]AC必备]]></title>
    <url>%2F2016%2F11%2F03%2FAC%E5%BF%85%E5%A4%87%2F</url>
    <content type="text"><![CDATA[#define _CRT_SECURE_NO_WARNINGS #include &amp;lt;iostream&amp;gt; #include &amp;lt;cstdio&amp;gt; #include &amp;lt;cstring&amp;gt; #include &amp;lt;algorithm&amp;gt; #include &amp;lt;stack&amp;gt; #include &amp;lt;string&amp;gt; #include &amp;lt;set&amp;gt; #include &amp;lt;cmath&amp;gt; #include &amp;lt;map&amp;gt; #include &amp;lt;queue&amp;gt; #include &amp;lt;sstream&amp;gt; #include &amp;lt;vector&amp;gt; #include &amp;lt;iomanip&amp;gt; #define m0(a) memset(a,0,sizeof(a)) #define mm(a) memset(a,0x3f,sizeof(a)) #define m_1(a) memset(a,-1,sizeof(a)) #define f(i,a,b) for(int i = a;i&amp;lt;=b;i++) #define fi(i,a,b) for(int i = a;i&amp;gt;=b;i--) #define lowbit(a) ((a)&amp;amp;(-a)) #define FFR freopen(&quot;data.in&quot;,&quot;r&quot;,stdin) #define FFW freopen(&quot;data.out&quot;,&quot;w&quot;,stdout) #define INF 0x3f3f3f3f #define DEBUG //printf typedef long long ll; typedef long double ld; const ld PI = acos(-1.0); using namespace std; #define SIZE (1) int aa[SIZE]; int main() { return 0; } 写每道题都会用到，把他们做成模版，每次就没必要都打一遍了，节省了时间。 作者：qq_27803491 发表于2016/11/3 23:50:06 [原文链接](http://blog.csdn.net/qq_27803491/article/details/53028318) 阅读：66 评论：0 [查看评论](http://blog.csdn.net/qq_27803491/article/details/53028318#comments)]]></content>
  </entry>
  <entry>
    <title><![CDATA[[原]2016-11-3 周四]]></title>
    <url>%2F2016%2F11%2F03%2F2016-11-3-%E5%91%A8%E5%9B%9B%2F</url>
    <content type="text"><![CDATA[计划（这周和下周）这两周，事情比较多，搞事情嘛，就是要有事做才好，不怕事，喜~事 1. 下周四数据库期中考试(10号) 2. 下周六、日ACM-ICPC北京赛区比赛（12、13号） 3. 下下周一操作系统考试（14号） 4. 周日复习操作系统和数据库。 5. 每天至少2到中级难度的题，有算法的能写到博客上的。 6. 面试时会考的算法掌握好。（不只是面试时，基本的算法掌握，熟练） 总结时间：11.14 acm_reginal 北京没有拿奖，真的差的很远，水平好差，要专注的去搞一件事情，用尽全力，否则，只有努力，没有成果，白受苦。 操作系统考的很差，数据库考的还可以。 心得为什么 “后悔没有早点知道” ，就算你知道的早了，你没有亲身体验过，你相信么，好了，现在亲身体验了，后果自己也吃了。所以，要变的优秀，要想成功，就得去坚信那些道理，因为那是前人总结出来的经验，这样才能少走弯路。 作者：qq_27803491 发表于2016/11/3 20:25:06 [原文链接](http://blog.csdn.net/qq_27803491/article/details/53025252) 阅读：54 评论：0 [查看评论](http://blog.csdn.net/qq_27803491/article/details/53025252#comments)]]></content>
  </entry>
  <entry>
    <title><![CDATA[[原]hdu5912 简单公式迭代]]></title>
    <url>%2F2016%2F11%2F02%2Fhdu5912-%E7%AE%80%E5%8D%95%E5%85%AC%E5%BC%8F%E8%BF%AD%E4%BB%A3%2F</url>
    <content type="text"><![CDATA[题目链接http://acm.hdu.edu.cn/showproblem.php?pid=5912 代码#include&amp;lt;iostream&amp;gt; #include&amp;lt;cstring&amp;gt; #include&amp;lt;cstdio&amp;gt; #include&amp;lt;algorithm&amp;gt; #define ll long long #define DEBUG printf using namespace std; ll GCD(ll aa,ll bb) { ll i,t; if(aa&amp;lt;bb){ t=aa; aa=bb; bb=t; } while(aa%bb!=0){ i=aa%bb; if(bb&amp;gt;i){ aa=bb; bb=i; } else aa=i; } return bb; } void solve(ll &amp;amp;mu,ll &amp;amp;zi,int *a,int *b,int n){ for(int i=n-1;i&amp;gt;=1;i--){ ll tmp_mu=mu,tmp_zi=zi; mu=tmp_zi+tmp_mu*a[i]; zi=tmp_mu*b[i]; ll yueshu=GCD(mu,zi); mu/=yueshu; zi/=yueshu; //DEBUG(&quot;%d:%lld/%lld\n&quot;,i,zi,mu); } } int main() { int t; scanf(&quot;%d&quot;,&amp;amp;t); for(int tt=1;tt&amp;lt;=t;tt++){ int a[11],b[11],n; scanf(&quot;%d&quot;,&amp;amp;n); memset(a,0,sizeof(a)); memset(b,0,sizeof(b)); for(int i=1;i&amp;lt;=n;i++){ scanf(&quot;%d&quot;,&amp;amp;a[i]); } for(int i=1;i&amp;lt;=n;i++){ scanf(&quot;%d&quot;,&amp;amp;b[i]); } ll mu=a[n],zi=b[n]; solve(mu,zi,a,b,n); int yueshu = GCD(mu,zi); mu/=yueshu; zi/=yueshu; printf(&quot;Case #%d: %lld %lld\n&quot;,tt,zi,mu); } return 0; } /* 1 8 1 2 3 4 5 6 7 8 9 8 7 6 5 4 3 2 */ 作者：qq_27803491 发表于2016/11/2 10:41:53 [原文链接](http://blog.csdn.net/qq_27803491/article/details/53005481) 阅读：48 评论：0 [查看评论](http://blog.csdn.net/qq_27803491/article/details/53005481#comments)]]></content>
  </entry>
  <entry>
    <title><![CDATA[[原]51nod 1416两点DFS]]></title>
    <url>%2F2016%2F11%2F01%2F51nod-1416%E4%B8%A4%E7%82%B9DFS%2F</url>
    <content type="text"><![CDATA[题目网址http://www.51nod.com/onlineJudge/questionCode.html#!problemId=1416 简单的深搜 直接上代码#include&amp;lt;iostream&amp;gt; #include&amp;lt;cstring&amp;gt; #include&amp;lt;cstdio&amp;gt; #include&amp;lt;algorithm&amp;gt; #define ll long long #define DEBUG print using namespace std; bool hash[51][51]; char tu[55][55]; int path[55][55]; bool dfs(int n,int m,int i,int j,int count,char c) { // DEBUG(&quot;%c %d %d\n&quot;,c,i,j); hash[i][j]=0; path[i][j]=count; if(j+1&amp;lt;m&amp;amp;&amp;amp;tu[i][j+1]==c){ if(path[i][j+1]&amp;lt;0){ if(dfs(n,m,i,j+1,count+1,c))return true; } else { if(path[i][j]-path[i][j+1]&amp;gt;=3)return true; } } if(i+1&amp;lt;n&amp;amp;&amp;amp;tu[i+1][j]==c){ if(path[i+1][j]&amp;lt;0){ if(dfs(n,m,i+1,j,count+1,c))return true; } else { if(path[i][j]-path[i+1][j]&amp;gt;=3)return true; } } if(j-1&amp;gt;=0&amp;amp;&amp;amp;tu[i][j-1]==c){ if(path[i][j-1]&amp;lt;0){ if(dfs(n,m,i,j-1,count+1,c))return true; } else { if(path[i][j]-path[i][j-1]&amp;gt;=3)return true; } } if(i-1&amp;gt;=0&amp;amp;&amp;amp;tu[i-1][j]==c){ if(path[i-1][j]&amp;lt;0){ if(dfs(n,m,i-1,j,count+1,c))return true; } else { if(path[i][j]-path[i-1][j]&amp;gt;=3)return true; } } return false; } int main() { // memset(hash,1,sizeof(hash)); memset(tu,0,sizeof(tu)); // memset(path,-1,sizeof(path)); int n,m; scanf(&quot;%d%d&quot;,&amp;amp;n,&amp;amp;m); getchar(); for(int i=0;i&amp;lt;n;i++){ for(int j=0;j&amp;lt;m;j++){ hash[i][j]=1; } } for(int i=0;i&amp;lt;n;i++){ for(int j=0;j&amp;lt;m;j++){ path[i][j]=-1; } } for(int i=0;i&amp;lt;n;i++){ for(int j=0;j&amp;lt;m;j++){ scanf(&quot;%c&quot;,&amp;amp;tu[i][j]); } getchar(); } bool ansflag=0; for(int i=0;i&amp;lt;n;i++){ for(int j=0;j&amp;lt;m;j++){ if(!hash[i][j])continue; else { if(dfs(n,m,i,j,0,tu[i][j])){ ansflag=1; break; } } } if(ansflag)break; } if(ansflag)printf(&quot;Yes\n&quot;); else printf(&quot;No\n&quot;); } 作者：qq_27803491 发表于2016/11/1 21:25:29 [原文链接](http://blog.csdn.net/qq_27803491/article/details/53000918) 阅读：49 评论：0 [查看评论](http://blog.csdn.net/qq_27803491/article/details/53000918#comments)]]></content>
  </entry>
</search>
